link,pdf_link,title,authors,abstract,submitted
https://arxiv.org/abs/2503.18460,https://arxiv.org/pdf/2503.18460,ModiGen: A Large Language Model-Based Workflow for Multi-Task Modelica Code Generation,"Jiahui Xiang, Tong Ye, Peiyu Liu, Yinan Zhang, Wenhai Wang","Modelica is a widely adopted language for simulating complex physical systems, yet effective model creation and optimization require substantial domain expertise. Although large language models (LLMs) have demonstrated promising capabilities in code generation, their application to modeling remains largely unexplored. To address this gap, we have developed benchmark datasets specifically designed to evaluate the performance of LLMs in generating Modelica component models and test cases. Our evaluation reveals substantial limitations in current LLMs, as the generated code often fails to simulate successfully. To overcome these challenges, we propose a specialized workflow that integrates supervised fine-tuning, graph retrieval-augmentedgeneration, and feedback optimization to improve the accuracy and reliability of Modelica code generation. The evaluation results demonstrate significant performance gains: the maximum improvement in pass@1 reached 0.3349 for the component generation task and 0.2457 for the testcasegeneration task. This research underscores the potential of LLMs to advance intelligent modeling tools and offers valuable insights for future developments in system modeling and engineering applications.","Submitted 24 March, 2025; originally announced March 2025."
