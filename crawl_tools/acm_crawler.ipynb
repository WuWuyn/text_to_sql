{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d7609d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DrissionPage import ChromiumPage, ChromiumOptions\n",
    "import time\n",
    "import pandas as pd\n",
    "import random\n",
    "from urllib.parse import urljoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44d0ff32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_link(keyword: str, page: ChromiumPage):\n",
    "    try:\n",
    "        # Open the ACM Digital Library website\n",
    "        search_input = f'https://dl.acm.org/action/doSearch?AllField={keyword}'\n",
    "        page.get(search_input)\n",
    "\n",
    "        # Wait for the page to load\n",
    "        time.sleep(2)\n",
    "\n",
    "        links = []\n",
    "        cnt = 1\n",
    "        base_url = \"https://dl.acm.org\"\n",
    "        while True:\n",
    "            try:\n",
    "                # Wait for the page to load\n",
    "                time.sleep(random.randint(2,5))\n",
    "\n",
    "                # Tìm phần tử <a> chứa đường link bằng CSS selector\n",
    "                link_elements = page.eles(\"css:.issue-item__title a\")\n",
    "                \n",
    "                if not link_elements:\n",
    "                    print(f\"No results found on page {cnt}\")\n",
    "                    break\n",
    "\n",
    "                for link in link_elements:\n",
    "                    relative_link = link.attr(\"href\")\n",
    "                    # Tạo đường link đầy đủ bằng cách kết hợp với URL cơ sở\n",
    "                    full_link = urljoin(base_url, relative_link)\n",
    "                    if full_link:\n",
    "                        links.append(full_link)\n",
    "\n",
    "                # Check for next button\n",
    "                next_button = page.ele(\"css:a.pagination__btn--next\")\n",
    "                if not next_button:\n",
    "                    print(f\"Reached last page for keyword: {keyword}\")\n",
    "                    break\n",
    "                \n",
    "                next_button.click()\n",
    "                cnt += 1\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing page {cnt}: {str(e)}\")\n",
    "                break\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error searching for keyword {keyword}: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52969b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def combination_keywords(sets):\n",
    "    \"\"\"Tạo danh sách các chuỗi từ khóa từ một danh sách các bộ từ khóa.\"\"\"\n",
    "    if not sets:\n",
    "        return []\n",
    "    combinations = itertools.product(*sets)\n",
    "    return [' AND '.join(combo) for combo in combinations]\n",
    "\n",
    "def generate_all_combinations(t2sql, security, llm):\n",
    "    \"\"\"Tạo danh sách tất cả các tổ hợp từ khóa theo các trường hợp yêu cầu.\"\"\"\n",
    "    # Định nghĩa các trường hợp cần tạo tổ hợp\n",
    "    cases = [\n",
    "        [t2sql],                    # Chỉ t2sql\n",
    "        [t2sql, security],          # t2sql + security\n",
    "        [t2sql, llm],               # t2sql + llm\n",
    "        [t2sql, security, llm]      # t2sql + security + llm\n",
    "    ]\n",
    "    \n",
    "    # Tạo và hợp nhất tất cả các tổ hợp\n",
    "    all_combinations = []\n",
    "    for case in cases:\n",
    "        all_combinations.extend(combination_keywords(case))\n",
    "    \n",
    "    return all_combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2dce54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_acm():\n",
    "    # Initialize empty lists to store all results\n",
    "    all_links = []\n",
    "\n",
    "    # option = ChromiumOptions()\n",
    "    # # Uncomment the following lines to run in headless mode or with specific options\n",
    "    # option.headless(on_off=True)  # Run in headless mode\n",
    "    # # Initialize Chromium browser\n",
    "    option = ChromiumOptions()\n",
    "    browser = ChromiumPage()\n",
    "\n",
    "    #Thêm ngoặc chính xác bộ keywords\n",
    "    t2sql = ['\"text-to-sql\"', '\"nl2sql\"', '\"t2sql\"', '\"text2sql\"', '\"natural language to sql\"', \n",
    "             '\"semantic parsing to sql\"', '\"nl to sql\"']\n",
    "    security = ['\"security\"', '\"access control\"', '\"injection\"', '\"prompt injection\"', '\"defense\"', '\"attack\"', '\"vulnerability\"']\n",
    "    llm = ['\"llm\"', '\"large language model\"']\n",
    "\n",
    "    keywords = generate_all_combinations(t2sql, security, llm)\n",
    "    \n",
    "    for keyword in keywords:\n",
    "        \n",
    "        print(f'{keyword} is proccessed......')\n",
    "\n",
    "        keyword_1 = keyword.strip()\n",
    "        keyword_1 = keyword_1.replace(\" \", \"+\")\n",
    "        links = crawl_link(keyword_1, browser)\n",
    "\n",
    "            # Create DataFrame after collecting all data\n",
    "        partly = pd.DataFrame()\n",
    "        partly['link'] = links\n",
    "\n",
    "\n",
    "        if not partly.empty:\n",
    "            keyword = keyword.replace('\"', '')\n",
    "            keyword = keyword.replace(' ', '_')\n",
    "            partly.drop_duplicates(subset=['link'], inplace=True)\n",
    "            partly.to_csv(f'../raw_crawl_papers/acm/crawl_by_{keyword}.csv', index=False)\n",
    "\n",
    "        all_links.extend(links)\n",
    "\n",
    "    full = pd.DataFrame()\n",
    "    \n",
    "    full['link'] = all_links\n",
    "    \n",
    "    full.drop_duplicates(subset=['link'], inplace=True)\n",
    "    full.to_csv('../raw_crawl_papers/acm/all_acm_papers.csv', index=False)\n",
    "\n",
    "    # Close the browser\n",
    "    browser.quit()\n",
    "    print(f\"Total papers collected: {len(full)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e489855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"text-to-sql\" is proccessed......\n",
      "Reached last page for keyword: \"text-to-sql\"\n",
      "\"nl2sql\" is proccessed......\n",
      "Reached last page for keyword: \"nl2sql\"\n",
      "\"t2sql\" is proccessed......\n",
      "No results found on page 1\n",
      "\"text2sql\" is proccessed......\n",
      "Reached last page for keyword: \"text2sql\"\n",
      "\"natural language to sql\" is proccessed......\n",
      "Reached last page for keyword: \"natural+language+to+sql\"\n",
      "\"semantic parsing to sql\" is proccessed......\n",
      "No results found on page 1\n",
      "\"nl to sql\" is proccessed......\n",
      "Reached last page for keyword: \"nl+to+sql\"\n",
      "\"text-to-sql\" AND \"security\" is proccessed......\n",
      "Reached last page for keyword: \"text-to-sql\"+AND+\"security\"\n",
      "\"text-to-sql\" AND \"access control\" is proccessed......\n",
      "Reached last page for keyword: \"text-to-sql\"+AND+\"access+control\"\n",
      "\"text-to-sql\" AND \"injection\" is proccessed......\n",
      "Reached last page for keyword: \"text-to-sql\"+AND+\"injection\"\n",
      "\"text-to-sql\" AND \"prompt injection\" is proccessed......\n",
      "Reached last page for keyword: \"text-to-sql\"+AND+\"prompt+injection\"\n",
      "\"text-to-sql\" AND \"defense\" is proccessed......\n",
      "Reached last page for keyword: \"text-to-sql\"+AND+\"defense\"\n",
      "\"text-to-sql\" AND \"attack\" is proccessed......\n",
      "Reached last page for keyword: \"text-to-sql\"+AND+\"attack\"\n",
      "\"text-to-sql\" AND \"vulnerability\" is proccessed......\n",
      "Reached last page for keyword: \"text-to-sql\"+AND+\"vulnerability\"\n",
      "\"nl2sql\" AND \"security\" is proccessed......\n",
      "Reached last page for keyword: \"nl2sql\"+AND+\"security\"\n",
      "\"nl2sql\" AND \"access control\" is proccessed......\n",
      "Reached last page for keyword: \"nl2sql\"+AND+\"access+control\"\n",
      "\"nl2sql\" AND \"injection\" is proccessed......\n",
      "Reached last page for keyword: \"nl2sql\"+AND+\"injection\"\n",
      "\"nl2sql\" AND \"prompt injection\" is proccessed......\n",
      "Reached last page for keyword: \"nl2sql\"+AND+\"prompt+injection\"\n",
      "\"nl2sql\" AND \"defense\" is proccessed......\n",
      "Reached last page for keyword: \"nl2sql\"+AND+\"defense\"\n",
      "\"nl2sql\" AND \"attack\" is proccessed......\n",
      "Reached last page for keyword: \"nl2sql\"+AND+\"attack\"\n",
      "\"nl2sql\" AND \"vulnerability\" is proccessed......\n",
      "Reached last page for keyword: \"nl2sql\"+AND+\"vulnerability\"\n",
      "\"t2sql\" AND \"security\" is proccessed......\n",
      "No results found on page 1\n",
      "\"t2sql\" AND \"access control\" is proccessed......\n",
      "No results found on page 1\n",
      "\"t2sql\" AND \"injection\" is proccessed......\n",
      "No results found on page 1\n",
      "\"t2sql\" AND \"prompt injection\" is proccessed......\n",
      "No results found on page 1\n",
      "\"t2sql\" AND \"defense\" is proccessed......\n",
      "No results found on page 1\n",
      "\"t2sql\" AND \"attack\" is proccessed......\n",
      "No results found on page 1\n",
      "\"t2sql\" AND \"vulnerability\" is proccessed......\n",
      "No results found on page 1\n",
      "\"text2sql\" AND \"security\" is proccessed......\n",
      "Reached last page for keyword: \"text2sql\"+AND+\"security\"\n",
      "\"text2sql\" AND \"access control\" is proccessed......\n",
      "Reached last page for keyword: \"text2sql\"+AND+\"access+control\"\n",
      "\"text2sql\" AND \"injection\" is proccessed......\n",
      "Reached last page for keyword: \"text2sql\"+AND+\"injection\"\n",
      "\"text2sql\" AND \"prompt injection\" is proccessed......\n",
      "Reached last page for keyword: \"text2sql\"+AND+\"prompt+injection\"\n",
      "\"text2sql\" AND \"defense\" is proccessed......\n",
      "Reached last page for keyword: \"text2sql\"+AND+\"defense\"\n",
      "\"text2sql\" AND \"attack\" is proccessed......\n",
      "Reached last page for keyword: \"text2sql\"+AND+\"attack\"\n",
      "\"text2sql\" AND \"vulnerability\" is proccessed......\n",
      "Reached last page for keyword: \"text2sql\"+AND+\"vulnerability\"\n",
      "\"natural language to sql\" AND \"security\" is proccessed......\n",
      "Reached last page for keyword: \"natural+language+to+sql\"+AND+\"security\"\n",
      "\"natural language to sql\" AND \"access control\" is proccessed......\n",
      "Reached last page for keyword: \"natural+language+to+sql\"+AND+\"access+control\"\n",
      "\"natural language to sql\" AND \"injection\" is proccessed......\n",
      "Reached last page for keyword: \"natural+language+to+sql\"+AND+\"injection\"\n",
      "\"natural language to sql\" AND \"prompt injection\" is proccessed......\n",
      "Reached last page for keyword: \"natural+language+to+sql\"+AND+\"prompt+injection\"\n",
      "\"natural language to sql\" AND \"defense\" is proccessed......\n",
      "Reached last page for keyword: \"natural+language+to+sql\"+AND+\"defense\"\n",
      "\"natural language to sql\" AND \"attack\" is proccessed......\n",
      "Reached last page for keyword: \"natural+language+to+sql\"+AND+\"attack\"\n",
      "\"natural language to sql\" AND \"vulnerability\" is proccessed......\n",
      "Reached last page for keyword: \"natural+language+to+sql\"+AND+\"vulnerability\"\n",
      "\"semantic parsing to sql\" AND \"security\" is proccessed......\n",
      "No results found on page 1\n",
      "\"semantic parsing to sql\" AND \"access control\" is proccessed......\n",
      "No results found on page 1\n",
      "\"semantic parsing to sql\" AND \"injection\" is proccessed......\n",
      "No results found on page 1\n",
      "\"semantic parsing to sql\" AND \"prompt injection\" is proccessed......\n",
      "No results found on page 1\n",
      "\"semantic parsing to sql\" AND \"defense\" is proccessed......\n",
      "No results found on page 1\n",
      "\"semantic parsing to sql\" AND \"attack\" is proccessed......\n",
      "No results found on page 1\n",
      "\"semantic parsing to sql\" AND \"vulnerability\" is proccessed......\n",
      "No results found on page 1\n",
      "\"nl to sql\" AND \"security\" is proccessed......\n",
      "Reached last page for keyword: \"nl+to+sql\"+AND+\"security\"\n",
      "\"nl to sql\" AND \"access control\" is proccessed......\n",
      "Reached last page for keyword: \"nl+to+sql\"+AND+\"access+control\"\n",
      "\"nl to sql\" AND \"injection\" is proccessed......\n",
      "Reached last page for keyword: \"nl+to+sql\"+AND+\"injection\"\n",
      "\"nl to sql\" AND \"prompt injection\" is proccessed......\n",
      "No results found on page 1\n",
      "\"nl to sql\" AND \"defense\" is proccessed......\n",
      "Reached last page for keyword: \"nl+to+sql\"+AND+\"defense\"\n",
      "\"nl to sql\" AND \"attack\" is proccessed......\n",
      "Reached last page for keyword: \"nl+to+sql\"+AND+\"attack\"\n",
      "\"nl to sql\" AND \"vulnerability\" is proccessed......\n",
      "Reached last page for keyword: \"nl+to+sql\"+AND+\"vulnerability\"\n",
      "\"text-to-sql\" AND \"llm\" is proccessed......\n",
      "Reached last page for keyword: \"text-to-sql\"+AND+\"llm\"\n",
      "\"text-to-sql\" AND \"large language model\" is proccessed......\n",
      "Reached last page for keyword: \"text-to-sql\"+AND+\"large+language+model\"\n",
      "\"nl2sql\" AND \"llm\" is proccessed......\n",
      "Reached last page for keyword: \"nl2sql\"+AND+\"llm\"\n",
      "\"nl2sql\" AND \"large language model\" is proccessed......\n",
      "Reached last page for keyword: \"nl2sql\"+AND+\"large+language+model\"\n",
      "\"t2sql\" AND \"llm\" is proccessed......\n",
      "No results found on page 1\n",
      "\"t2sql\" AND \"large language model\" is proccessed......\n",
      "No results found on page 1\n",
      "\"text2sql\" AND \"llm\" is proccessed......\n",
      "Reached last page for keyword: \"text2sql\"+AND+\"llm\"\n",
      "\"text2sql\" AND \"large language model\" is proccessed......\n",
      "Reached last page for keyword: \"text2sql\"+AND+\"large+language+model\"\n",
      "\"natural language to sql\" AND \"llm\" is proccessed......\n",
      "Reached last page for keyword: \"natural+language+to+sql\"+AND+\"llm\"\n",
      "\"natural language to sql\" AND \"large language model\" is proccessed......\n",
      "Reached last page for keyword: \"natural+language+to+sql\"+AND+\"large+language+model\"\n",
      "\"semantic parsing to sql\" AND \"llm\" is proccessed......\n",
      "No results found on page 1\n",
      "\"semantic parsing to sql\" AND \"large language model\" is proccessed......\n",
      "No results found on page 1\n",
      "\"nl to sql\" AND \"llm\" is proccessed......\n",
      "Reached last page for keyword: \"nl+to+sql\"+AND+\"llm\"\n",
      "\"nl to sql\" AND \"large language model\" is proccessed......\n",
      "Reached last page for keyword: \"nl+to+sql\"+AND+\"large+language+model\"\n",
      "\"text-to-sql\" AND \"security\" AND \"llm\" is proccessed......\n",
      "Reached last page for keyword: \"text-to-sql\"+AND+\"security\"+AND+\"llm\"\n",
      "\"text-to-sql\" AND \"security\" AND \"large language model\" is proccessed......\n",
      "Reached last page for keyword: \"text-to-sql\"+AND+\"security\"+AND+\"large+language+model\"\n",
      "\"text-to-sql\" AND \"access control\" AND \"llm\" is proccessed......\n",
      "Reached last page for keyword: \"text-to-sql\"+AND+\"access+control\"+AND+\"llm\"\n",
      "\"text-to-sql\" AND \"access control\" AND \"large language model\" is proccessed......\n",
      "Reached last page for keyword: \"text-to-sql\"+AND+\"access+control\"+AND+\"large+language+model\"\n",
      "\"text-to-sql\" AND \"injection\" AND \"llm\" is proccessed......\n",
      "Reached last page for keyword: \"text-to-sql\"+AND+\"injection\"+AND+\"llm\"\n",
      "\"text-to-sql\" AND \"injection\" AND \"large language model\" is proccessed......\n",
      "Reached last page for keyword: \"text-to-sql\"+AND+\"injection\"+AND+\"large+language+model\"\n",
      "\"text-to-sql\" AND \"prompt injection\" AND \"llm\" is proccessed......\n",
      "Reached last page for keyword: \"text-to-sql\"+AND+\"prompt+injection\"+AND+\"llm\"\n",
      "\"text-to-sql\" AND \"prompt injection\" AND \"large language model\" is proccessed......\n",
      "Reached last page for keyword: \"text-to-sql\"+AND+\"prompt+injection\"+AND+\"large+language+model\"\n",
      "\"text-to-sql\" AND \"defense\" AND \"llm\" is proccessed......\n",
      "Reached last page for keyword: \"text-to-sql\"+AND+\"defense\"+AND+\"llm\"\n",
      "\"text-to-sql\" AND \"defense\" AND \"large language model\" is proccessed......\n",
      "Reached last page for keyword: \"text-to-sql\"+AND+\"defense\"+AND+\"large+language+model\"\n",
      "\"text-to-sql\" AND \"attack\" AND \"llm\" is proccessed......\n",
      "Reached last page for keyword: \"text-to-sql\"+AND+\"attack\"+AND+\"llm\"\n",
      "\"text-to-sql\" AND \"attack\" AND \"large language model\" is proccessed......\n",
      "Reached last page for keyword: \"text-to-sql\"+AND+\"attack\"+AND+\"large+language+model\"\n",
      "\"text-to-sql\" AND \"vulnerability\" AND \"llm\" is proccessed......\n",
      "Reached last page for keyword: \"text-to-sql\"+AND+\"vulnerability\"+AND+\"llm\"\n",
      "\"text-to-sql\" AND \"vulnerability\" AND \"large language model\" is proccessed......\n",
      "Reached last page for keyword: \"text-to-sql\"+AND+\"vulnerability\"+AND+\"large+language+model\"\n",
      "\"nl2sql\" AND \"security\" AND \"llm\" is proccessed......\n",
      "Reached last page for keyword: \"nl2sql\"+AND+\"security\"+AND+\"llm\"\n",
      "\"nl2sql\" AND \"security\" AND \"large language model\" is proccessed......\n",
      "Reached last page for keyword: \"nl2sql\"+AND+\"security\"+AND+\"large+language+model\"\n",
      "\"nl2sql\" AND \"access control\" AND \"llm\" is proccessed......\n",
      "Reached last page for keyword: \"nl2sql\"+AND+\"access+control\"+AND+\"llm\"\n",
      "\"nl2sql\" AND \"access control\" AND \"large language model\" is proccessed......\n",
      "Reached last page for keyword: \"nl2sql\"+AND+\"access+control\"+AND+\"large+language+model\"\n",
      "\"nl2sql\" AND \"injection\" AND \"llm\" is proccessed......\n",
      "Reached last page for keyword: \"nl2sql\"+AND+\"injection\"+AND+\"llm\"\n",
      "\"nl2sql\" AND \"injection\" AND \"large language model\" is proccessed......\n",
      "Reached last page for keyword: \"nl2sql\"+AND+\"injection\"+AND+\"large+language+model\"\n",
      "\"nl2sql\" AND \"prompt injection\" AND \"llm\" is proccessed......\n",
      "Reached last page for keyword: \"nl2sql\"+AND+\"prompt+injection\"+AND+\"llm\"\n",
      "\"nl2sql\" AND \"prompt injection\" AND \"large language model\" is proccessed......\n",
      "Reached last page for keyword: \"nl2sql\"+AND+\"prompt+injection\"+AND+\"large+language+model\"\n",
      "\"nl2sql\" AND \"defense\" AND \"llm\" is proccessed......\n",
      "Reached last page for keyword: \"nl2sql\"+AND+\"defense\"+AND+\"llm\"\n",
      "\"nl2sql\" AND \"defense\" AND \"large language model\" is proccessed......\n",
      "Reached last page for keyword: \"nl2sql\"+AND+\"defense\"+AND+\"large+language+model\"\n",
      "\"nl2sql\" AND \"attack\" AND \"llm\" is proccessed......\n",
      "Reached last page for keyword: \"nl2sql\"+AND+\"attack\"+AND+\"llm\"\n",
      "\"nl2sql\" AND \"attack\" AND \"large language model\" is proccessed......\n",
      "Reached last page for keyword: \"nl2sql\"+AND+\"attack\"+AND+\"large+language+model\"\n",
      "\"nl2sql\" AND \"vulnerability\" AND \"llm\" is proccessed......\n",
      "Reached last page for keyword: \"nl2sql\"+AND+\"vulnerability\"+AND+\"llm\"\n",
      "\"nl2sql\" AND \"vulnerability\" AND \"large language model\" is proccessed......\n",
      "Reached last page for keyword: \"nl2sql\"+AND+\"vulnerability\"+AND+\"large+language+model\"\n",
      "\"t2sql\" AND \"security\" AND \"llm\" is proccessed......\n",
      "No results found on page 1\n",
      "\"t2sql\" AND \"security\" AND \"large language model\" is proccessed......\n",
      "No results found on page 1\n",
      "\"t2sql\" AND \"access control\" AND \"llm\" is proccessed......\n",
      "No results found on page 1\n",
      "\"t2sql\" AND \"access control\" AND \"large language model\" is proccessed......\n",
      "No results found on page 1\n",
      "\"t2sql\" AND \"injection\" AND \"llm\" is proccessed......\n",
      "No results found on page 1\n",
      "\"t2sql\" AND \"injection\" AND \"large language model\" is proccessed......\n",
      "No results found on page 1\n",
      "\"t2sql\" AND \"prompt injection\" AND \"llm\" is proccessed......\n",
      "No results found on page 1\n",
      "\"t2sql\" AND \"prompt injection\" AND \"large language model\" is proccessed......\n",
      "No results found on page 1\n",
      "\"t2sql\" AND \"defense\" AND \"llm\" is proccessed......\n",
      "No results found on page 1\n",
      "\"t2sql\" AND \"defense\" AND \"large language model\" is proccessed......\n",
      "No results found on page 1\n",
      "\"t2sql\" AND \"attack\" AND \"llm\" is proccessed......\n",
      "No results found on page 1\n",
      "\"t2sql\" AND \"attack\" AND \"large language model\" is proccessed......\n",
      "No results found on page 1\n",
      "\"t2sql\" AND \"vulnerability\" AND \"llm\" is proccessed......\n",
      "No results found on page 1\n",
      "\"t2sql\" AND \"vulnerability\" AND \"large language model\" is proccessed......\n",
      "No results found on page 1\n",
      "\"text2sql\" AND \"security\" AND \"llm\" is proccessed......\n",
      "Reached last page for keyword: \"text2sql\"+AND+\"security\"+AND+\"llm\"\n",
      "\"text2sql\" AND \"security\" AND \"large language model\" is proccessed......\n",
      "Reached last page for keyword: \"text2sql\"+AND+\"security\"+AND+\"large+language+model\"\n",
      "\"text2sql\" AND \"access control\" AND \"llm\" is proccessed......\n",
      "Reached last page for keyword: \"text2sql\"+AND+\"access+control\"+AND+\"llm\"\n",
      "\"text2sql\" AND \"access control\" AND \"large language model\" is proccessed......\n",
      "Reached last page for keyword: \"text2sql\"+AND+\"access+control\"+AND+\"large+language+model\"\n",
      "\"text2sql\" AND \"injection\" AND \"llm\" is proccessed......\n",
      "Reached last page for keyword: \"text2sql\"+AND+\"injection\"+AND+\"llm\"\n",
      "\"text2sql\" AND \"injection\" AND \"large language model\" is proccessed......\n",
      "Reached last page for keyword: \"text2sql\"+AND+\"injection\"+AND+\"large+language+model\"\n",
      "\"text2sql\" AND \"prompt injection\" AND \"llm\" is proccessed......\n",
      "Reached last page for keyword: \"text2sql\"+AND+\"prompt+injection\"+AND+\"llm\"\n",
      "\"text2sql\" AND \"prompt injection\" AND \"large language model\" is proccessed......\n",
      "Reached last page for keyword: \"text2sql\"+AND+\"prompt+injection\"+AND+\"large+language+model\"\n",
      "\"text2sql\" AND \"defense\" AND \"llm\" is proccessed......\n",
      "Reached last page for keyword: \"text2sql\"+AND+\"defense\"+AND+\"llm\"\n",
      "\"text2sql\" AND \"defense\" AND \"large language model\" is proccessed......\n",
      "Reached last page for keyword: \"text2sql\"+AND+\"defense\"+AND+\"large+language+model\"\n",
      "\"text2sql\" AND \"attack\" AND \"llm\" is proccessed......\n",
      "Reached last page for keyword: \"text2sql\"+AND+\"attack\"+AND+\"llm\"\n",
      "\"text2sql\" AND \"attack\" AND \"large language model\" is proccessed......\n",
      "Reached last page for keyword: \"text2sql\"+AND+\"attack\"+AND+\"large+language+model\"\n",
      "\"text2sql\" AND \"vulnerability\" AND \"llm\" is proccessed......\n",
      "Reached last page for keyword: \"text2sql\"+AND+\"vulnerability\"+AND+\"llm\"\n",
      "\"text2sql\" AND \"vulnerability\" AND \"large language model\" is proccessed......\n",
      "Reached last page for keyword: \"text2sql\"+AND+\"vulnerability\"+AND+\"large+language+model\"\n",
      "\"natural language to sql\" AND \"security\" AND \"llm\" is proccessed......\n",
      "Reached last page for keyword: \"natural+language+to+sql\"+AND+\"security\"+AND+\"llm\"\n",
      "\"natural language to sql\" AND \"security\" AND \"large language model\" is proccessed......\n",
      "Reached last page for keyword: \"natural+language+to+sql\"+AND+\"security\"+AND+\"large+language+model\"\n",
      "\"natural language to sql\" AND \"access control\" AND \"llm\" is proccessed......\n",
      "Reached last page for keyword: \"natural+language+to+sql\"+AND+\"access+control\"+AND+\"llm\"\n",
      "\"natural language to sql\" AND \"access control\" AND \"large language model\" is proccessed......\n",
      "Reached last page for keyword: \"natural+language+to+sql\"+AND+\"access+control\"+AND+\"large+language+model\"\n",
      "\"natural language to sql\" AND \"injection\" AND \"llm\" is proccessed......\n",
      "Reached last page for keyword: \"natural+language+to+sql\"+AND+\"injection\"+AND+\"llm\"\n",
      "\"natural language to sql\" AND \"injection\" AND \"large language model\" is proccessed......\n",
      "Reached last page for keyword: \"natural+language+to+sql\"+AND+\"injection\"+AND+\"large+language+model\"\n",
      "\"natural language to sql\" AND \"prompt injection\" AND \"llm\" is proccessed......\n",
      "Reached last page for keyword: \"natural+language+to+sql\"+AND+\"prompt+injection\"+AND+\"llm\"\n",
      "\"natural language to sql\" AND \"prompt injection\" AND \"large language model\" is proccessed......\n",
      "Reached last page for keyword: \"natural+language+to+sql\"+AND+\"prompt+injection\"+AND+\"large+language+model\"\n",
      "\"natural language to sql\" AND \"defense\" AND \"llm\" is proccessed......\n",
      "Reached last page for keyword: \"natural+language+to+sql\"+AND+\"defense\"+AND+\"llm\"\n",
      "\"natural language to sql\" AND \"defense\" AND \"large language model\" is proccessed......\n",
      "Reached last page for keyword: \"natural+language+to+sql\"+AND+\"defense\"+AND+\"large+language+model\"\n",
      "\"natural language to sql\" AND \"attack\" AND \"llm\" is proccessed......\n",
      "Reached last page for keyword: \"natural+language+to+sql\"+AND+\"attack\"+AND+\"llm\"\n",
      "\"natural language to sql\" AND \"attack\" AND \"large language model\" is proccessed......\n",
      "Reached last page for keyword: \"natural+language+to+sql\"+AND+\"attack\"+AND+\"large+language+model\"\n",
      "\"natural language to sql\" AND \"vulnerability\" AND \"llm\" is proccessed......\n",
      "Reached last page for keyword: \"natural+language+to+sql\"+AND+\"vulnerability\"+AND+\"llm\"\n",
      "\"natural language to sql\" AND \"vulnerability\" AND \"large language model\" is proccessed......\n",
      "Reached last page for keyword: \"natural+language+to+sql\"+AND+\"vulnerability\"+AND+\"large+language+model\"\n",
      "\"semantic parsing to sql\" AND \"security\" AND \"llm\" is proccessed......\n",
      "No results found on page 1\n",
      "\"semantic parsing to sql\" AND \"security\" AND \"large language model\" is proccessed......\n",
      "No results found on page 1\n",
      "\"semantic parsing to sql\" AND \"access control\" AND \"llm\" is proccessed......\n",
      "No results found on page 1\n",
      "\"semantic parsing to sql\" AND \"access control\" AND \"large language model\" is proccessed......\n",
      "No results found on page 1\n",
      "\"semantic parsing to sql\" AND \"injection\" AND \"llm\" is proccessed......\n",
      "No results found on page 1\n",
      "\"semantic parsing to sql\" AND \"injection\" AND \"large language model\" is proccessed......\n",
      "No results found on page 1\n",
      "\"semantic parsing to sql\" AND \"prompt injection\" AND \"llm\" is proccessed......\n",
      "No results found on page 1\n",
      "\"semantic parsing to sql\" AND \"prompt injection\" AND \"large language model\" is proccessed......\n",
      "No results found on page 1\n",
      "\"semantic parsing to sql\" AND \"defense\" AND \"llm\" is proccessed......\n",
      "No results found on page 1\n",
      "\"semantic parsing to sql\" AND \"defense\" AND \"large language model\" is proccessed......\n",
      "No results found on page 1\n",
      "\"semantic parsing to sql\" AND \"attack\" AND \"llm\" is proccessed......\n",
      "No results found on page 1\n",
      "\"semantic parsing to sql\" AND \"attack\" AND \"large language model\" is proccessed......\n",
      "No results found on page 1\n",
      "\"semantic parsing to sql\" AND \"vulnerability\" AND \"llm\" is proccessed......\n",
      "No results found on page 1\n",
      "\"semantic parsing to sql\" AND \"vulnerability\" AND \"large language model\" is proccessed......\n",
      "No results found on page 1\n",
      "\"nl to sql\" AND \"security\" AND \"llm\" is proccessed......\n",
      "Reached last page for keyword: \"nl+to+sql\"+AND+\"security\"+AND+\"llm\"\n",
      "\"nl to sql\" AND \"security\" AND \"large language model\" is proccessed......\n",
      "Reached last page for keyword: \"nl+to+sql\"+AND+\"security\"+AND+\"large+language+model\"\n",
      "\"nl to sql\" AND \"access control\" AND \"llm\" is proccessed......\n",
      "Reached last page for keyword: \"nl+to+sql\"+AND+\"access+control\"+AND+\"llm\"\n",
      "\"nl to sql\" AND \"access control\" AND \"large language model\" is proccessed......\n",
      "Reached last page for keyword: \"nl+to+sql\"+AND+\"access+control\"+AND+\"large+language+model\"\n",
      "\"nl to sql\" AND \"injection\" AND \"llm\" is proccessed......\n",
      "Reached last page for keyword: \"nl+to+sql\"+AND+\"injection\"+AND+\"llm\"\n",
      "\"nl to sql\" AND \"injection\" AND \"large language model\" is proccessed......\n",
      "Reached last page for keyword: \"nl+to+sql\"+AND+\"injection\"+AND+\"large+language+model\"\n",
      "\"nl to sql\" AND \"prompt injection\" AND \"llm\" is proccessed......\n",
      "No results found on page 1\n",
      "\"nl to sql\" AND \"prompt injection\" AND \"large language model\" is proccessed......\n",
      "No results found on page 1\n",
      "\"nl to sql\" AND \"defense\" AND \"llm\" is proccessed......\n",
      "Reached last page for keyword: \"nl+to+sql\"+AND+\"defense\"+AND+\"llm\"\n",
      "\"nl to sql\" AND \"defense\" AND \"large language model\" is proccessed......\n",
      "Reached last page for keyword: \"nl+to+sql\"+AND+\"defense\"+AND+\"large+language+model\"\n",
      "\"nl to sql\" AND \"attack\" AND \"llm\" is proccessed......\n",
      "Reached last page for keyword: \"nl+to+sql\"+AND+\"attack\"+AND+\"llm\"\n",
      "\"nl to sql\" AND \"attack\" AND \"large language model\" is proccessed......\n",
      "Reached last page for keyword: \"nl+to+sql\"+AND+\"attack\"+AND+\"large+language+model\"\n",
      "\"nl to sql\" AND \"vulnerability\" AND \"llm\" is proccessed......\n",
      "No results found on page 1\n",
      "\"nl to sql\" AND \"vulnerability\" AND \"large language model\" is proccessed......\n",
      "No results found on page 1\n",
      "Total papers collected: 279\n"
     ]
    }
   ],
   "source": [
    "crawl_acm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "385daa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_detail(page: ChromiumPage, link: str):\n",
    "    \n",
    "    page.get(link)\n",
    "    time.sleep(2)\n",
    "\n",
    "   # Trích xuất PDF link\n",
    "    # Select the <a> tag with class \"btn btn--pdf red\" using CSS selector\n",
    "    pdf_element = page.ele(\"css:a.btn.btn--pdf.red\") if page.ele(\"css:a.btn.btn--pdf.red\") else None\n",
    "\n",
    "    # Extract the href attribute (PDF link)\n",
    "    pdf_link = pdf_element.attr(\"href\") if pdf_element else None\n",
    "    print(f\"PDF Link: {pdf_link}\")\n",
    "\n",
    "    # Trích xuất tiêu đề\n",
    "    title = page.ele(\"css:h1[property='name']\").text if page.ele(\"css:h1[property='name']\") else None\n",
    "    print(f'Title:{title}')\n",
    "\n",
    "    # Trích xuất danh sách tác giả\n",
    "    author_spans = page.eles(\"css:span[property='author']\") if page.eles(\"css:span[property='author']\") else None\n",
    "    authors = [author_span.ele(\"css:a\").text for author_span in author_spans] if author_spans else None\n",
    "    if authors:\n",
    "        print(f\"Authors: {', '.join(authors)}\")\n",
    "    else:\n",
    "        print('Author: None')\n",
    "\n",
    "    # Trích xuất tóm tắt\n",
    "    abstract_paragraphs = page.ele(\"css:#abstracts\").eles(\"css:div[role='paragraph']\") if page.ele(\"css:#abstracts\") else None\n",
    "    abstract = \" \".join([p.text for p in abstract_paragraphs]) if abstract_paragraphs else None\n",
    "    print(f\"Abstract: {abstract}\")\n",
    "\n",
    "    # Trích xuất ngày gửi\n",
    "    submission_date = page.ele(\"css:span.core-date-published\").text if page.ele(\"css:span.core-date-published\") else None\n",
    "    print(f\"Submission Date: {submission_date}\")\n",
    "\n",
    "    # Trích xuất DOI link\n",
    "    doi_link = page.ele(\"css:a[property='sameAs']\").attr(\"href\") if page.ele(\"css:a[property='sameAs']\") else None\n",
    "    print(f\"DOI Link: {doi_link}\")\n",
    "\n",
    "    return title, authors, pdf_link, abstract, doi_link, submission_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d13fcdc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing link: https://dl.acm.org/doi/10.1145/3708359.3712083\n",
      "PDF Link: https://dl.acm.org/doi/pdf/10.1145/3708359.3712083\n",
      "Title:Text-to-SQL Domain Adaptation via Human-LLM Collaborative Data Annotation\n",
      "Authors: YuanTian, DanielLee, FeiWu, TungMai, KunQian, SiddharthaSahai, TianyiZhang, YunyaoLi\n",
      "Abstract: Text-to-SQL models, which parse natural language (NL) questions to executable SQL queries, are increasingly adopted in real-world applications. However, deploying such models in the real world often requires adapting them to the highly specialized database schemas used in specific applications. We find that existing text-to-SQL models experience significant performance drops when applied to new schemas, primarily due to the lack of domain-specific data for fine-tuning. This data scarcity also limits the ability to effectively evaluate model performance in new domains. Continuously obtaining high-quality text-to-SQL data for evolving schemas is prohibitively expensive in real-world scenarios. To bridge this gap, we propose SQLsynth, a human-in-the-loop text-to-SQL data annotation system. SQLsynth streamlines the creation of high-quality text-to-SQL datasets through human-LLM collaboration in a structured workflow. A within-subjects user study comparing SQLsynth with manual annotation and ChatGPT shows that SQLsynth significantly accelerates text-to-SQL data annotation, reduces cognitive load, and produces datasets that are more accurate, natural, and diverse. Our code is available at https://github.com/adobe/nl_sql_analyzer.\n",
      "Submission Date: 24 March 2025\n",
      "DOI Link: https://doi.org/10.1145/3708359.3712083\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3737873\n",
      "PDF Link: https://dl.acm.org/doi/pdf/10.1145/3737873\n",
      "Title:A Survey on Employing Large Language Models for Text-to-SQL Tasks\n",
      "Authors: LiangShi, ZhengjuTang, NanZhang, XiaotongZhang, ZhiYang\n",
      "Abstract: With the development of the Large Language Models (LLMs), a large range of LLM-based Text-to-SQL(Text2SQL) methods have emerged. This survey provides a comprehensive review of LLM-based Text2SQL studies. We first enumerate classic benchmarks and evaluation metrics. For the two mainstream methods, prompt engineering and finetuning, we introduce a comprehensive taxonomy and offer practical insights into each subcategory. We present an overall analysis of the above methods and various models evaluated on well-known datasets and extract some characteristics. Finally, we discuss the challenges and future directions in this field.\n",
      "Submission Date: 03 June 2025\n",
      "DOI Link: https://doi.org/10.1145/3737873\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3701551.3707416\n",
      "PDF Link: None\n",
      "Title:The Generalization and Error Detection in LLM-based Text-to-SQL Systems\n",
      "Authors: OlegSomov\n",
      "Abstract: Text-to-SQL systems streamline human-database interactions, improving data retrieval and decision-making. Although large language models (LLMs) can now generate SQL code, challenges with generalization and uncontrolled generation hinder their use in production. Text-to-SQL tasks are particularly sensitive to distribution shifts, where performance declines with unfamiliar database elements or novel queries. Effective systems must maintain quality, measured in terms of generalization (correct processing of novel user requests) and error detection (identification of incorrect generations). This study empirically assesses LLM-based Text-to-SQL systems limitations, defining reliable production scenarios. Current contributions include a cross-lingual generalization research, study on generative model generalization abilities and the quality of selective classification for error detection risk under different distribution shifts in task of Text-to-SQL.\n",
      "Submission Date: 10 March 2025\n",
      "DOI Link: https://doi.org/10.1145/3701551.3707416\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3626772.3657961\n",
      "PDF Link: None\n",
      "Title:Graph Reasoning Enhanced Language Models for Text-to-SQL\n",
      "Authors: ZhengGong, YingSun\n",
      "Abstract: Text-to-SQL parsing has attracted substantial attention recently due to its potential to remove barriers for non-expert end users interacting with databases. A key challenge in Text-to-SQL parsing is developing effective encoding mechanisms to capture the complex relationships between question words, database schemas, and their associated connections within the heterogeneous graph structure. Existing approaches typically introduce some useful multi-hop structures manually and then incorporate them into graph neural networks (GNNs) by stacking multiple layers, which (1) ignore the difficult-to-identify but meaningful semantics embedded in the multi-hop reasoning path, and (2) are limited by the expressive capability of GNN to capture long-range dependencies among the heterogeneous graph. To address these shortcomings, we introduce GRL-SQL, a graph reasoning enhanced language model, which innovatively applies structure encoding to capture the dependencies between node pairs, encompassing one-hop, multi-hop and distance information, subsequently enriched through self-attention for enhanced representational power over GNNs. Furthermore, GRL-SQL incorporates an interaction module that enables joint reasoning and fusion over the question-schema representations for enhancing global context modeling. Comprehensive experiments demonstrate the effectiveness and robustness of our proposed GRL-SQL.\n",
      "Submission Date: 11 July 2024\n",
      "DOI Link: https://doi.org/10.1145/3626772.3657961\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3709719\n",
      "PDF Link: https://dl.acm.org/doi/pdf/10.1145/3709719\n",
      "Title:Reliable Text-to-SQL with Adaptive Abstention\n",
      "Authors: KaiwenChen, YuetingChen, NickKoudas, XiaohuiYu\n",
      "Abstract: Large language models (LLMs) have revolutionized natural language interfaces for databases, particularly in text-to-SQL conversion. However, current approaches often generate unreliable outputs when faced with ambiguity or insufficient context. We present Reliable Text-to-SQL (RTS), a novel framework that enhances query generation reliability by incorporating abstention and human-in-the-loop mechanisms. RTS focuses on the critical schema linking phase, which aims to identify the key database elements needed for generating SQL queries. It autonomously detects potential errors during the answer generation process and responds by either abstaining or engaging in user interaction. A vital component of RTS is the Branching Point Prediction (BPP) which utilizes statistical conformal techniques on the hidden layers of the LLM model for schema linking, providing probabilistic guarantees on schema linking accuracy. We validate our approach through comprehensive experiments on the BIRD benchmark, demonstrating significant improvements in robustness and reliability. Our findings highlight the potential of combining transparent-box LLMs with human-in-the-loop processes to create more robust natural language interfaces for databases. For the BIRD benchmark, our approach achieves near-perfect schema linking accuracy, autonomously involving a human when needed. Combined with query generation, we demonstrate that near-perfect schema linking and a small query generation model can almost match SOTA accuracy achieved with a model orders of magnitude larger than the one we use.\n",
      "Submission Date: 11 February 2025\n",
      "DOI Link: https://doi.org/10.1145/3709719\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3701716.3715257\n",
      "PDF Link: https://dl.acm.org/doi/pdf/10.1145/3701716.3715257\n",
      "Title:RBDQ: A Reliable LLM-based Text-to-SQL System for Business Data Queries\n",
      "Authors: FenglinBi, DongdongCao, ZhiyuWang, YangChen, FangliangZhao, TaoHu, ZhiLi, YanbinZhang, WeiWang\n",
      "Abstract: Using large language models (LLMs) to convert natural language (NL) into SQL simplifies data access for users by allowing them to use everyday language. However, business departments often distrust LLM-based text-to-SQL systems due to the probabilistic nature of SQL generation, which can result in incorrect but executable SQL queries caused by model hallucinations. This leads to significant concerns regarding the accuracy and reliability of the queried data. In this paper, we present RBDQ, a novel LLM-based text-to-SQL system designed to address the unique challenges of business data queries. RBDQ innovatively introduces the Hierarchical Metrics Query Method and integrates advanced Retrieval-Augmented Generation (RAG) methods along with a self-reflection mechanism to tackle these challenges. RBDQ effectively meets the requirements of business metric queries in real-world scenarios. Currently implemented in the Quality Assurance department at ByteDance, RBDQ has significantly improved operational efficiency and query flexibility. Our experiments demonstrate the system's effectiveness, achieving an Execution Accuracy of 96.20%.\n",
      "Submission Date: 23 May 2025\n",
      "DOI Link: https://doi.org/10.1145/3701716.3715257\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3654930\n",
      "PDF Link: None\n",
      "Title:CodeS: Towards Building Open-source Language Models for Text-to-SQL\n",
      "Authors: HaoyangLi, JingZhang, HanbingLiu, JuFan, XiaokangZhang, JunZhu, RenjieWei, HongyanPan, CuipingLi, HongChen\n",
      "Abstract: Language models have shown promising performance on the task of translating natural language questions into SQL queries (Text-to-SQL). However, most of the state-of-the-art (SOTA) approaches rely on powerful yet closed-source large language models (LLMs), such as ChatGPT and GPT-4, which may have the limitations of unclear model architectures, data privacy risks, and expensive inference overheads. To address the limitations, we introduce CodeS, a series of pre-trained language models with parameters ranging from 1B to 15B, specifically designed for the text-to-SQL task. CodeS is a fully open-source language model, which achieves superior accuracy with much smaller parameter sizes. This paper studies the research challenges in building CodeS. To enhance the SQL generation abilities of CodeS, we adopt an incremental pre-training approach using a specifically curated SQL-centric corpus. Based on this, we address the challenges of schema linking and rapid domain adaptation through strategic prompt construction and a bi-directional data augmentation technique. We conduct comprehensive evaluations on multiple datasets, including the widely used Spider benchmark, the newly released BIRD benchmark, robustness-diagnostic benchmarks such as Spider-DK, Spider-Syn, Spider-Realistic, and Dr.Spider, as well as two real-world datasets created for financial and academic applications. The experimental results show that our CodeS achieves new SOTA accuracy and robustness on nearly all challenging text-to-SQL benchmarks.\n",
      "Submission Date: 30 May 2024\n",
      "DOI Link: https://doi.org/10.1145/3654930\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3627673.3679951\n",
      "PDF Link: None\n",
      "Title:Learn From Mistakes: Guidance on Zero-shot Conversational Text-to-SQL\n",
      "Authors: WenshuoZhai, XiangZhao, JinzhiLiao, ZiyangChen\n",
      "Abstract: Large language models (LLMs) possess powerful contextual comprehension capabilities and have demonstrated remarkable success in conversational tasks. However, existing works that apply LLMs to conversational text-to-SQL task have the problem of repetitive mistakes, which results in the failure to bring out the performance of LLMs. In this paper, we propose a novel approach that provides guidance through learning from mistakes. Specifically, the guidance offered by our approach includes tailored suggestions, corrective feedback, and personalized strategies aimed at improving learning outcomes. Furthermore, we employ chain-of-thought (CoT) to utilize guidance that is not suitable directly as prompts. Our method rigorously analyzes actual errors and strategizes on how to utilize the derived guidance effectively. Experimental results demonstrate that our approach improves the state-of-the-art (SOTA) performance metrics, increasing QEX performance from 66.3% to 70.9% (an absolute improvement of 4.6%) and IEX performance from 37.4% to 45.1% (an absolute improvement of 7.7%) on the CoSQL dataset.\n",
      "Submission Date: 21 October 2024\n",
      "DOI Link: https://doi.org/10.1145/3627673.3679951\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3626246.3653375\n",
      "PDF Link: None\n",
      "Title:FinSQL: Model-Agnostic LLMs-based Text-to-SQL Framework for Financial Analysis\n",
      "Authors: ChaoZhang, YurenMao, YijiangFan, YuMi, YunjunGao, LuChen, DongfangLou, JinshuLin\n",
      "Abstract: Text-to-SQL, which provides zero-code interface for operating relational databases, has gained much attention in financial analysis; because financial professionals may not be well-skilled in SQL programming. However, until now, there is no practical Text-to-SQL benchmark dataset for financial analysis, and existing Text-to-SQL methods have not considered the unique characteristics of databases in financial applications, such as commonly existing wide tables. To address these issues, we collect a practical Text-to-SQL benchmark dataset and propose a model-agnostic Large Language Model (LLMs)-based Text-to-SQL framework for financial analysis. The benchmark dataset, BULL, is collected from the practical financial analysis business of Hundsun Technologies Inc., including databases for fund, stock, and macro economy. Besides, the proposed LLMs-based Text-to-SQL framework, FinSQL, provides a systematic treatment for financial Text-to-SQL from the perspectives of prompt construction, parameter-efficient fine-tuning and output calibration. Experiments on BULL demonstrate that FinSQL achieves state-of-the-art performance at low cost, and it brings up to 36.64% improvement in few-shot cross-database scenarios.\n",
      "Submission Date: 09 June 2024\n",
      "DOI Link: https://doi.org/10.1145/3626246.3653375\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3605098.3636065\n",
      "PDF Link: None\n",
      "Title:Ar-Spider: Text-to-SQL in Arabic\n",
      "Authors: SalehAlmohaimeed, SaadAlmohaimeed, MansourAl Ghanim, LiqiangWang\n",
      "Abstract: In Natural Language Processing (NLP), one of the most important tasks is text-to-SQL semantic parsing, which focuses on enabling users to interact with the database in a more natural manner. In recent years, text-to-SQL has made significant progress, but most were English-centric. In this paper, we introduce Ar-Spider 1, the first Arabic cross-domain text-to-SQL dataset. Due to the unique nature of the language, two major challenges have been encountered, namely schema linguistic and SQL structural challenges. In order to handle these issues and conduct the experiments, we adopt two baseline models LGESQL [4] and S2SQL [12], both of which are tested with two cross-lingual models to alleviate the effects of schema linguistic and SQL structure linking challenges. The baselines demonstrate decent single-language performance on our Arabic text-to-SQL dataset, Ar-Spider, achieving 62.48% for S2SQL and 65.57% for LGESQL, only 8.79% below the highest results achieved by the baselines when trained in English dataset. To achieve better performance on Arabic text-to-SQL, we propose the context similarity relationship (CSR) approach, which results in a significant increase in the overall performance of about 1.52% for S2SQL and 1.06% for LGESQL and closes the gap between Arabic and English languages to 7.73%.\n",
      "Submission Date: 21 May 2024\n",
      "DOI Link: https://doi.org/10.1145/3605098.3636065\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3627673.3679216\n",
      "PDF Link: None\n",
      "Title:Demonstration of a Multi-agent Framework for Text to SQL Applications with Large Language Models\n",
      "Authors: ChenShen, JinWang, SajjadurRahman, EserKandogan\n",
      "Abstract: The Text-to-SQL problem aims at developing natural language query interfaces for relational database systems by converting the text input into executable SQL queries. Recently, using Large Language Models (LLM) has emerged as a new paradigm for the Text-to-SQL problem. To this end, the LLM needs to understand not only user input but also information from the database. In this demo, we present multi-agent SQL (MageSQL), an LLM based Text-to-SQL approach that tackles the task by orchestrating multiple agents in a pipeline. We will showcase a user-friendly interface to demonstrate the inner workings of our approach that allows users to add and modify the agents with different functionalities, customize prompts, and see their impact on specific examples. Through several use cases, we will demonstrate how to (i) construct a Text-to-SQL pipeline with multiple agents; (ii) generate prompts for LLM with various templates and strategies; and (iii) monitor the results of natural language queries and perform debugging.\n",
      "Submission Date: 21 October 2024\n",
      "DOI Link: https://doi.org/10.1145/3627673.3679216\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3701716.3715541\n",
      "PDF Link: https://dl.acm.org/doi/pdf/10.1145/3701716.3715541\n",
      "Title:SQLord: A Robust Enterprise Text-to-SQL Solution via Reverse Data Generation and Workflow Decomposition\n",
      "Authors: SongCheng, QiannanCheng, LinboJin, LeiYi, GuannanZhang\n",
      "Abstract: Transforming natural language into SQL queries (NL2SQL) is crucial for data-driven business applications. Existing frameworks, trained on open-source datasets, struggle with complex business logic and lack domain-specific data for fine-tuning. Additionally, evaluation methods often require annotated data and executable database environments, which are scarce in real-world scenarios. To address these challenges, we propose SQLord, an enterprise-level NL2SQL framework. First, SQLord introduces a data reverse generation approach to convert raw SQL statements into annotated data for supervised fine-tuning (SFT). Second, it proposes a decomposition method for complex queries using an automated workflow generator. Additionally, SQLord features a comprehensive GPT-Judge evaluation framework, including Execution Evaluation (EXE), Query-SQL Evaluation (QSE), and SQL-SQL Evaluation (SSE), tailored to diverse scenarios. Offline tests significantly outperform state-of-the-art baselines, and online accuracy consistently exceeds 90, highlighting SQLord's advantages and effectiveness in complex real-world scenarios. SQLord has been successfully applied across multiple scenarios on the world's largest B2B e-commerce platform.\n",
      "Submission Date: 23 May 2025\n",
      "DOI Link: https://doi.org/10.1145/3701716.3715541\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3639477.3639732\n",
      "PDF Link: https://dl.acm.org/doi/pdf/10.1145/3639477.3639732\n",
      "Title:Enhancing Text-to-SQL Translation for Financial System Design\n",
      "Authors: YeweiSong, SaadEzzini, XunzhuTang, CedricLothritz, JacquesKlein, TegawendeBissyande, AndreyBoytsov, UlrickBle, AnneGoujon\n",
      "Abstract: Text-to-SQL, the task of translating natural language questions into SQL queries, is part of various business processes. Its automation, which is an emerging challenge, will empower software practitioners to seamlessly interact with relational databases using natural language, thereby bridging the gap between business needs and software capabilities. In this paper, we consider Large Language Models (LLMs), which have achieved state of the art for various NLP tasks. Specifically, we benchmark Text-to-SQL performance, the evaluation methodologies, as well as input optimization (e.g., prompting). In light of the empirical observations that we have made, we propose two novel metrics that were designed to adequately measure the similarity between SQL queries. Overall, we share with the community various findings, notably on how to select the right LLM on Text-to-SQL tasks. We further demonstrate that a tree-based edit distance constitutes a reliable metric for assessing the similarity between generated SQL queries and the oracle for benchmarking Text2SQL approaches. This metric is important as it relieves researchers from the need to perform computationally expensive experiments such as executing generated queries as done in prior works. Our work implements financial domain use cases and, therefore contributes to the advancement of Text2SQL systems and their practical adoption in this domain.\n",
      "Submission Date: 31 May 2024\n",
      "DOI Link: https://doi.org/10.1145/3639477.3639732\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3589292\n",
      "PDF Link: None\n",
      "Title:Few-shot Text-to-SQL Translation using Structure and Content Prompt Learning\n",
      "Authors: ZihuiGu, JuFan, NanTang, LeiCao, BowenJia, SamMadden, XiaoyongDu\n",
      "Abstract: A common problem with adopting Text-to-SQL translation in database systems is poor generalization. Specifically, when there is limited training data on new datasets, existing few-shot Text-to-SQL techniques, even with carefully designed textual prompts on pre-trained language models (PLMs), tend to be ineffective. In this paper, we present a divide-and-conquer framework to better support few-shot Text-to-SQL translation, which divides Text-to-SQL translation into two stages (or sub-tasks), such that each sub-task is simpler to be tackled. The first stage, called the structure stage, steers a PLM to generate an SQL structure (including SQL commands such as SELECT, FROM, WHERE and SQL operators such as <\", ?>\") with placeholders for missing identifiers. The second stage, called the content stage, guides a PLM to populate the placeholders in the generated SQL structure with concrete values (including SQL identifies such as table names, column names, and constant values). We propose a hybrid prompt strategy that combines learnable vectors and fixed vectors (i.e., word embeddings of textual prompts), such that the hybrid prompt can learn contextual information to better guide PLMs for prediction in both stages. In addition, we design keyword constrained decoding to ensure the validity of generated SQL structures, and structure guided decoding to guarantee the model to fill correct content. Extensive experiments, by comparing with ten state-of-the-art Text-to-SQL solutions at the time of writing, show that SC-Prompt significantly outperforms them in the few-shot scenario. In particular, on the widely-adopted Spider dataset, given less than 500 labeled training examples (5% of the official training set), SC-Prompt outperforms the previous SOTA methods by around 5% on accuracy.\n",
      "Submission Date: 20 June 2023\n",
      "DOI Link: https://doi.org/10.1145/3589292\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3582768.3582782\n",
      "PDF Link: None\n",
      "Title:Measuring Text-to-SQL Semantic Parsing Model on the Question Generalizability\n",
      "Authors: ThanakritJulavanich, AkikoAizawa\n",
      "Abstract: One of the challenges in NLP tasks, such as text-to-SQL semantic parsing, is generalization. In the text-to-SQL task, having separate training and testing data can measure one aspect of the generalization: how well the model generalizes to unseen databases. Other aspects, however, remain unaccounted for. We propose a new dataset and a more challenging and thorough evaluation process that focuses on the two challenges of generalizing the text-to-SQL model: database content references and question patterns. We create SPIDER-QG, an augmented dataset that employs three techniques, to assess generalizability. First, we replace the set of values in the existing test set with other values from the same column in the same database. Second, we use the synonym of each value as a replacement instead. Third, we generate new questions for the existing SQL query by back-translating the original question. Our evaluation setup demonstrates the generalization challenges and struggles of the current models.\n",
      "Submission Date: 27 June 2023\n",
      "DOI Link: https://doi.org/10.1145/3582768.3582782\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3622896.3622906\n",
      "PDF Link: None\n",
      "Title:Instruction Tuning Text-to-SQL with Large Language Models in the Power Grid Domain\n",
      "Authors: GangSun, RanShen, LiangfengJin, YifanWang, ShiyuXu, JinpengChen, WeihaoJiang\n",
      "Abstract: This paper explores the large language models to address the Text-to-SQL task in real-world scenarios in the electricity domain. To tackle the lack of training data and corresponding databases for vertical domain real-world scenarios, the paper devised specific prompts to leverage ChatGPT for data generation, achieving significant improvements in annotation efficiency through automated data generation. Furthermore, to apply the powerful semantic parsing and generation capabilities of large language models to Text-to-SQL, the paper utilized a large language model for instruction tuning for SQL generation. This model has undergone secondary pre-training with electrical knowledge, tailoring it to the specific SQL generation task. On the power grid test set, the paper’s matching accuracy reached 65.7%, and the execution accuracy reached 80.9%. Additionally, the paper conducted further tests on various general large language models for zero-shot learning and single-sample prompt-based Text-to-SQL. The results indicate that while simple single-table queries can be achieved, meeting the requirements for complex queries remains challenging.\n",
      "Submission Date: 03 October 2023\n",
      "DOI Link: https://doi.org/10.1145/3622896.3622906\n",
      "Processing link: https://dl.acm.org/doi/10.14778/3641204.3641221\n",
      "PDF Link: None\n",
      "Title:Text-to-SQL Empowered by Large Language Models: A Benchmark Evaluation\n",
      "Authors: DaweiGao, HaibinWang, YaliangLi, XiuyuSun, YichenQian, BolinDing, JingrenZhou\n",
      "Abstract: Large language models (LLMs) have emerged as a new paradigm for Text-to-SQL task. However, the absence of a systematical benchmark inhibits the development of designing effective, efficient and economic LLM-based Text-to-SQL solutions. To address this challenge, in this paper, we first conduct a systematical and extensive comparison over existing prompt engineering methods, including question representation, example selection and example organization, and with these experimental results, we elaborate their pros and cons. Based on these findings, we propose a new integrated solution, named DAIL-SQL, which refreshes the Spider leaderboard with 86.6% execution accuracy and sets a new bar. To explore the potential of open-source LLM, we investigate them in various scenarios, and further enhance their performance with supervised fine-tuning. Our explorations highlight open-source LLMs' potential in Text-to-SQL, as well as the advantages and disadvantages of the supervised fine-tuning. Additionally, towards an efficient and economic LLM-based Text-to-SQL solution, we emphasize the token efficiency in prompt engineering and compare the prior studies under this metric. We hope that our work provides a deeper understanding of Text-to-SQL with LLMs, and inspires further investigations and broad applications.\n",
      "Submission Date: 01 January 2024\n",
      "DOI Link: https://doi.org/10.14778/3641204.3641221\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3690931.3691010\n",
      "PDF Link: None\n",
      "Title:TFFSQL:Enhancing Graph Neural Network through Text Feature Fusion for Text-to-SQL\n",
      "Authors: YaozhenHe, EnpeiHuang, RongzhiQi\n",
      "Abstract: In text-to-SQL, generating accurate SQL queries is crucial. Existing methods that rely on Graph Neural Networks (GNN) still fall short in capturing complex semantic and relational information. We propose TFFSQL, which obtains the textual information of natural language questions as node features and integrates them with the original node features. It also adopts segmentation processing to handle long queries, generates vectors for each segment, and merges them with the node structural features, effectively capturing the semantic information of natural language queries and improving the efficiency and accuracy of the model in processing long queries. An cross-graph attention is introduced in the Relational Graph Attention Network (RGAT). Through the cross-graph attention, the model can dynamically adjust attention weights between the original graph and the line graph, thereby capturing rich relational information. Additionally, TFFSQL also combines recursive decoding with the ASTormer decoder for decoding. Experimental results show that our method outperforms existing GNN-based methods on the Spider dataset, significantly improving the accuracy of SQL query generation.\n",
      "Submission Date: 04 October 2024\n",
      "DOI Link: https://doi.org/10.1145/3690931.3691010\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3579030\n",
      "PDF Link: None\n",
      "Title:Bravely Say I Don’t Know: Relational Question-Schema Graph for Text-to-SQL Answerability Classification\n",
      "Authors: WeiYu, HaiyanYang, MengzhuWang, XiaodongWang\n",
      "Abstract: Recently, the Text-to-SQL task has received much attention. Many sophisticated neural models have been invented that achieve significant results. Most current work assumes that all the inputs are legal and the model should generate an SQL query for any input. However, in the real scenario, users are allowed to enter the arbitrary text that may not be answered by an SQL query. In this article, we focus on the issue–answerability classification for the Text-to-SQL system, which aims to distinguish the answerability of the question according to the given database schema. Existing methods concatenate the question and the database schema into a sentence, then fine-tune the pre-trained language model on the answerability classification task. In this way, the database schema is regarded as sequence text that may ignore the intrinsic structure relationship of the schema data, and the attention that represents the correlation between the question token and the database schema items is not well designed. To this end, we propose a relational Question-Schema graph framework that can effectively model the attention and relation between question and schema. In addition, a conditional layer normalization mechanism is employed to modulate the pre-trained language model to generate better question representation. Experiments demonstrate that the proposed framework outperforms all existing models by large margins, achieving new state of the art on the benchmark TRIAGESQL. Specifically, the model attains 88.41%, 78.24%, and 75.98% in Precision, Recall, and F1, respectively. Additionally, it outperforms the baseline by approximately 4.05% in Precision, 6.96% in Recall, and 6.01% in F1.\n",
      "Submission Date: 25 March 2023\n",
      "DOI Link: https://doi.org/10.1145/3579030\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3534678.3539294\n",
      "PDF Link: https://dl.acm.org/doi/pdf/10.1145/3534678.3539294\n",
      "Title:Semantic Enhanced Text-to-SQL Parsing via Iteratively Learning Schema Linking Graph\n",
      "Authors: AiweiLiu, XumingHu, LiLin, LijieWen\n",
      "Abstract: The generalizability to new databases is of vital importance to Text-to-SQL systems which aim to parse human utterances into SQL statements. Existing works achieve this goal by leveraging the exact matching method to identify the lexical matching between the question words and the schema items. However, these methods fail in other challenging scenarios, such as the synonym substitution in which the surface form differs between the corresponding question words and schema items. In this paper, we propose a framework named ISESL-SQL to iteratively build a semantic enhanced schema-linking graph between question tokens and database schemas. First, we extract a schema linking graph from PLMs through a probing procedure in an unsupervised manner. Then the schema linking graph is further optimized during the training process through a deep graph learning method. Meanwhile, we also design an auxiliary task called graph regularization to improve the schema information mentioned in the schema-linking graph. Extensive experiments on three benchmarks demonstrate that ISESL-SQL could consistently outperform the baselines and further investigations show its generalizability and robustness.\n",
      "Submission Date: 14 August 2022\n",
      "DOI Link: https://doi.org/10.1145/3534678.3539294\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3448016.3452836\n",
      "PDF Link: None\n",
      "Title:An In-Depth Benchmarking of Text-to-SQL Systems\n",
      "Authors: OrestGkini, TheofilosBelmpas, GeorgiaKoutrika, YannisIoannidis\n",
      "Abstract: Text-to-SQL systems allow users to explore relational databases by posing free-form queries, alleviating the need for using structured languages, such as SQL. Although numerous systems have been developed so far, existing system evaluations lack in rigour. In this work, we build a text-to-SQL benchmark that covers different classes of queries, and we evaluate the effectiveness of several systems in the field. To evaluate system efficiency, we measure execution time and resource consumption for the different query classes. Our comprehensive evaluation aims at filling in a big gap in understanding the capabilities and boundaries of existing systems and it reveals several open challenges.\n",
      "Submission Date: 18 June 2021\n",
      "DOI Link: https://doi.org/10.1145/3448016.3452836\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3448016.3457543\n",
      "PDF Link: None\n",
      "Title:A Deep Dive into Deep Learning Approaches for Text-to-SQL Systems\n",
      "Authors: GeorgeKatsogiannis-Meimarakis, GeorgiaKoutrika\n",
      "Abstract: Data is a prevalent part of every business and scientific domain,but its explosive volume and increasing complexity make data querying challenging even for experts. For this reason, numerous text-to-SQL systems have been developed that enable querying relational databases using natural language. The recent advances on deep neural networks along with the creation of two large datasets specifically made for training text-to-SQL systems, have paved the path for a novel and very promising research area. The purpose of this tutorial is a deep dive into this area, covering state-of-the-art techniques for natural language representation in neural networks,benchmarks that sparked research and competition, recent text-to-SQL systems using deep learning techniques, as well as open problems and research opportunities.\n",
      "Submission Date: 18 June 2021\n",
      "DOI Link: https://doi.org/10.1145/3448016.3457543\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3534678.3539305\n",
      "PDF Link: https://dl.acm.org/doi/pdf/10.1145/3534678.3539305\n",
      "Title:Proton: Probing Schema Linking Information from Pre-trained Language Models for Text-to-SQL Parsing\n",
      "Authors: LihanWang, BowenQin, BinyuanHui, BowenLi, MinYang, BailinWang, BinhuaLi, JianSun, FeiHuang, LuoSi, YongbinLi\n",
      "Abstract: The importance of building text-to-SQL parsers which can be applied to new databases has long been acknowledged, and a critical step to achieve this goal is schema linking, i.e., properly recognizing mentions of unseen columns or tables when generating SQLs. In this work, we propose a novel framework to elicit relational structures from large-scale pre-trained language models (PLMs) via a probing procedure based on Poincaré distance metric, and use the induced relations to augment current graph-based parsers for better schema linking. Compared with commonly-used rule-based methods for schema linking, we found that probing relations can robustly capture semantic correspondences, even when surface forms of mentions and entities differ. Moreover, our probing procedure is entirely unsupervised and requires no additional parameters. Extensive experiments show that our framework sets new state-of-the-art performance on three benchmarks. We empirically verify that our probing procedure can indeed find desired relational structures through qualitative analysis.\n",
      "Submission Date: 14 August 2022\n",
      "DOI Link: https://doi.org/10.1145/3534678.3539305\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3454127.3457619\n",
      "PDF Link: None\n",
      "Title:A review of the Text to SQL Frameworks\n",
      "Authors: KaramAhkouk, MachkourMustapha, MajhadiKhadija, MamaRachid\n",
      "Abstract: The use of relational databases and the extraction of the stored data are generally carried out using queries expressed in a query language such as SQL (Structured Query Language). In particular, people with limited knowledge on databases are unable to write such requests. To resolve this problem, the use of natural language (NL) to interact with these systems will be the easiest alternative. Using natural language interfaces for databases (NLIDB) is the key solution to make the translation of natural languages like English to SQL queries possible. This can help to generalize access to databases for different types of users regardless their technical level of knowledge on SQL. This paper will present a short review of our already proposed framework that deal with Natural Language translation to Database queries.\n",
      "Submission Date: 26 November 2021\n",
      "DOI Link: https://doi.org/10.1145/3454127.3457619\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3511095.3531282\n",
      "PDF Link: https://dl.acm.org/doi/pdf/10.1145/3511095.3531282\n",
      "Title:Exploring the Feasibility of Crowd-Powered Decomposition of Complex User Questions in Text-to-SQL Tasks\n",
      "Authors: SaraSalimzadeh, UjwalGadiraju, ClaudiaHauff, Arievan Deursen\n",
      "Abstract: Natural Language Interfaces to Databases (NLIDB), also known as Text-to-SQL models, enable users with different levels of knowledge in Structured Query Language (SQL) to access relational databases without any programming effort. By translating natural languages into SQL query, not only do NLIDBs minimize the burden of memorizing the schema of databases and writing complex SQL queries, but they also allow non-experts to acquire information from databases in natural languages. However, existing NLIDBs largely fail to translate natural languages to SQL when they are complex, preventing them from being deployed in real-world scenarios and generalizing across unseen complex databases. In this paper, we explored the feasibility of decomposing complex user questions into multiple sub-questions — each with a reduced complexity — as a means to circumvent the problem of complex SQL generation. We investigated the feasibility of decomposing complex user questions in a manner that each sub-question is simple enough for existing NLIDBs to generate correct SQL queries, using non-expert crowd workers in juxtaposition with SQL experts. Through an empirical study on an NLIDB benchmark dataset, we found that crowd-powered decomposition of complex user questions led to an accuracy boost of an existing Text-to-SQL pipeline from 30% to 59% (96% accuracy boost). Similarly, decomposition by SQL experts resulted in boosting the accuracy to 76% (153% accuracy boost). Our findings suggest that crowd-powered decomposition can be a scalable alternative to producing the training data necessary to build machine learning models that can automatically decompose complex user questions, thereby improving Text-to-SQL pipelines.\n",
      "Submission Date: 28 June 2022\n",
      "DOI Link: https://doi.org/10.1145/3511095.3531282\n",
      "Processing link: https://dl.acm.org/doi/10.1109/TASLP.2021.3070726\n",
      "PDF Link: None\n",
      "Title:A Multiple-Integration Encoder for Multi-Turn Text-to-SQL Semantic Parsing\n",
      "Authors: Run-ZeWang, Zhen-HuaLing, Jing-BoZhou, YuHu\n",
      "Abstract: This paper studies multi-turn text-to-SQL generation, which is a new but important task in semantic parsing. In order to deal with its two challenges, i.e., multi-turn interaction and cross-domain evaluation, this paper proposes a multiple-integration encoder, which derives the vector representations of user utterances and database schemas using three custom-designed modules for information integration. First, an utterance representation enhancing module is built to integrate the information of history utterances into the representation of each token in current utterance by attentive selection. Second, a schema discrepancy enhancing module is designed to integrate previous predicted SQL query into the representation of schema items. Third, a latent schema linking module is employed to integrate schema information into utterance representations for better dealing with unseen database schemas. These three modules are all implemented based on a lightweight multi-head attention mechanism, which reduces the number of parameters in conventional multi-head attention. Experimental results on the SParC dataset show that our method achieved better accuracy of multi-turn text-to-SQL generation than the most advanced benchmarks. Further ablations studies and analysis also demonstrate the effectiveness of the three modules designed for information integration in the encoder.\n",
      "Submission Date: 02 April 2021\n",
      "DOI Link: https://doi.org/10.1109/TASLP.2021.3070726\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3366423.3380120\n",
      "PDF Link: None\n",
      "Title:Text-to-SQL Generation for Question Answering on Electronic Medical Records\n",
      "Authors: PingWang, TianShi, Chandan K.Reddy\n",
      "Abstract: Electronic medical records (EMR) contain comprehensive patient information and are typically stored in a relational database with multiple tables. Effective and efficient patient information retrieval from EMR data is a challenging task for medical experts. Question-to-SQL generation methods tackle this problem by first predicting the SQL query for a given question about a database, and then, executing the query on the database. However, most of the existing approaches have not been adapted to the healthcare domain due to a lack of healthcare Question-to-SQL dataset for learning models specific to this domain. In addition, wide use of the abbreviation of terminologies and possible typos in questions introduce additional challenges for accurately generating the corresponding SQL queries. In this paper, we tackle these challenges by developing a deep learning based TRanslate-Edit Model for Question-to-SQL (TREQS) generation, which adapts the widely used sequence-to-sequence model to directly generate the SQL query for a given question, and further performs the required edits using an attentive-copying mechanism and task-specific look-up tables. Based on the widely used publicly available electronic medical database, we create a new large-scale Question-SQL pair dataset, named MIMICSQL, in order to perform the Question-to-SQL generation task in healthcare domain. An extensive set of experiments are conducted to evaluate the performance of our proposed model on MIMICSQL. Both quantitative and qualitative experimental results indicate the flexibility and efficiency of our proposed method in predicting condition values and its robustness to random questions with abbreviations and typos.\n",
      "Submission Date: 20 April 2020\n",
      "DOI Link: https://doi.org/10.1145/3366423.3380120\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3617023.3617035\n",
      "PDF Link: None\n",
      "Title:DBVinci – towards the usage of GPT engine for processing SQL Queries\n",
      "Authors: VanessaCâmara, RayolMendonca-Neto, AndréSilva, LuizCordovil-Jr\n",
      "Abstract: One of the goals of Natural Language Processing (NLP) is transforming sentences to output relevant information in a given context. For instance, relevant applications such as chatbots, translation systems, and sentiment analysis classifiers work that way. The advance of NLP techniques made it possible to automate complex tasks, such as converting text queries to tabular data queries, specifically SQL, to return contextualized data. Since it is crucial in many areas to interpret the data to obtain information and consider the particularities of a text-to-SQL parser, we propose a SQL processing engine whose internals are customized with natural language instructions. DBVinci is our proposed processing model which is based on OpenAI’s GPT-3.5 Text-davinci-003 engine that can perform language tasks such as text-to-SQL, consistent instruction-following, and supports inserting completions within text. Our framework is on top of GPT-3.5 and decomposes complex SQL queries into a series of simple processing steps, described in natural language. DBVinci outperforms well-known text-to-SQL methods (e.g., RAT-SQL and SQLOVA) reaching 89.7% of execution accuracy, considering WikiSQL benchmark. We also obtain impressive performance without the need of large scale annotated dataset for fine-tuning the downstream task, by achieving 90% accuracy in zero-shot setting. Therefore, we conclude that to obtain competitive results using the Pre-trained Language Model (PLM), there is no need of the “pre-training+fine-tuning” paradigm, besides that, when employing zero-shot in the proposed method, we can achieve promising results.\n",
      "Submission Date: 23 October 2023\n",
      "DOI Link: https://doi.org/10.1145/3617023.3617035\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3579654.3579656\n",
      "PDF Link: None\n",
      "Title:Retrieval Augmented via Execution Guidance in Open-domain Table QA\n",
      "Authors: SiqinChen, YuboLiu, JieWu, MengshuHou\n",
      "Abstract: The goal of the open-domain table QA task is to answer a question based on retrieving and extracting information from a large corpus of structured tables. Currently, the accuracy of the most popular framework in open-domain QA: the two-stage retrieval, is limited by the table retriever. Inspired by the research on Text-to-SQL, this paper proposes to use execution guidance to enhance the effect of table retrieval. Our contributions are mainly threefold: 1. Proposed using execution-guided method to enhance table retrieval to fully leveraging schema information of tables. 2. Proposed the pure Text-to-SQL task for open domains. We design a two-stage Table QA framework based on semantic parsing to generate logical forms and answers simultaneously. 3. Proposed an open-domain Text-to-SQL dataset: Open-domain WikiSQL. We change the original WikiSQL to become suitable for the Open-domain setting, by removing the approximate tables, decontextualizing the questions, etc. We conducted experiments on the new dataset using BM25 and DPR as the retriever, and HydraNet as the generator of SQL. The results show that the execute-guided significantly improves the table retrieval by 19% (DPR in hit@1) and achieves good performance (accuracy of logical form and execution improves by 12.7% and 13.1%) on end-to-end open-domain Text-to-SQL tasks as well.\n",
      "Submission Date: 14 March 2023\n",
      "DOI Link: https://doi.org/10.1145/3579654.3579656\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3539597.3572728\n",
      "PDF Link: https://dl.acm.org/doi/pdf/10.1145/3539597.3572728\n",
      "Title:Data Democratisation with Deep Learning: The Anatomy of a Natural Language Data Interface\n",
      "Authors: GeorgeKatsogiannis-Meimarakis, MikeXydas, GeorgiaKoutrika\n",
      "Abstract: In the age of the Digital Revolution, almost all human activities, from industrial and business operations to medical and academic research, are reliant on the constant integration and utilisation of ever-increasing volumes of data. However, the explosive volume and complexity of data makes data querying and exploration challenging even for experts, and makes the need to democratise the access to data, even for non-technical users, all the more evident. It is time to lift all technical barriers, by empowering users to access relational databases through conversation. We consider 3 main research areas that a natural language data interface is based on: Text-to-SQL, SQL-to-Text, and Data-to-Text. The purpose of this tutorial is a deep dive into these areas, covering state-of-the-art techniques and models, and explaining how the progress in the deep learning field has led to impressive advancements. We will present benchmarks that sparked research and competition, and discuss open problems and research opportunities with one of the most important challenges being the integration of these 3 research areas into one conversational system.\n",
      "Submission Date: 27 February 2023\n",
      "DOI Link: https://doi.org/10.1145/3539597.3572728\n",
      "Processing link: https://dl.acm.org/doi/10.14778/3681954.3682017\n",
      "PDF Link: None\n",
      "Title:Generating Succinct Descriptions of Database Schemata for Cost-Efficient Prompting of Large Language Models\n",
      "Authors: ImmanuelTrummer\n",
      "Abstract: Using large language models (LLMs) for tasks like text-to-SQL translation often requires describing the database schema as part of the model input. LLM providers typically charge as a function of the number of tokens read. Hence, reducing the length of the schema description saves money at each model invocation. This paper introduces Schemonic, a system that automatically finds concise text descriptions of relational database schemata. By introducing abbreviations or grouping schema elements with similar properties, Schemonic typically finds descriptions that use significantly fewer tokens than naive schema representations. Internally, Schemonic models schema compression as a combinatorial optimization problem and uses integer linear programming solvers to find guaranteed optimal or near-optimal solutions. It speeds up optimization by starting optimization from heuristic solutions and reducing the search space size via pre-processing. The experiments on TPC-H, SPIDER, and Public-BI demonstrate that Schemonic reduces schema description length significantly, along with fees for reading them, without reducing the accuracy in tasks such as text-to-SQL translation.\n",
      "Submission Date: 01 July 2024\n",
      "DOI Link: https://doi.org/10.14778/3681954.3682017\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3511808.3557703\n",
      "PDF Link: None\n",
      "Title:SpCQL: A Semantic Parsing Dataset for Converting Natural Language into Cypher\n",
      "Authors: AiboGuo, XinyiLi, GuanchenXiao, ZhenTan, XiangZhao\n",
      "Abstract: The Neo4j query language Cypher enables efficient querying for graphs and has become the most popular graph database language. Due to its complexities, semantic parsing (similar to Text-to-SQL) that translates natural language queries to Cypher becomes highly desirable. We propose the first Text-to-CQL dataset, SpCQL, which contains one Neo4j graph database, 10,000 manually annotated natural language queries and the matching Cypher queries (CQL). Correspondingly, based on this dataset, we define a new semantic parsing task Text-to-CQL. The Text-to-CQL task differs from the traditional Text-to-SQL task due to CQL being more flexible and versatile, especially for schema queries, which brings precedented challenges for the translation process. Although current SOTA Text-to-SQL models utilize SQL schema and contents, they do not scale up to large-scale graph databases. Besides, due to the absence of the primary and foreign keys in Cypher, which are essential for the multi-table Text-to-SQL task, existing Text-to-SQL models are rendered ineffective in this new task and have to be adapted to work. We propose three baselines based on the Seq2Seq framework and conduct experiments on the SpCQL dataset. The experiments yield undesirable results for existing models, hence pressing for subsequent research that considers the characteristics of SQL. The dataset is available at https://github.com/Guoaibo/Text-to-CQL.\n",
      "Submission Date: 17 October 2022\n",
      "DOI Link: https://doi.org/10.1145/3511808.3557703\n",
      "Processing link: https://dl.acm.org/doi/10.14778/3685800.3685876\n",
      "PDF Link: None\n",
      "Title:Demonstration of DB-GPT: Next Generation Data Interaction System Empowered by Large Language Models\n",
      "Authors: SiqiaoXue, DanruiQi, CaigaoJiang, FangyinCheng, KetingChen, ZhipingZhang, HongyangZhang, GanglinWei, WangZhao, FanZhou, HongYi, ShaodongLiu, HongjunYang, FaqiangChen\n",
      "Abstract: The recent breakthroughs in large language models (LLMs) are positioned to transition many areas of software. In this paper, we present DB-GPT, a revolutionary and product-ready Python library that integrates LLMs into traditional data interaction tasks to enhance user experience and accessibility. DB-GPT is designed to understand data interaction tasks described by natural language and provide context-aware responses powered by LLMs, making it an indispensable tool for users ranging from novice to expert. Its system design supports deployment across local, distributed, and cloud environments. Beyond handling basic data interaction tasks like Text-to-SQL with LLMs, it can handle complex tasks like generative data analysis through a Multi-Agents framework and the Agentic Workflow Expression Language (AWEL). The Service-oriented Multi-model Management Framework (SMMF) ensures data privacy and security, enabling users to employ DB-GPT with private LLMs. Additionally, DB-GPT offers a series of product-ready features designed to enable users to integrate DB-GPT within their product environments easily. The code of DB-GPT is available at Github.\n",
      "Submission Date: 01 August 2024\n",
      "DOI Link: https://doi.org/10.14778/3685800.3685876\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3584371.3613008\n",
      "PDF Link: https://dl.acm.org/doi/pdf/10.1145/3584371.3613008\n",
      "Title:Text-to-ESQ: A Two-Stage Controllable Approach for Efficient Retrieval of Vaccine Adverse Events from NoSQL Database\n",
      "Authors: WenlongZhang, KangpingZeng, XinmingYang, TianShi, PingWang\n",
      "Abstract: The Vaccine Adverse Event Reporting System (VAERS) contains detailed reports of adverse events following vaccine administration. However, efficiently and accurately searching for specific information from VAERS poses significant challenges, especially for medical experts. Natural language querying (NLQ) methods tackle the challenge by translating the input questions into executable queries, allowing for the exploration of complex databases with large amounts of information. Most existing studies focus on the relational database and solve the Text-to-SQL task. However, the capability of full-text for Text-to-SQL is greatly limited by the data structures and functionality of the SQL databases. In addition, the potential of natural language querying has not been comprehensively explored in the healthcare domain. To overcome these limitations, we investigate the potential of NoSQL databases, specifically Elasticsearch, and forge a new research direction for NLQ, which we refer to as Text-to-ESQ generation. This exploration requires us to re-design various aspects of NLQ, such as the target application and the advantages of NoSQL database. In our approach, we develop a two-stage controllable (TSC) framework consisting of a question-to-question (Q2Q) translation module and an ESQ condition extraction (ECE) module. These modules are carefully designed to efficiently retrieve information from the VEARS data stored in a NoSQL database. Additionally, we construct a dedicated question-ESQ pair dataset called VAERSESQ, to support the task in the healthcare domain. Extensive experiments were conducted on the VAERSESQ dataset to evaluate the proposed methods. The results, both quantitative and qualitative, demonstrate the accuracy and efficiency of our approach in generating queries for NoSQL databases, thus enabling efficient retrieval of VEARS data.\n",
      "Submission Date: 04 October 2023\n",
      "DOI Link: https://doi.org/10.1145/3584371.3613008\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3627673.3679100\n",
      "PDF Link: None\n",
      "Title:On the Use of Large Language Models for Table Tasks\n",
      "Authors: YuyangDong, MasafumiOyamada, ChuanXiao, HaochenZhang\n",
      "Abstract: The proliferation of large language models (LLMs) has catalyzed a diverse array of applications. This tutorial delves into the application of LLMs for tabular data and targets a variety of table-related tasks, such as table understanding, text-to-SQL conversion, and tabular data preprocessing. It surveys LLM solutions to these tasks in five classes, categorized by their underpinning techniques: prompting, fine-tuning, RAG, agents, and multimodal methods. It discusses how LLMs offer innovative ways to interpret, augment, query, and cleanse tabular data, featuring academic contributions and their practical use in the industrial sector. It emphasizes the versatility and effectiveness of LLMs in handling complex table tasks, showcasing their ability to improve data quality, enhance analytical capabilities, and facilitate more intuitive data interactions. By surveying different approaches, this tutorial highlights the strengths of LLMs in enriching table tasks with more accuracy and usability, setting a foundation for future research and application in data science and AI-driven analytics. Presentation slides for this tutorial will be available at: https://dongyuyang.github.io/tableLLM-tutorial/ .\n",
      "Submission Date: 21 October 2024\n",
      "DOI Link: https://doi.org/10.1145/3627673.3679100\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3661304.3661901\n",
      "PDF Link: None\n",
      "Title:A Benchmark to Understand the Role of Knowledge Graphs on Large Language Model's Accuracy for Question Answering on Enterprise SQL Databases\n",
      "Authors: JuanSequeda, DeanAllemang, BryonJacob\n",
      "Abstract: Enterprise applications of Large Language Models (LLMs) hold promise for question answering on enterprise SQL databases. However, the extent to which LLMs can accurately respond to enterprise questions in such databases remains unclear, given the absence of suitable Text-to-SQL benchmarks tailored to enterprise settings. Additionally, the potential of Knowledge Graphs (KGs) to enhance LLM-based question answering by providing business context is not well understood. This study aims to evaluate the accuracy of LLM-powered question answering systems in the context of enterprise questions and SQL databases, while also exploring the role of knowledge graphs in improving accuracy. To achieve this, we introduce a benchmark comprising an enterprise SQL schema in the insurance domain, a range of enterprise queries encompassing reporting to metrics, and a contextual layer incorporating an ontology and mappings that define a knowledge graph. Our primary finding reveals that question answering using GPT-4, with zero-shot prompts directly on SQL databases, achieves an accuracy of 16%. Notably, this accuracy increases to 54% when questions are posed over a Knowledge Graph representation of the enterprise SQL database. Therefore, investing in Knowledge Graph provides higher accuracy for LLM powered question answering systems.\n",
      "Submission Date: 09 June 2024\n",
      "DOI Link: https://doi.org/10.1145/3661304.3661901\n",
      "Processing link: https://dl.acm.org/doi/10.14778/3654621.3654640\n",
      "PDF Link: None\n",
      "Title:ZeroEA: A Zero-Training Entity Alignment Framework via Pre-Trained Language Model\n",
      "Authors: NanHuo, ReynoldCheng, BenKao, WentaoNing, Nur Al HasanHaldar, XiaodongLi, JinyangLi, Mohammad MatinNajafi, TianLi, GeQu\n",
      "Abstract: Entity alignment (EA), a crucial task in knowledge graph (KG) research, aims to identify equivalent entities across different KGs to support downstream tasks like KG integration, text-to-SQL, and question-answering systems. Given rich semantic information within KGs, pre-trained language models (PLMs) have shown promise in EA tasks due to their exceptional context-aware encoding capabilities. However, the current solutions based on PLMs encounter obstacles such as the need for extensive training, expensive data annotation, and inadequate incorporation of structural information. In this study, we introduce a novel zero-training EA framework, ZeroEA, which effectively captures both semantic and structural information for PLMs. To be specific, Graph2Prompt module serves as the bridge between graph structure and plain text by converting KG topology into textual context suitable for PLM input. Additionally, in order to provide PLMs with concise and clear input text of reasonable length, we design a motif-based neighborhood filter to eliminate noisy neighbors. The comprehensive experiments and analyses on 5 benchmark datasets demonstrate the effectiveness of ZeroEA, outperforming all leading competitors and achieving state-of-the-art performance in entity alignment. Notably, our study highlights the considerable potential of EA technique in improving the performance of downstream tasks, thereby benefitting the broader research field.\n",
      "Submission Date: 01 March 2024\n",
      "DOI Link: https://doi.org/10.14778/3654621.3654640\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3665939.3665969\n",
      "PDF Link: None\n",
      "Title:LLMs as an Interactive Database Interface for Designing Large Queries\n",
      "Authors: YilinLi, DeddyJobson\n",
      "Abstract: Text2SQL is typically considered a one-shot process where the user gives a natural language query and receives an SQL query in return. This approach is fraught with potential concerns, such as syntactical errors, logical mismatches, and schema hallucination, which often require time-consuming validations by end users. These challenges are exacerbated by the complexity of large queries typical in industry settings and the inherent ambiguity of natural language. To address these limitations, we propose a system that employs an iterative process for both query creation and validation, ensuring that the resulting data set meets the user's expectations. We tested this system against existing text-to-SQL LLM approaches using a standard industry use case, showcasing our system's ability to deliver coherent and accurate outcomes. Opportunities for future research to further refine this approach are also discussed1.\n",
      "Submission Date: 18 June 2024\n",
      "DOI Link: https://doi.org/10.1145/3665939.3665969\n",
      "Processing link: https://dl.acm.org/doi/10.14778/3611540.3611575\n",
      "PDF Link: None\n",
      "Title:Natural Language Interfaces for Databases with Deep Learning\n",
      "Authors: GeorgeKatsogiannis-Meimarakis, MikeXydas, GeorgiaKoutrika\n",
      "Abstract: In the age of the Digital Revolution, almost all human activities, from industrial and business operations to medical and academic research, are reliant on the constant integration and utilisation of ever-increasing volumes of data. However, the explosive volume and complexity of data makes data querying and exploration challenging even for experts, and makes the need to democratise the access to data, even for non-technical users, all the more evident. It is time to lift all technical barriers, by empowering users to access relational databases through conversation. We consider 3 main research areas that a natural language data interface is based on: Text-to-SQL, SQL-to-Text, and Data-to-Text. The purpose of this tutorial is a deep dive into these areas, covering state-of-the-art techniques and models, and explaining how the progress in the deep learning field has led to impressive advancements. We will present benchmarks that sparked research and competition, and discuss open problems and research opportunities with one of the most important challenges being the integration of these 3 research areas into one conversational system.\n",
      "Submission Date: 01 August 2023\n",
      "DOI Link: https://doi.org/10.14778/3611540.3611575\n",
      "Processing link: https://dl.acm.org/doi/10.14778/3685800.3685816\n",
      "PDF Link: None\n",
      "Title:AutoTQA: Towards Autonomous Tabular Question Answering through Multi-Agent Large Language Models\n",
      "Authors: Jun-PengZhu, PengCai, KaiXu, LiLi, YishenSun, ShuaiZhou, HaihuangSu, LiuTang, QiLiu\n",
      "Abstract: With the growing significance of data analysis, several studies aim to provide precise answers to users' natural language questions from tables, a task referred to as tabular question answering (TQA). The state-of-the-art TQA approaches are limited to handling only single-table questions. However, real-world TQA problems are inherently complex and frequently involve multiple tables, which poses challenges in directly extending single-table TQA designs to handle multiple tables, primarily due to the limited extensibility of the majority of single-table TQA methods. This paper proposes AutoTQA, a novel Autonomous Tabular Question Answering framework that employs multi-agent large language models (LLMs) across multiple tables from various systems (e.g., TiDB, BigQuery). AutoTQA comprises five agents: the User, responsible for receiving the user's natural language inquiry; the Planner, tasked with creating an execution plan for the user's inquiry; the Engineer, responsible for executing the plan step-by-step; the Executor, provides various execution environments (e.g., text-to-SQL) to fulfill specific tasks assigned by the Engineer; and the Critic, responsible for judging whether to complete the user's natural language inquiry and identifying gaps between the current results and initial tasks. To facilitate the interaction between different agents, we have also devised agent scheduling algorithms. Furthermore, we have developed LinguFlow, an open-source, low-code visual programming tool, to quickly build and debug LLM-based applications, and to accelerate the creation of various external tools and execution environments. We also implemented a series of data connectors, which allows AutoTQA to access various tables from multiple systems. Extensive experiments show that AutoTQA delivers outstanding performance on four representative datasets.\n",
      "Submission Date: 01 August 2024\n",
      "DOI Link: https://doi.org/10.14778/3685800.3685816\n",
      "Processing link: https://dl.acm.org/doi/10.14778/3685800.3685905\n",
      "PDF Link: None\n",
      "Title:Chat2Data: An Interactive Data Analysis System with RAG, Vector Databases and LLMs\n",
      "Authors: XinyangZhao, XuanheZhou, GuoliangLi\n",
      "Abstract: Traditional data analysis methods require users to write programming codes or issue SQL queries to analyze the data, which are inconvenient for ordinary users. Large language models (LLMs) can alleviate these limitations by enabling users to interact with the data with natural language (NL), e.g., result retrieval and summarization for unstructured data and transforming the NL text to SQL queries or codes for structured data. However, existing LLMs have three limitations: hallucination (due to lacking domain knowledge for vertical domains), high cost for LLM reasoning, and low accuracy for complicated tasks. To address these problems, we propose a prototype, Chat2Data, to interactively analyze the data with natural language. Chat2Data adopts a three-layer method, where the first layer uses Retrieval-Augmented Generation (RAG) to embed domain knowledge in order to address the hallucination problem, the second layer utilizes vector databases to reduce the number of interactions with LLMs so as to improve the performance, and the third layer designs a pipeline agent to decompose a complex task to multiple subtasks and use multiple round reasoning to generate the results in order to improve the accuracy of LLMs. We demonstrate Chat2Data with two real scenarios, unstructured data retrieval and summarization, and natural language-based structured data analysis. The online demo is available at http://vdemo.dbmind.cn.\n",
      "Submission Date: 01 August 2024\n",
      "DOI Link: https://doi.org/10.14778/3685800.3685905\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3514221.3520158\n",
      "PDF Link: None\n",
      "Title:VoiceQuerySystem: A Voice-driven Database Querying System Using Natural Language Questions\n",
      "Authors: YuanfengSong, Raymond Chi-WingWong, XuefangZhao, DiJiang\n",
      "Abstract: With recent development in natural language processing (NLP) and automatic speech recognition (ASR), voice-based interfaces have become a necessity for applications such as chatbots, search engines, and databases. In this demonstration, we introduce VoiceQuerySystem, a voice-based database querying system that enables users to conduct data operations with natural language questions (NLQs). Different from existing voice-based interfaces such as SpeakQL or EchoQuery, which restricts the voice input to be an exact SQL or follow a pre-defined template, VoiceQuerySystem attempts to achieve data manipulation via common NLQs, and thus does not require the user's technical background in SQL language. The underlying techniques in VoiceQuerySystem is a new task named Speech-to-SQL, which aims to understand the semantic in speech and then translate it into SQL queries. We explore two proposed approaches - the cascaded one and the end-to-end (E2E) one towards speech-to-SQL translation. The cascaded method first converts the user's voice-based NLQs into text by a self-developed ASR module, and then conducts downstream SQL generation via a text-to-SQL model (i.e., IRNet). In contrast, the E2E method is a novel neural architecture named SpeechSQLNet designed by us, which converts the speech signals into SQL queries directly without the middle medium as text. Extensive experiments and demonstrations validate the rationale of the speech-to-SQL task and the effectiveness of the proposed SpeechSQLNet model. To the best of our knowledge, this is the first system that provides a voice-based querying functionality on DBMS from common NLQs.\n",
      "Submission Date: 11 June 2022\n",
      "DOI Link: https://doi.org/10.1145/3514221.3520158\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3430984.3431046\n",
      "PDF Link: None\n",
      "Title:ACL-SQL: Generating SQL Queries from Natural Language\n",
      "Authors: RonakKaoshik, RohitPatil, PrakashR, ShauryaAgarawal, NamanJain, MayankSingh\n",
      "Abstract: Relational databases are prevalent in handling large and complex databases; however, writing the SQL queries can be a tedious task for databases. Recent studies for automating the task of translating natural language text to SQL query are not robust to queries having multi-table dependencies. Also, considering the lack of such research in scientific domain, we introduce ACL-SQL, a dataset with complex queries depending on up to five tables and benchmark the dataset on a simple approach. Evaluation shows that our approach is reasonably precise and can be adopted for practical applications. The dataset and codes are available at https://github.com/rohitshantarampatil/sql-nlp.\n",
      "Submission Date: 02 January 2021\n",
      "DOI Link: https://doi.org/10.1145/3430984.3431046\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3448016.3452753\n",
      "PDF Link: None\n",
      "Title:Demonstrating Robust Voice Querying with MUVE: Optimally Visualizing Results of Phonetically Similar Queries\n",
      "Authors: ZiyunWei, ImmanuelTrummer, ConnorAnderson\n",
      "Abstract: Recently proposed voice query interfaces translate voice input into SQL queries. Unreliable speech recognition on top of the intrinsic challenges of text-to-SQL translation makes it hard to reliably interpret user input. We present MUVE (Multiplots for Voice quEries), a system for robust voice querying. MUVE reduces the impact of ambiguous voice queries by filling the screen with multiplots, capturing results of phonetically similar queries. It maps voice input to a probability distribution over query candidates, executes a selected subset of queries, and visualizes their results in a multiplot. Our goal is to maximize probability to show the correct query result. Also, we want to optimize the visualization (e.g., by coloring a subset of likely results) in order to minimize expected time until users find the correct result. Via a user study, we validate a simple cost model estimating the latter overhead. The resulting optimization problem is NP-hard. We propose an exhaustive algorithm, based on integer programming, as well as a greedy heuristic. As shown in a corresponding user study, MUVE enables users to identify accurate results faster, compared to prior work.\n",
      "Submission Date: 18 June 2021\n",
      "DOI Link: https://doi.org/10.1145/3448016.3452753\n",
      "Processing link: https://dl.acm.org/doi/10.14778/3476249.3476289\n",
      "PDF Link: None\n",
      "Title:Robust voice querying with MUVE: optimally visualizing results of phonetically similar queries\n",
      "Authors: ZiyunWei, ImmanuelTrummer, ConnorAnderson\n",
      "Abstract: Recently proposed voice query interfaces translate voice input into SQL queries. Unreliable speech recognition on top of the intrinsic challenges of text-to-SQL translation makes it hard to reliably interpret user input. We present MUVE (Multiplots for Voice quEries), a system for robust voice querying. MUVE reduces the impact of ambiguous voice queries by filling the screen with multiplots, capturing results of phonetically similar queries. It maps voice input to a probability distribution over query candidates, executes a selected subset of queries, and visualizes their results in a multiplot. Our goal is to maximize probability to show the correct query result. Also, we want to optimize the visualization (e.g., by coloring a subset of likely results) in order to minimize expected time until users find the correct result. Via a user study, we validate a simple cost model estimating the latter overhead. The resulting optimization problem is NP-hard. We propose an exhaustive algorithm, based on integer programming, as well as a greedy heuristic. As shown in a corresponding user study, MUVE enables users to identify accurate results faster, compared to prior work.\n",
      "Submission Date: 01 July 2021\n",
      "DOI Link: https://doi.org/10.14778/3476249.3476289\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3459637.3482496\n",
      "PDF Link: None\n",
      "Title:The Primacy of Data in Deep Learning NLP for Conversational AI\n",
      "Authors: MarkJohnson\n",
      "Abstract: Computational Linguistics and Natural Language Processing have changed considerably in the past few decades. Early research focused on representing and using linguistic knowledge in computational processes such as parsers, while these days the field focuses on practically-useful tasks such as information retrieval and chatbots. Currently our Deep Learning models have little to do with linguistic theory For example, the Oracle Digital Assistant is built on top of generic \"Foundation\" Deep Learning models. An intermediate Focusing step adapts these models to specific enterprise domains. Transfer Learning is used to refocus these models onto specific customer-oriented tasks such as Intent Classification, Named Entity Recognition, as well as more advanced models such as text-to-SQL sequence-to-sequence models. These technologies have revolutionised the application of NLP to practical problems with commercial relevance, enabling us to build better systems faster and cheaper than ever before. Linguistic insights aren't gone from the field, however; they play a critical role in data manufacturing and evaluation. This talk explain how we use hundreds of different evaluations to understand the strengths and weaknesses of our models in the Oracle Digital Assistant, and how we automatically use this in hyper-parameter tuning. It also describes areas where additional research is still required before we can claim that NLP has become an engineering field.\n",
      "Submission Date: 30 October 2021\n",
      "DOI Link: https://doi.org/10.1145/3459637.3482496\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3701716.3715484\n",
      "PDF Link: https://dl.acm.org/doi/pdf/10.1145/3701716.3715484\n",
      "Title:AIArena: A Blockchain-Based Decentralized AI Training Platform\n",
      "Authors: ZhipengWang, RuiSun, ElizabethLui, TuoZhou, YizheWen, JiahaoSun\n",
      "Abstract: The rapid advancement of AI has underscored critical challenges in its development and implementation, largely due to centralized control by a few major corporations. This concentration of power intensifies biases within AI models, resulting from inadequate governance and oversight mechanisms. Additionally, it limits public involvement and heightens concerns about the integrity of model generation. Such monopolistic control over data and AI outputs threatens both innovation and fair data usage, as users inadvertently contribute data that primarily benefits these corporations. In this work, we propose AIArena, a blockchain-based decentralized AI training platform designed to democratize AI development and alignment through on-chain incentive mechanisms. AIArena fosters an open and collaborative environment where participants can contribute models and computing resources. Its on-chain consensus mechanism ensures fair rewards for participants based on their contributions. We instantiate and implement AIArena on the public Base blockchain Sepolia testnet, and the evaluation results demonstrate the feasibility of AIArena in real-world applications. Our project page is available at https://train.flock.io/explore.\n",
      "Submission Date: 23 May 2025\n",
      "DOI Link: https://doi.org/10.1145/3701716.3715484\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3701716.3715173\n",
      "PDF Link: https://dl.acm.org/doi/pdf/10.1145/3701716.3715173\n",
      "Title:EFF BI: Effortless Business Intelligence -Text-to-Vis from LLM Agents\n",
      "Authors: VaishnavMuralidharan, Ho Cheng EnBryan, Tan Wee KianJustin, MuhammadReyaaz, SuzannaSia\n",
      "Abstract: Traditional Business Intelligence (BI) tools rely on complex user interfaces and modeling languages, creating significant accessibility barriers for non-technical users. This often forces domain experts to rely on BI developers to translate and refine their requirements, resulting in time-intensive workflows. In this paper, we introduce Eff BI (Effortless Business Intelligence), an open-source, LLM-powered Text-to-Visualization (Text-to-Vis) tool that enables users to retrieve data from enterprise databases, and generate graphs and charts instantly through natural language. Eff BI's open-source architecture supports plug-and-play functionality with proprietary LLMs, ensuring data remains secure within company servers. Our application is fully open-source and accompanied by documentation for both users and future developers. An example of the visualization and corresponding SQL output is shown in Figure 1.\n",
      "Submission Date: 23 May 2025\n",
      "DOI Link: https://doi.org/10.1145/3701716.3715173\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3654777.3676368\n",
      "PDF Link: https://dl.acm.org/doi/pdf/10.1145/3654777.3676368\n",
      "Title:SQLucid: Grounding Natural Language Database Queries with Interactive Explanations\n",
      "Authors: YuanTian, Jonathan K.Kummerfeld, Toby Jia-JunLi, TianyiZhang\n",
      "Abstract: Though recent advances in machine learning have led to significant improvements in natural language interfaces for databases, the accuracy and reliability of these systems remain limited, especially in high-stakes domains. This paper introduces SQLucid, a novel user interface that bridges the gap between non-expert users and complex database querying processes. SQLucid addresses existing limitations by integrating visual correspondence, intermediate query results, and editable step-by-step SQL explanations in natural language to facilitate user understanding and engagement. This unique blend of features empowers users to understand and refine SQL queries easily and precisely. Two user studies and one quantitative experiment were conducted to validate SQLucid’s effectiveness, showing significant improvement in task completion accuracy and user confidence compared to existing interfaces. Our code is available at https://github.com/magic-YuanTian/SQLucid.\n",
      "Submission Date: 11 October 2024\n",
      "DOI Link: https://doi.org/10.1145/3654777.3676368\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3706468.3706491\n",
      "PDF Link: https://dl.acm.org/doi/pdf/10.1145/3706468.3706491\n",
      "Title:Self-service Teacher-facing Learning Analytics Dashboard with Large Language Models\n",
      "Authors: ZuoWang, WeiyueLin, XiaoHu\n",
      "Abstract: With the rise of online learning platforms, the need for effective learning analytics (LA) has become critical for teachers. However, the development of traditional LA dashboards often requires technical expertise and a certain level of data literacy, preventing many teachers from integrating LA dashboards effectively and flexibly into their teaching practice. This paper explores the development of a self-service teacher-facing learning analytics dashboard powered by large language models (LLMs), for improving teaching practices. By leveraging LLMs, the self-service system aims to simplify the implementation of data queries and visualizations, allowing teachers to create personalized LA dashboards using natural languages. This study also investigates the capabilities of LLMs in generating charts for LA dashboards and evaluates the effectiveness of the self-service system through usability tests with 15 teachers. Preliminary findings suggest that LLMs demonstrate high capabilities in generating charts for LA dashboards, and the LLM-powered self-service system can effectively address participating teachers’ pedagogical needs for LA. This research contributes to the ongoing research on the intersection of LLMs and education, emphasizing the potential of self-service systems to empower teachers in daily teaching practices.\n",
      "Submission Date: 03 March 2025\n",
      "DOI Link: https://doi.org/10.1145/3706468.3706491\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3696410.3714920\n",
      "PDF Link: None\n",
      "Title:2D-TPE: Two-Dimensional Positional Encoding Enhances Table Understanding for Large Language Models\n",
      "Authors: Jia-NanLi, JianGuan, WeiWu, ZhengtaoYu, RuiYan\n",
      "Abstract: Tables are ubiquitous across various domains for concisely representing structured information. Empowering large language models (LLMs) to reason over tabular data represents an actively explored direction. However, since typical LLMs only support one-dimensional (1D) inputs, existing methods often flatten the two-dimensional (2D) table structure into a sequence of tokens, which can severely disrupt the spatial relationships and result in an inevitable loss of vital contextual information. In this paper, we first empirically demonstrate the detrimental impact of such flattening operations on the performance of LLMs in capturing the spatial information of tables through two elaborate proxy tasks. Subsequently, we introduce a simple yet effective positional encoding method, termed \"2D-TPE\" (Two-Dimensional Table Positional Encoding), to address this challenge. 2D-TPE enables each attention head to dynamically select a permutation order of tokens within the context for attending to them, where each permutation represents a distinct traversal mode for the table, such as column-wise or row-wise traversal. 2D-TPE effectively mitigates the risk of losing essential spatial information while preserving computational efficiency, thus better preserving the table structure. Extensive experiments across five benchmarks demonstrate that 2D-TPE outperforms strong baselines, underscoring the importance of preserving the table structure for accurate table comprehension. Comprehensive analysis further reveals the substantially better scalability of 2D-TPE to large tables than baselines.\n",
      "Submission Date: 22 April 2025\n",
      "DOI Link: https://doi.org/10.1145/3696410.3714920\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3698204.3716476\n",
      "PDF Link: None\n",
      "Title:Instruct-to-SPARQL: A text-to-SPARQL dataset for training SPARQL Agents\n",
      "Authors: MehdiBen Amor, AlexisStrappazzon, MichaelGranitzer, ElödEgyed-Zsigmond, JelenaMitrović\n",
      "Abstract: The rapid adoption of Large Language Models (LLMs) for search engines and fact-checking platforms necessitates enhancing their output accuracy. Retrieval Augmented Generation (RAG) mitigates hallucinations but requires semantically rich repositories like Wikidata. However, there is a lack of high-quality data to fine-tune LLMs for querying such knowledge bases. To address this gap, we propose a curated dataset with 2,771 unique queries for fine-tuning LLMs to generate accurate and syntactically valid SPARQL queries from natural language instructions. This dataset, customized for interaction with Wikidata, also serves as a robust benchmark for text-to-SPARQL task evaluation. Key findings show that models generally perform better on queries with lower complexity.\n",
      "Submission Date: 29 April 2025\n",
      "DOI Link: https://doi.org/10.1145/3698204.3716476\n",
      "Processing link: https://dl.acm.org/doi/10.14778/3705829.3705832\n",
      "PDF Link: None\n",
      "Title:QueryArtisan: Generating Data Manipulation Codes for Ad-hoc Analysis in Data Lakes\n",
      "Authors: XiuTang, WenhaoLiu, SaiWu, ChangYao, GongshengYuan, ShanshanYing, GangChen\n",
      "Abstract: Query processing over data lakes is a challenging task, often requiring extensive data pre-processing activities such as data cleaning, transformation, and loading. However, the advent of Large Language Models (LLMs) has illuminated a new pathway to address these complexities by offering a unified approach to understanding the diverse datasets submerged in data lakes. In this paper, we introduce QueryArtisan, a novel LLM-powered analytic tool specifically designed for data lakes. QueryArtisan transcends traditional ETL (Extract, Transform, Load) processes by generating just-intime code for dataset-specific queries. It eliminates the need for an intermediary schema, enabling users to query the data lake directly using natural language. To achieve this, we have developed a suite of heterogeneous operators capable of processing data across various modalities. Additionally, QueryArtisan incorporates a cost model-based query optimization technique, significantly enhancing its code generation capabilities for efficient query resolution. Our extensive experimental evaluations, conducted with real-life datasets, demonstrate that QueryArtisan markedly outperforms existing solutions in terms of effectiveness, efficiency and usability.\n",
      "Submission Date: 01 October 2024\n",
      "DOI Link: https://doi.org/10.14778/3705829.3705832\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3641554.3701932\n",
      "PDF Link: https://dl.acm.org/doi/pdf/10.1145/3641554.3701932\n",
      "Title:A Critical Approach to ChatGPT: An Experience in SQL Learning\n",
      "Authors: LauraFarinetti, LucaCagliero\n",
      "Abstract: ChatGPT potential value in education is broadly recognized and many studies report experiments of its use inside or outside the classroom by students and teachers. On the other hand, the use of ChatGPT rises lots of concerns about well-known problems such as hallucination, plagiarism, overreliance, or misinformation. It is of primary importance to teach students a correct and constructive use of ChatGPT and a critical approach to its returned outputs. The paper presents a classroom experience where students were asked to interact with ChatGPT in the context of a database course. The declared challenge for the students was, given a set of predefined relational database schemata, to invent questions for ChatGPT and try to force wrong SQL solutions. Students had to record the question, the ChatGPT solution, their solution, and the comments about the eventual ChatGPT syntactical and/or semantical errors. This gamification approach was meant to enhance students' motivation, but the main teachers' goal was to make them reflect critically (i) on ChatGPT output, experiencing that it does make mistakes, (ii) on the interpretation of ChatGPT errors, and (iii) on the possible strategies for forcing ChatGPT errors. The experiment involved 166 B.S. students in Engineering and the collected data have been analyzed under different points of view to get an insight into the approach and the critical attitude of the students. The paper reports the results of this analysis and discusses the impact of the activity on learning by analyzing the correlation between students' participation and exam performance.\n",
      "Submission Date: 18 February 2025\n",
      "DOI Link: https://doi.org/10.1145/3641554.3701932\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3637528.3671935\n",
      "PDF Link: None\n",
      "Title:Marrying Dialogue Systems with Data Visualization: Interactive Data Visualization Generation from Natural Language Conversations\n",
      "Authors: YuanfengSong, XuefangZhao, Raymond Chi-WingWong\n",
      "Abstract: Data visualization (DV) has become the prevailing tool in the market due to its effectiveness into illustrating insights in vast amounts of data. To lower the barrier of using DVs, automatic DV tasks, such as natural language question (NLQ) to visualization translation (formally called text-to-vis), have been investigated in the research community. However, text-to-vis assumes the NLQ to be well-organized and expressed in a single sentence. However, in real-world settings, complex DV is needed through consecutive exchanges between the DV system and the users. In this paper, we propose a new task named CoVis, short for <u>Co</u>nversational text-to-<u>Vis</u>ualization, aiming at constructing DVs through a series of interactions between users and the system. Since it is the task which has not been studied in the literature, we first build a benchmark dataset named Dial-NVBench, including dialogue sessions with a sequence of queries from a user and responses from the system. The ultimate goal of each dialogue session is to create a suitable DV. However, this process can contain diverse dialogue queries, such as seeking information about the dataset, manipulating parts of the data, and visualizing the data. Then, we propose a multi-modal neural network named MMCoVisNet to answer these DV-related queries. In particular, MMCoVisNet first fully understands the dialogue context and determines the corresponding responses. Then, it uses adaptive decoders to provide the appropriate replies: (i) a straightforward text decoder is used to produce general responses, (ii) an SQL-form decoder is applied to synthesize data querying responses, and (iii) a DV-form decoder tries to construct the appropriate DVs. We comparatively evaluate MMCoVisNet with other baselines over our proposed benchmark dataset. Experimental results validate that MMCoVisNet performs better than existing baselines and achieves a state-of-the-art performance.\n",
      "Submission Date: 24 August 2024\n",
      "DOI Link: https://doi.org/10.1145/3637528.3671935\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3637528.3671609\n",
      "PDF Link: https://dl.acm.org/doi/pdf/10.1145/3637528.3671609\n",
      "Title:MFTCoder: Boosting Code LLMs with Multitask Fine-Tuning\n",
      "Authors: BingchangLiu, ChaoyuChen, ZiGong, CongLiao, HuanWang, ZhichaoLei, MingLiang, DajunChen, MinShen, HailianZhou, WeiJiang, HangYu, JianguoLi\n",
      "Abstract: Code LLMs have emerged as a specialized research field, with remarkable studies dedicated to enhancing model's coding capabilities through fine-tuning on pre-trained models. Previous fine-tuning approaches were typically tailored to specific downstream tasks or scenarios, which meant separate fine-tuning for each task, requiring extensive training resources and posing challenges in terms of deployment and maintenance. Furthermore, these approaches failed to leverage the inherent interconnectedness among different code-related tasks. To overcome these limitations, we present a multi-task fine-tuning framework, MFTCoder, that enables simultaneous and parallel fine-tuning on multiple tasks. By incorporating various loss functions, we effectively address common challenges in multi-task learning, such as data imbalance, varying difficulty levels, and inconsistent convergence speeds. Extensive experiments have conclusively demonstrated that our multi-task fine-tuning approach outperforms both individual fine-tuning on single tasks and fine-tuning on a mixed ensemble of tasks. Moreover, MFTCoder offers efficient training capabilities, including efficient data tokenization modes and parameter efficient fine-tuning (PEFT) techniques, resulting in significantly improved speed compared to traditional fine-tuning methods. MFTCoder seamlessly integrates with several mainstream open-source LLMs, such as CodeLLama and Qwen. Our MFTCoder fine-tuned CodeFuse-DeepSeek-33B claimed the top spot on the Big Code Models Leaderboard ranked by WinRate as of January 30, 2024. MFTCoder is open-sourced at https://github.com/codefuse-ai/MFTCOder\n",
      "Submission Date: 24 August 2024\n",
      "DOI Link: https://doi.org/10.1145/3637528.3671609\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3626772.3661384\n",
      "PDF Link: https://dl.acm.org/doi/pdf/10.1145/3626772.3661384\n",
      "Title:Large Language Models for Tabular Data: Progresses and Future Directions\n",
      "Authors: HaoyuDong, ZhiruoWang\n",
      "Abstract: Tables contain a significant portion of the world's structured information. The ability to efficiently and accurately understand, process, reason about, analyze, and generate tabular data is critical for achieving Artificial General Intelligence (AGI) systems. However, despite their prevalence and importance, tables present unique challenges due to their structured nature and the diverse semantics embedded within them. Textual content, numerical values, visual formats, and even formulas in tables carry rich semantic information that is often underutilized due to the complexity of accurately interpreting and integrating. Fortunately, the advent of Large Language Models (LLMs) has opened new frontiers in natural language processing (NLP) and machine learning (ML), showing remarkable success in understanding and generating text, code, etc. Applying these advanced models to the domain of tabular data holds the promise of significant breakthroughs in how we process and leverage structured information. Therefore, this tutorial aims to provide a comprehensive study of the advances, challenges, and opportunities in leveraging cutting-edge LLMs for tabular data. By introducing methods of prompting or training cutting-edge LLMs for table interpreting, processing, reasoning, analytics, and generation, we aim to equip researchers and practitioners with the knowledge and tools needed to unlock the full potential of LLMs for tabular data in their domains.\n",
      "Submission Date: 11 July 2024\n",
      "DOI Link: https://doi.org/10.1145/3626772.3661384\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3654777.3676462\n",
      "PDF Link: https://dl.acm.org/doi/pdf/10.1145/3654777.3676462\n",
      "Title:FathomGPT: A natural language interface for interactively exploring ocean science data\n",
      "Authors: NabinKhanal, Chun MengYu, Jui-ChengChiu, AnavChaudhary, ZiyueZhang, KakaniKatija, Angus G.Forbes\n",
      "Abstract: We introduce FathomGPT, an open source system for the interactive investigation of ocean science data via a natural language interface. FathomGPT was developed in close collaboration with marine scientists to enable researchers to explore and analyze the FathomNet image database. FathomGPT provides a custom information retrieval pipeline that leverages OpenAI’s large language models to enable: the creation of complex queries to retrieve images, taxonomic information, and scientific measurements; mapping common names and morphological features to scientific names; generating interactive charts on demand; and searching by image or specified patterns within an image. In designing FathomGPT, particular emphasis was placed on enhancing the user’s experience by facilitating free-form exploration and optimizing response times. We present an architectural overview and implementation details of FathomGPT, along with a series of ablation studies that demonstrate the effectiveness of our approach to name resolution, fine tuning, and prompt modification. We also present usage scenarios of interactive data exploration sessions and document feedback from ocean scientists and machine learning experts.\n",
      "Submission Date: 11 October 2024\n",
      "DOI Link: https://doi.org/10.1145/3654777.3676462\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3626111.3628191\n",
      "PDF Link: None\n",
      "Title:Adapting Foundation Models for Operator Data Analytics\n",
      "Authors: ManikantaKotaru\n",
      "Abstract: The complexity of operator networks and myriad of specialized metrics produced by network function providers present a formidable challenge in retrieving and analyzing operator data, a vital component for network operations. This necessitates specialist intervention, which is time-consuming and limits customization. This paper proposes Data Intelligence for Operators Copilot, a natural language interface for retrieval and analytics tasks on operator data, leveraging foundation models. It addresses the challenges posed by operator data through a novel application of semantic search to effectively provide necessary context regarding specialized metrics. The system has outperformed state-of-the-art natural language interfaces for databases, when applied to an operator-specific benchmark dataset of expert-generated representative queries, with 66% execution accuracy.\n",
      "Submission Date: 28 November 2023\n",
      "DOI Link: https://doi.org/10.1145/3626111.3628191\n",
      "Processing link: https://dl.acm.org/doi/10.14778/3632093.3632111\n",
      "PDF Link: None\n",
      "Title:FormaT5: Abstention and Examples for Conditional Table Formatting with Natural Language\n",
      "Authors: MukulSingh, JoséCambronero, SumitGulwani, VuLe, CarinaNegreanu, ElnazNouri, MohammadRaza, GustVerbruggen\n",
      "Abstract: Formatting is an important property in tables for visualization, presentation, and analysis. Spreadsheet software allows users to automatically format their tables by writing data-dependent conditional formatting (CF) rules. Writing such rules is often challenging for users as it requires understanding and implementing the underlying logic. We present FormaT5, a transformer-based model that can generate a CF rule given the target table and a natural language description of the desired formatting logic. We find that user descriptions for these tasks are often under-specified or ambiguous, making it harder for code generation systems to accurately learn the desired rule in a single step. To tackle this problem of under-specification and minimise argument errors, FormaT5 learns to predict placeholders though an abstention objective. These placeholders can then be filled by a second model or, when examples of rows that should be formatted are available, by a programming-by-example system. To evaluate FormaT5 on diverse and real scenarios, we create an extensive benchmark of 1053 CF tasks, containing real-world descriptions collected from four different sources. We release our benchmarks to encourage research in this area. Abstention and filling allow FormaT5 to outperform 8 different neural approaches on our benchmarks, both with and without examples. Our results illustrate the value of building domain-specific learning systems.\n",
      "Submission Date: 01 November 2023\n",
      "DOI Link: https://doi.org/10.14778/3632093.3632111\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3589132.3625597\n",
      "PDF Link: None\n",
      "Title:MaaSDB: Spatial Databases in the Era of Large Language Models (Vision Paper)\n",
      "Authors: JianzhongQi, ZuqingLi, EgemenTanin\n",
      "Abstract: Large language models (LLMs) are advancing rapidly. Such models have demonstrated strong capabilities in learning from large-scale (unstructured) text data and answering user queries. Users do not need to be experts in structured query languages to interact with systems built upon such models. This provides great opportunities to reduce the barrier of information retrieval for the general public. By introducing LLMs into spatial data management, we envisage an LLM-based spatial database system to learn from both structured and unstructured spatial data. Such a system will offer seamless access to spatial knowledge for the users, thus benefiting individuals, business, and government policy makers alike.\n",
      "Submission Date: 22 December 2023\n",
      "DOI Link: https://doi.org/10.1145/3589132.3625597\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3722043\n",
      "PDF Link: https://dl.acm.org/doi/pdf/10.1145/3722043\n",
      "Title:How to Evaluate AI that's Smarter than Us: Exploring three strategies: functional correctness, AI-as-a-judge, and comparative evaluation\n",
      "Authors: ChipHuyen\n",
      "Abstract: Evaluating AI models that surpass human expertise in the task at hand presents unique challenges. These challenges only grow as AI becomes more intelligent. However, the three effective strategies presented in this article exist to address these hurdles. The strategies are: Functional correctness: evaluating AI by how well it accomplishes its intended tasks; AI-as-a-judge: using AI instead of human experts to evaluate AI outputs; and Comparative evaluation: evaluating AI systems in relationship with each other instead of independently.\n",
      "Submission Date: 01 April 2025\n",
      "DOI Link: https://doi.org/10.1145/3722043\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3640544.3645228\n",
      "PDF Link: None\n",
      "Title:Can LLMs Infer Domain Knowledge from Code Exemplars? A Preliminary Study\n",
      "Authors: JiajingGuo, VikramMohanty, HongtaoHao, LiangGou, LiuRen\n",
      "Abstract: As organizations recognize the potential of Large Language Models (LLMs), bespoke domain-specific solutions are emerging, which inherently face challenges of knowledge gaps and contextual accuracy. Prompt engineering techniques such as chain-of-thoughts and few-shot prompting have been proposed to enhance LLMs’ capabilities by dynamically presenting relevant exemplars. Are LLMs able to infer domain knowledge from code exemplars involving similar domain concepts and analyze the data correctly? To investigate this, we curated a synthetic dataset containing 45 tabular databases, each has domain concepts and definitions, natural language data analysis queries, and responses in the form of Python code, visualizations, and insights. Using this dataset, we conducted a within-subjects experiment to evaluate the effectiveness of domain-specific exemplars versus randomly selected, generic exemplars. Our study underscores the significance of tailored exemplars in enhancing LLMs’ accuracy and contextual understanding in domain-specific tasks, paving the way for more intuitive and effective data analysis solutions.\n",
      "Submission Date: 05 April 2024\n",
      "DOI Link: https://doi.org/10.1145/3640544.3645228\n",
      "Processing link: https://dl.acm.org/doi/10.14778/3636218.3636237\n",
      "PDF Link: None\n",
      "Title:Observatory: Characterizing Embeddings of Relational Tables\n",
      "Authors: TianjiCong, MadelonHulsebos, ZhenjieSun, PaulGroth, H. V.Jagadish\n",
      "Abstract: Language models and specialized table embedding models have recently demonstrated strong performance on many tasks over tabular data. Researchers and practitioners are keen to leverage these models in many new application contexts; but limited understanding of the strengths and weaknesses of these models, and the table representations they generate, makes the process of finding a suitable model for a given task reliant on trial and error. There is an urgent need to gain a comprehensive understanding of these models to minimize inefficiency and failures in downstream usage. To address this need, we propose Observatory, a formal framework to systematically analyze embedding representations of relational tables. Motivated both by invariants of the relational data model and by statistical considerations regarding data distributions, we define eight primitive properties, and corresponding measures to quantitatively characterize table embeddings for these properties. Based on these properties, we define an extensible framework to evaluate language and table embedding models. We collect and synthesize a suite of datasets and use Observatory to analyze nine such models. Our analysis provides insights into the strengths and weaknesses of learned representations over tables. We find, for example, that some models are sensitive to table structure such as column order, that functional dependencies are rarely reflected in embeddings, and that specialized table embedding models have relatively lower sample fidelity. Such insights help researchers and practitioners better anticipate model behaviors and select appropriate models for their downstream tasks, while guiding researchers in the development of new models.\n",
      "Submission Date: 01 December 2023\n",
      "DOI Link: https://doi.org/10.14778/3636218.3636237\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3555041.3589724\n",
      "PDF Link: None\n",
      "Title:Fast Natural Language Based Data Exploration with Samples\n",
      "Authors: ShubhamAgarwal, Gromit Yeuk-YinChan, ShaddyGarg, TongYu, SubrataMitra\n",
      "Abstract: The ability to extract insights from large amounts of data in a timely manner is a crucial problem. Exploratory Data Analysis (EDA) is commonly used by analysts to uncover insights using a sequence of SQL commands and associated visualizations. However, in many cases, this process is carried out by non-programmers who must work within tight time constraints, such as in a marketing campaign where a marketer must quickly analyse large amounts of data to reach a target revenue. This paper presents ApproxEDA - a system that combines a natural language processing (NLP) interface for insight discovery with an underlying sample-based EDA engine. The NLP interface can convert high-level questions into contextual SQL queries of the dataset, while the backend EDA engine significantly speeds up insight discovery by selecting the most optimum sample from among many pre-created samples using various sampling strategies. We demonstrate that ApproxEDA addresses two key aspects: converting high-level NLP inputs to contextual SQL and intelligently selecting samples using a reinforcement learning agent. This protects users from diverging from their original intent of analysis, which can occur due to approximation errors in results and visualizations, while still providing optimal latency reduction through the use of samples.\n",
      "Submission Date: 05 June 2023\n",
      "DOI Link: https://doi.org/10.1145/3555041.3589724\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3654975\n",
      "PDF Link: https://dl.acm.org/doi/pdf/10.1145/3654975\n",
      "Title:SchemaPile: A Large Collection of Relational Database Schemas\n",
      "Authors: TillDöhmen, RaduGeacu, MadelonHulsebos, SebastianSchelter\n",
      "Abstract: Access to fine-grained schema information is crucial for understanding how relational databases are designed and used in practice, and for building systems that help users interact with them. Furthermore, such information is required as training data to leverage the potential of large language models (LLMs) for improving data preparation, data integration and natural language querying. Existing single-table corpora such as GitTables provide insights into how tables are structured in-the-wild, but lack detailed schema information about how tables relate to each other, as well as metadata like data types or integrity constraints. On the other hand, existing multi-table (or database schema) datasets are rather small and attribute-poor, leaving it unclear to what extent they actually represent typical real-world database schemas. In order to address these challenges, we present SchemaPile, a corpus of 221,171 database schemas, extracted from SQL files on GitHub. It contains 1.7 million tables with 10 million column definitions, 700 thousand foreign key relationships, seven million integrity constraints, and data content for more than 340 thousand tables. We conduct an in-depth analysis on the millions of schema metadata properties in our corpus, as well as its highly diverse language and topic distribution. In addition, we showcase the potential of \\corpus to improve a variety of data management applications, e.g., fine-tuning LLMs for schema-only foreign key detection, improving CSV header detection and evaluating multi-dialect SQL parsers. We publish the code and data for recreating SchemaPile and a permissively licensed subset SchemaPile-Perm.\n",
      "Submission Date: 30 May 2024\n",
      "DOI Link: https://doi.org/10.1145/3654975\n",
      "Processing link: https://dl.acm.org/doi/10.14778/3551793.3551841\n",
      "PDF Link: None\n",
      "Title:CodexDB: synthesizing code for query processing from natural language instructions using GPT-3 codex\n",
      "Authors: ImmanuelTrummer\n",
      "Abstract: CodexDB enables users to customize SQL query processing via natural language instructions. CodexDB is based on OpenAI's GPT-3 Codex model which translates text into code. It is a framework on top of GPT-3 Codex that decomposes complex SQL queries into a series of simple processing steps, described in natural language. Processing steps are enriched with user-provided instructions and descriptions of database properties. Codex translates the resulting text into query processing code. An early prototype of CodexDB is able to generate correct code for up to 81% of queries for the WikiSQL benchmark and for up to 62% on the SPIDER benchmark.\n",
      "Submission Date: 01 July 2022\n",
      "DOI Link: https://doi.org/10.14778/3551793.3551841\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3696410.3714930\n",
      "PDF Link: None\n",
      "Title:SCOOT: SLO-Oriented Performance Tuning for LLM Inference Engines\n",
      "Authors: KeCheng, ZhiWang, WenHu, TiannuoYang, JianguoLi, ShengZhang\n",
      "Abstract: As large language models (LLMs) are gaining increasing popularity across a wide range of web applications, it is of great importance to optimize service-level objectives (SLOs) for LLM inference services to enhance user satisfaction and improve the competitiveness of cloud vendors. In this paper, we observe that adjusting the parameters of LLM inference engines can improve service performance, and the optimal parameter configurations of different services are different. Therefore, we propose SCOOT, an automatic performance tuning system to optimize SLOs for each LLM inference service by tuning the parameters of the inference engine. SCOOT jointly exploits single-objective and multiple-objective Bayesian optimization (BO) techniques to handle various optimization objectives via exploration and exploitation. Moreover, SCOOT prunes the search space with known constraints and adopts a random forest to learn hidden constraints during the tuning process to mitigate invalid exploration. To improve the tuning efficiency, SCOOT utilizes the parallel suggestion to accelerate the tuning process. Extensive experiments demonstrate that SCOOT considerably outperforms existing tuning techniques in SLO optimization while greatly improving the tuning efficiency. Moreover, SCOOT is universally applicable to various LLM inference engines including vLLM and TensorRT-LLM. Currently, SCOOT has already been implemented in the production environment at Ant Group.\n",
      "Submission Date: 22 April 2025\n",
      "DOI Link: https://doi.org/10.1145/3696410.3714930\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3642979.3643007\n",
      "PDF Link: None\n",
      "Title:Rethinking E-Commerce Search\n",
      "Authors: HaixunWang, TaesikNa\n",
      "Abstract: E-commerce search and recommendation usually operate on structured data such as product catalogs and taxonomies. However, creating better search and recommendation systems often requires a large variety of unstructured data including customer reviews and articles on the web. Traditionally, the solution has always been converting unstructured data into structured data through information extraction, and conducting search over the structured data. However, this is a costly approach that often has low quality. In this paper, we envision a solution that does entirely the opposite. Instead of converting unstructured data (web pages, customer reviews, etc) to structured data, we instead convert structured data (product inventory, catalogs, taxonomies, etc) into textual data, which can be easily integrated into the text corpus that trains LLMs. Then, search and recommendation can be performed through a Q/A mechanism through an LLM instead of using traditional information retrieval methods over structured data.\n",
      "Submission Date: 22 January 2024\n",
      "DOI Link: https://doi.org/10.1145/3642979.3643007\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3626730\n",
      "PDF Link: None\n",
      "Title:Generation of Training Examples for Tabular Natural Language Inference\n",
      "Authors: Jean-FlavienBussotti, EnzoVeltri, DonatelloSantoro, PaoloPapotti\n",
      "Abstract: Tabular data is becoming increasingly important in Natural Language Processing (NLP) tasks, such as Tabular Natural Language Inference (TNLI). Given a table and a hypothesis expressed in NL text, the goal is to assess if the former structured data supports or refutes the latter. In this work, we focus on the role played by the annotated data in training the inference model. We introduce a system, Tenet, for the automatic augmentation and generation of training examples for TNLI. Given the tables, existing approaches are either based on human annotators, and thus expensive, or on methods that produce simple examples that lack data variety and complex reasoning. Instead, our approach is built around the intuition that SQL queries are the right tool to achieve variety in the generated examples, both in terms of data variety and reasoning complexity. The first is achieved by evidence-queries that identify cell values over tables according to different data patterns. Once the data for the example is identified, semantic-queries describe the different ways such data can be identified with standard SQL clauses. These rich descriptions are then verbalized as text to create the annotated examples for the TNLI task. The same approach is also extended to create counterfactual examples, i.e., examples where the hypothesis is false, with a method based on injecting errors in the original (clean) table. For all steps, we introduce generic generation algorithms that take as input only the tables. For our experimental study, we use three datasets from the TNLI literature and two crafted by us on more complex tables. Tenet generates human-like examples, which lead to the effective training of several inference models with results comparable to those obtained by training the same models with manually-written examples.\n",
      "Submission Date: 12 December 2023\n",
      "DOI Link: https://doi.org/10.1145/3626730\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3627673.3680117\n",
      "PDF Link: https://dl.acm.org/doi/pdf/10.1145/3627673.3680117\n",
      "Title:Generative AI and Retrieval-Augmented Generation (RAG) Systems for Enterprise\n",
      "Authors: AnbangXu, TanYu, MinDu, PritamGundecha, YufanGuo, XinliangZhu, MayWang, PingLi, XinyunChen\n",
      "Abstract: This workshop introduces generative AI applications for enterprise, with a focus on retrieval-augmented generation (RAG) systems. Generative AI is a field of artificial intelligence that can create new content and solve complex problems. RAG systems are a novel generative AI technique that combines information retrieval with text generation to generate rich and diverse responses. RAG systems can leverage enterprise data, which is often specific, structured, and dynamic, to provide customized solutions for various domains. However, enterprise data also poses challenges such as scalability, security, and data quality. This workshop convenes researchers and practitioners to explore RAG and other generative AI systems in real-world enterprise scenarios, fostering knowledge exchange, collaboration, and identification of future directions. Relevant to the CIKM community, the workshop intersects with core areas of data science and machine learning, offering potential benefits across various domains.\n",
      "Submission Date: 21 October 2024\n",
      "DOI Link: https://doi.org/10.1145/3627673.3680117\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3543873.3587309\n",
      "PDF Link: None\n",
      "Title:Mirror: A Natural Language Interface for Data Querying, Summarization, and Visualization\n",
      "Authors: CanwenXu, JulianMcAuley, PenghanWang\n",
      "Abstract: We present Mirror, an open-source platform for data exploration and analysis powered by large language models. Mirror offers an intuitive natural language interface for querying databases, and automatically generates executable SQL commands to retrieve relevant data and summarize it in natural language. In addition, users can preview and manually edit the generated SQL commands to ensure the accuracy of their queries. Mirror also generates visualizations to facilitate understanding of the data. Designed with flexibility and human input in mind, Mirror is suitable for both experienced data analysts and non-technical professionals looking to gain insights from their data.1\n",
      "Submission Date: 30 April 2023\n",
      "DOI Link: https://doi.org/10.1145/3543873.3587309\n",
      "Processing link: https://dl.acm.org/doi/proceedings/10.1145/3622896\n",
      "PDF Link: None\n",
      "Title:None\n",
      "Author: None\n",
      "Abstract: None\n",
      "Submission Date: None\n",
      "DOI Link: None\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3631504.3631518\n",
      "PDF Link: None\n",
      "Title:From Large Language Models to Databases and Back: A Discussion on Research and Education\n",
      "Authors: SihemAmer-Yahia, AngelaBonifati, LeiChen, GuoliangLi, KyuseokShim, JianliangXu, XiaochunYang\n",
      "Abstract: In recent years, large language models (LLMs) have garnered increasing attention from both academia and industry due to their potential to facilitate natural language processing (NLP) and generate highquality text. Despite their benefits, however, the use of LLMs is raising concerns about the reliability of knowledge extraction. The combination of DB research and data science has advanced the state of the art in solving real-world problems, such as merchandise recommendation and hazard prevention [30]. In this discussion, we explore the challenges and opportunities related to LLMs in DB and data science research and education.\n",
      "Submission Date: 02 November 2023\n",
      "DOI Link: https://doi.org/10.1145/3631504.3631518\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3597503.3639081\n",
      "PDF Link: https://dl.acm.org/doi/pdf/10.1145/3597503.3639081\n",
      "Title:Xpert: Empowering Incident Management with Query Recommendations via Large Language Models\n",
      "Authors: YuxuanJiang, ChaoyunZhang, ShilinHe, ZhihaoYang, MinghuaMa, SiQin, YuKang, YingnongDang, SaravanRajmohan, QingweiLin, DongmeiZhang\n",
      "Abstract: Large-scale cloud systems play a pivotal role in modern IT infrastructure. However, incidents occurring within these systems can lead to service disruptions and adversely affect user experience. To swiftly resolve such incidents, on-call engineers depend on crafting domain-specific language (DSL) queries to analyze telemetry data. However, writing these queries can be challenging and time-consuming. This paper presents a thorough empirical study on the utilization of queries of KQL, a DSL employed for incident management in a large-scale cloud management system at Microsoft. The findings obtained underscore the importance and viability of KQL queries recommendation to enhance incident management. Building upon these valuable insights, we introduce Xpert, an end-to-end machine learning framework that automates KQL recommendation process. By leveraging historical incident data and large language models, Xpert generates customized KQL queries tailored to new incidents. Furthermore, Xpert incorporates a novel performance metric called Xcore, enabling a thorough evaluation of query quality from three comprehensive perspectives. We conduct extensive evaluations of Xpert, demonstrating its effectiveness in offline settings. Notably, we deploy Xpert in the real production environment of a large-scale incident management system in Microsoft, validating its efficiency in supporting incident management. To the best of our knowledge, this paper represents the first empirical study of its kind, and Xpert stands as a pioneering DSL query recommendation framework designed for incident management.\n",
      "Submission Date: 12 April 2024\n",
      "DOI Link: https://doi.org/10.1145/3597503.3639081\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3687997.3695650\n",
      "PDF Link: https://dl.acm.org/doi/pdf/10.1145/3687997.3695650\n",
      "Title:Towards an In-Context LLM-Based Approach for Automating the Definition of Model Views\n",
      "Authors: James WilliamPontes Miranda, HugoBruneliere, MassimoTisi, GersonSunyé\n",
      "Abstract: In the Model-Driven Engineering (MDE) of complex systems, multiple models represent various systems' aspects. In practice, these models are often unconnected and specified using different modeling languages. Model view solutions can be employed to automatically combine such models. However, writing model view definitions is not trivial. When modeling languages are semantically distant and/or have a large number of concepts, it can quickly become difficult to manually identify the language elements to be selected, associated, or queried to build a model view. As a solution, this paper proposes an in-context Large Language Model (LLM)-based approach to assist engineers in writing model-view definitions. Notably, we rely on LLMs and Prompt Engineering techniques to automatically generate drafts of model-view definitions by providing as input only minimal information on the modeling languages to be combined. We implemented our approach by integrating the EMF Views solution for model views with the LangChain framework for LLM-based applications. To this end, we tailored LangChain to handle EMF metamodels. We validated our approach and implementation on a set of model views originally specified either in VPDL, the ViewPoint Definition Language of EMF Views, or as ATL model-to-model transformations. We compared these original model view definitions with the ones we automatically generated. The obtained results show the feasibility and applicability of our approach.\n",
      "Submission Date: 17 October 2024\n",
      "DOI Link: https://doi.org/10.1145/3687997.3695650\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3713082.3730382\n",
      "PDF Link: https://dl.acm.org/doi/pdf/10.1145/3713082.3730382\n",
      "Title:Can Large Language Models Verify System Software? A Case Study Using FSCQ as a Benchmark\n",
      "Authors: JianxingQin, AlexanderDu, DanfengZhang, MatthewLentz, DanyangZhuo\n",
      "Abstract: Large language models (LLMs) have demonstrated remarkable coding capabilities. They excel in code synthesis benchmarks across diverse domains and have become ubiquitous in coding tools. Recently, they have also shown promise in generating mathematical proofs and small software programs. In this paper, we explore their potential to produce proofs for complex system software (e.g., file systems), where verification typically requires substantial manual effort. By automating parts of this process, LLMs could reduce the verification burden and make rigorous proofs for system software more accessible. To evaluate LLMs for system software verification, we use FSCQ, a verified file system, as our benchmark. Our results confirm the promise of this approach: with appropriate proof context and a straightforward best-first tree search, off-the-shelf LLMs achieve 38% proof coverage for theorems sampled from FSCQ. Moreover, for simpler theorems---those with human proofs under 64 tokens, which make up about 60% of all FSCQ theorems---LLMs achieve over 57% coverage. These findings are preliminary, and we anticipate that various techniques can further improve proof coverage.\n",
      "Submission Date: 06 June 2025\n",
      "DOI Link: https://doi.org/10.1145/3713082.3730382\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3534678.3539330\n",
      "PDF Link: None\n",
      "Title:RGVisNet: A Hybrid Retrieval-Generation Neural Framework Towards Automatic Data Visualization Generation\n",
      "Authors: YuanfengSong, XuefangZhao, Raymond Chi-WingWong, DiJiang\n",
      "Abstract: Recent years have witnessed the burgeoning of data visualization (DV) systems in both the research and the industrial communities since they provide vivid and powerful tools to convey the insights behind the massive data. A necessary step to visualize data is through creating suitable specifications in some declarative visualization languages (DVLs, e.g., Vega-Lite, ECharts). Due to the steep learning curve of mastering DVLs, automatically generating DVs via natural language questions, or text-to-vis, has been proposed and received great attention. However, existing neural network-based text-to-vis models, such as Seq2Vis or ncNet, usually generate DVs from scratch, limiting their performance due to the complex nature of this problem. Inspired by how developers reuse previously validated source code snippets from code search engines or a large-scale codebase when they conduct software development, we provide a novel hybrid retrieval-generation framework named RGVisNet for text-to-vis. It retrieves the most relevant DV query candidate as a prototype from the DV query codebase, and then revises the prototype to generate the desired DV query. Specifically, the DV query retrieval model is a neural ranking model which employs a schema-aware encoder for the NL question, and a GNN-based DV query encoder to capture the structure information of a DV query. At the same time, the DV query revision model shares the same structure and parameters of the encoders, and employs a DV grammar-aware decoder to reuse the retrieved prototype. Experimental evaluation on the public NVBench dataset validates that RGVisNet can significantly outperform existing generative text-to-vis models such as ncNet, by up to 74.28% relative improvement in terms of overall accuracy. To the best of our knowledge, RGVisNet is the first framework that seamlessly integrates the retrieval- with the generative-based approach for the text-to-vis task.\n",
      "Submission Date: 14 August 2022\n",
      "DOI Link: https://doi.org/10.1145/3534678.3539330\n",
      "Processing link: https://dl.acm.org/doi/10.14778/3554821.3554896\n",
      "PDF Link: None\n",
      "Title:From BERT to GPT-3 codex: harnessing the potential of very large language models for data management\n",
      "Authors: ImmanuelTrummer\n",
      "Abstract: Large language models have recently advanced the state of the art on many natural language processing benchmarks. The newest generation of models can be applied to a variety of tasks with little to no specialized training. This technology creates various opportunities for applications in the context of data management. The tutorial will introduce participants to basic background on language models, discuss different methods to use language models, and give an overview and short demonstration of available libraries and APIs. Models for generating natural language will be considered as well as models, such as GPT-3 Codex, which complete program code or generate code from natural language instructions. Finally, the tutorial will discuss recent research in the database community that exploits language models in the context of traditional database systems or proposes novel system architectures that are based on them. The tutorial is targeted at database researchers. No prior background on language models is required. The goal of the tutorial is to introduce database researchers to the latest generation of language models, and to their use cases in the domain of data management.\n",
      "Submission Date: 01 August 2022\n",
      "DOI Link: https://doi.org/10.14778/3554821.3554896\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3550356.3561542\n",
      "PDF Link: None\n",
      "Title:Combining OCL and natural language: a call for a community effort\n",
      "Authors: JordiCabot, DavidDelgado, LolaBurgueño\n",
      "Abstract: The growing popularity and availability of pretrained natural language models opens the door to many interesting applications combining natural language (NL) with software artefacts. A couple of examples are the generation of code excerpts from NL instructions or the verbalization of programs in NL to facilitate their comprehension. Many of these language models have been trained with open source software datasets and therefore \"understand\" a variety of programming languages, but not OCL. We argue that OCL needs to jump into the machine learning bandwagon or it will risk losing its appeal as a constraint specification language. For that, the key first task is to create together an OCL corpus dataset amenable for natural language processing.\n",
      "Submission Date: 09 November 2022\n",
      "DOI Link: https://doi.org/10.1145/3550356.3561542\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3627673.3679932\n",
      "PDF Link: https://dl.acm.org/doi/pdf/10.1145/3627673.3679932\n",
      "Title:Generating Cross-model Analytics Workloads Using LLMs\n",
      "Authors: XiuwenZheng, ArunKumar, AmarnathGupta\n",
      "Abstract: Data analytics applications today often require processing heterogeneous data from different data models, including relational, graph, and text data, for more holistic analytics. While query optimization for single data models, especially relational data, has been studied for decades, there is surprisingly little work on query optimization for cross-model data analytics. Cross-model query optimization can benefit from the long line of prior work in query optimization in the relational realm, wherein cost-based and/or machine learning-based (ML-based) optimizers are common. Both approaches require a large and diverse set of query workloads to measure, tune, and evaluate a query optimizer. To the best of our knowledge, there are still no large public cross-model benchmark workloads, a significant obstacle for systems researchers in this space. In this paper, we take a step toward filling this research gap by generating new query workloads spanning relational and graph data, which are ubiquitous in analytics applications. Our approach leverages large language models (LLMs) via different prompting strategies to generate queries and proposes new rule-based post-processing methods to ensure query correctness. We evaluate the pros and cons of each strategy and perform an in-depth analysis by categorizing the syntactic and semantic errors of the generated queries. So far, we have produced over 4000 correct cross-model queries, the largest set ever. Our code, prompts, data, and query workloads will all be released publicly.\n",
      "Submission Date: 21 October 2024\n",
      "DOI Link: https://doi.org/10.1145/3627673.3679932\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3709727\n",
      "PDF Link: https://dl.acm.org/doi/pdf/10.1145/3709727\n",
      "Title:SNAILS: Schema Naming Assessments for Improved LLM-Based SQL Inference\n",
      "Authors: KyleLuoma, ArunKumar\n",
      "Abstract: Large Language Models (LLMs) have revolutionized Natural Language to SQL (NL-to-SQL), dominating most NL-to-SQL benchmarks. But LLMs still face limitations due to hallucinations, semantic ambiguity, and lexical mismatches between an NL query and the database schema. Naturally, a lot of work in the ML+DB intersection aims to mitigate such LLM limitations. In this work, we shine the light on a complementary data-centric question: How should DB schemas evolve in this era of LLMs to boost NL-to-SQL? The intuition is that more NL-friendly schema identifiers can help LLMs work better with DBs. We dive deeper into this seemingly obvious, but hitherto underexplored and important, connection between schema identifier ''naturalness'' and the behavior of LLM-based NL-to-SQL by creating a new integrated benchmark suite we call SNAILS. SNAILS has 4 novel artifacts: (1) A collection of real-world DB schemas not present in prior NL-to-SQL benchmarks; (2) A set of labeled NL-SQL query pairs on our collection not seen before by public LLMs; (3) A notion of naturalness level for schema identifiers and a novel labeled dataset of modified identifiers; and (4) AI artifacts to automatically modify identifier naturalness. Using SNAILS, we perform a comprehensive empirical evaluation of the impact of schema naturalness on LLM-based NL-to-SQL accuracy, and present a method for improving LLM-based NL-to-SQL with natural views. Our results reveal statistically significant correlations across multiple public LLMs from OpenAI, Meta, and Google on multiple databases using both zero-shot prompting as well as more complex NL-to-SQL workflows: DIN SQL, and CodeS. We present several fine-grained insights and discuss pathways for DB practitioners to better exploit LLMs for NL-to-SQL.\n",
      "Submission Date: 11 February 2025\n",
      "DOI Link: https://doi.org/10.1145/3709727\n",
      "Processing link: https://dl.acm.org/doi/10.14778/3696435.3696440\n",
      "PDF Link: None\n",
      "Title:LLM-R2: A Large Language Model Enhanced Rule-Based Rewrite System for Boosting Query Efficiency\n",
      "Authors: ZhaodonghuiLi, HaitaoYuan, HuimingWang, GaoCong, LidongBing\n",
      "Abstract: Query rewrite, which aims to improve query efficiency by altering an SQL query's structure without changing its result, has been an important research problem. In order to maintain equivalence between the rewritten query and the original one during rewriting, traditional query rewrite methods always rewrite the queries following certain rewrite rules. However, some problems still remain. First, existing methods of finding the optimal choice or sequence of rewrite rules are still limited and the process always costs a lot of resources. Methods involving discovering new rewrite rules typically require complicated proofs of structural logic or extensive user interactions. Second, current query rewrite methods usually rely highly on DBMS cost estimators which are often not accurate. In this paper, we address these problems by proposing a novel query rewrite method named LLM-R2, which leverages a large language model (LLM) to recommend rewrite rules for a database rewrite system. To further enhance the inference ability of the LLM in recommending rewrite rules, we train a contrastive model using a curriculum-based approach to learn query representations and select effective query demonstrations for the LLM. Experimental results show that our method significantly improves the query execution efficiency and outperforms the baseline methods. In addition, our method exhibits high robustness across different datasets.\n",
      "Submission Date: 01 September 2024\n",
      "DOI Link: https://doi.org/10.14778/3696435.3696440\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3487553.3547182\n",
      "PDF Link: None\n",
      "Title:Accepted Tutorials at The Web Conference 2022\n",
      "Authors: RiccardoTommasini, SenjutiBasu Roy, XuanWang, HongweiWang, HengJi, JiaweiHan, PreslavNakov, GiovanniDa San Martino, FirojAlam, MarkusSchedl, ElisabethLex, AkashBharadwaj, GrahamCormode, MilanDojchinovski, JanForberg, JohannesFrey, PieterBonte, MarcoBalduini, MatteoBelcao, EmanueleDella Valle, JunliangYu, HongzhiYin, TongChen, HaochenLiu, YiqiWang, WenqiFan, XiaoruiLiu, JamellDacon, LingjuanLye, JiliangTang, AristidesGionis, StefanNeumann, BrunoOrdozgoiti, SimonRazniewski, HibaArnaout, ShresthaGhosh, FabianSuchanek, LingfeiWu, YuChen, YunyaoLi, BangLiu, FilipIlievski, DanielGarijo, HansChalupsky, PedroSzekely, IliasKanellos, DimitrisSacharidis, ThanasisVergoulis, NurendraChoudhary, NikhilRao, KarthikSubbian, SrinivasanSengamedu, Chandan K.Reddy, FriedhelmVictor, BernhardHaslhofer, GeorgeKatsogiannis- Meimarakis, GeorgiaKoutrika, ShengminJin, DanaiKoutra, RezaZafarani, YuliaTsvetkov, VidhishaBalachandran, SachinKumar, XiangyuZhao, BoChen, HuifengGuo, YejingWang, RuimingTang, YangZhang, WenjieWang, PengWu, FuliFeng, XiangnanHe\n",
      "Abstract: This paper summarizes the content of the 20 tutorials that have been given at The Web Conference 2022: 85% of these tutorials are lecture style, and 15% of these are hands on.\n",
      "Submission Date: 16 August 2022\n",
      "DOI Link: https://doi.org/10.1145/3487553.3547182\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3702879.3702924\n",
      "PDF Link: None\n",
      "Title:A method for Querying Textile and Clothing Design Elements in a Resource Library based on Multi-source Data Mining\n",
      "Authors: LanZhang\n",
      "Abstract: This paper presents a query method of textile and garment design elements resource library based on multi-source data mining. By using multi-source data mining techniques to explore the correlation between different data sources, the implicit relationship characteristics between textile and clothing design elements are revealed. Based on the mining results, the feature extraction process of textile and clothing design elements was implemented. By leveraging the sparse and distributed storage characteristics of HBase, a storage model was designed to meet the requirements of massive data storage and real-time operations. The introduction of improved decision tree algorithm as a query tool has improved the accuracy and efficiency of querying textile and clothing design elements. The experimental results show that the proposed method has high query accuracy and fast query speed. It has been confirmed that the proposed method can effectively process multi-source clothing design data, providing strong support for the field of textile and clothing design.\n",
      "Submission Date: 11 December 2024\n",
      "DOI Link: https://doi.org/10.1145/3702879.3702924\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3587281.3587700\n",
      "PDF Link: https://dl.acm.org/doi/pdf/10.1145/3587281.3587700\n",
      "Title:A More Accessible Web with Natural Language Interface\n",
      "Authors: XiangDeng\n",
      "Abstract: The past decade has witnessed the rapid growth and evolution of the Web. Today, people can perform a multitude of tasks through the use of a single browser. Despite the immense power and capabilities of the Web, its increasing complexity and the overwhelming amount of information pose significant challenges for users to easily access the information they need and achieve their goals. Especially for those who are less technologically proficient or have disabilities. In this work, we propose to tackle this issue by building a general natural language interface for the Web, which enables users to express their needs in natural language and have the system carry out the arduous actions. We examine the key components crucial for building the natural language interface. On top of that, we present our ongoing efforts in curating a new benchmark dataset covering a diverse range of websites and tasks, and establishing baselines to demonstrate the feasibility of building such a system.\n",
      "Submission Date: 30 April 2023\n",
      "DOI Link: https://doi.org/10.1145/3587281.3587700\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3709681\n",
      "PDF Link: None\n",
      "Title:Dialogue Benchmark Generation from Knowledge Graphs with Cost-Effective Retrieval-Augmented LLMs\n",
      "Authors: RehamOmar, OmijMangukiya, EssamMansour\n",
      "Abstract: Dialogue benchmarks are crucial in training and evaluating chatbots engaging in domain-specific conversations. Knowledge graphs (KGs) represent semantically rich and well-organized data spanning various domains, such as DBLP, DBpedia, and YAGO. Traditionally, dialogue benchmarks have been manually created from documents, neglecting the potential of KGs in automating this process. Some question-answering benchmarks are automatically generated using extensive preprocessing from KGs, but they do not support dialogue generation. This paper introduces Chatty-Gen, a novel multi-stage retrieval-augmented generation platform for automatically generating high-quality dialogue benchmarks tailored to a specific domain using a KG. Chatty-Gen decomposes the generation process into manageable stages and uses assertion rules for automatic validation between stages. Our approach enables control over intermediate results to prevent time-consuming restarts due to hallucinations. It also reduces reliance on costly and more powerful commercial LLMs. Chatty-Gen eliminates upfront processing of the entire KG using efficient query-based retrieval to find representative subgraphs based on the dialogue context. Our experiments with several real and large KGs demonstrate that Chatty-Gen significantly outperforms state-of-the-art systems and ensures consistent model and system performance across multiple LLMs of diverse capabilities, such as GPT-4o, Gemini 1.5, Llama 3, and Mistral.\n",
      "Submission Date: 11 February 2025\n",
      "DOI Link: https://doi.org/10.1145/3709681\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3535508.3545518\n",
      "PDF Link: https://dl.acm.org/doi/pdf/10.1145/3535508.3545518\n",
      "Title:Attention-based aspect reasoning for knowledge base question answering on clinical notes\n",
      "Authors: PingWang, TianShi, KhushbuAgarwal, SutanayChoudhury, Chandan K.Reddy\n",
      "Abstract: Question Answering (QA) in clinical notes has gained a lot of attention in the past few years. Existing machine reading comprehension approaches in clinical domain can only handle questions about a single block of clinical texts and fail to retrieve information about multiple patients and their clinical notes. To handle more complex questions, we aim at creating knowledge base from clinical notes to link different patients and clinical notes, and performing knowledge base question answering (KBQA). Based on the expert annotations available in the n2c2 dataset, we first created the ClinicalKBQA dataset that includes around 9K QA pairs and covers questions about seven medical topics using more than 300 question templates. Then, we investigated an attention-based aspect reasoning (AAR) method for KBQA and analyzed the impact of different aspects of answers (e.g., entity, type, path, and context) for prediction. The AAR method achieves better performance due to the well-designed encoder and attention mechanism. From our experiments, we find that both aspects, type and path, enable the model to identify answers satisfying the general conditions and produce lower precision and higher recall. On the other hand, the aspects, entity and context, limit the answers by node-specific information and lead to higher precision and lower recall.\n",
      "Submission Date: 07 August 2022\n",
      "DOI Link: https://doi.org/10.1145/3535508.3545518\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3663741.3664785\n",
      "PDF Link: None\n",
      "Title:Are Large Language Models the New Interface for Data Pipelines?\n",
      "Authors: SylvioBarbon Junior, PaoloCeravolo, SvenGroppe, MustafaJarrar, SamiraMaghool, FlorenceSèdes, SororSahri, MauriceVan Keulen\n",
      "Abstract: A Language Model is a term that encompasses various types of models designed to understand and generate human communication. Large Language Models (LLMs) have gained significant attention due to their ability to process text with human-like fluency and coherence, making them valuable for a wide range of data-related tasks fashioned as pipelines. The capabilities of LLMs in natural language understanding and generation, combined with their scalability, versatility, and state-of-the-art performance, enable innovative applications across various AI-related fields, including eXplainable Artificial Intelligence (XAI), Automated Machine Learning (AutoML), and Knowledge Graphs (KG). Furthermore, we believe these models can extract valuable insights and make data-driven decisions at scale, a practice commonly referred to as Big Data Analytics (BDA). In this position paper, we provide some discussions in the direction of unlocking synergies among these technologies, which can lead to more powerful and intelligent AI solutions, driving improvements in data pipelines across a wide range of applications and domains integrating humans, computers, and knowledge.\n",
      "Submission Date: 09 June 2024\n",
      "DOI Link: https://doi.org/10.1145/3663741.3664785\n",
      "Processing link: https://dl.acm.org/doi/proceedings/10.1145/3626246\n",
      "PDF Link: None\n",
      "Title:None\n",
      "Author: None\n",
      "Abstract: None\n",
      "Submission Date: None\n",
      "DOI Link: None\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3626246.3653378\n",
      "PDF Link: https://dl.acm.org/doi/pdf/10.1145/3626246.3653378\n",
      "Title:Vertically Autoscaling Monolithic Applications with CaaSPER: Scalable Container-as-a-Service Performance Enhanced Resizing Algorithm for the Cloud\n",
      "Authors: AnnaPavlenko, JoyceCahoon, YiwenZhu, BrianKroth, MichaelNelson, AndrewCarter, DavidLiao, TravisWright, JesúsCamacho-Rodríguez, KarlaSaur\n",
      "Abstract: Kubernetes has emerged as a prominent open-source platform for managing cloud applications, including stateful databases. These monolithic applications rely on vertical scaling, adjusting CPU cores based on load fluctuations. However, our analysis of Kubernetes-based Database-as-a-Service (DBaaS) offerings at Microsoft revealed that many customers consistently over-provision resources for peak workloads, neglecting cost-saving opportunities through resource scale-down. We found that there is a gap in the ability of existing vertical autoscaling tools to minimize resource slack and respond promptly to throttling, leading to increased costs and impacting crucial metrics such as throughput and availability. To address this challenge, we propose CaaSPER, a vertical autoscaling algorithm that blends reactive and proactive strategies. By dynamically adjusting CPU resources, CaaSPER minimizes resource slack, maintains optimal CPU utilization, and reduces throttling. Importantly, customers have the flexibility to prioritize either cost savings or high performance based on their preferences. Extensive testing demonstrates that CaaSPER effectively reduces throttling and keeps CPU utilization within target levels. CaaSPER is designed to be application-agnostic and platform-agnostic, with potential for extension to other applications requiring vertical autoscaling.\n",
      "Submission Date: 09 June 2024\n",
      "DOI Link: https://doi.org/10.1145/3626246.3653378\n",
      "Processing link: https://dl.acm.org/doi/proceedings/10.1145/3661304\n",
      "PDF Link: None\n",
      "Title:None\n",
      "Author: None\n",
      "Abstract: None\n",
      "Submission Date: None\n",
      "DOI Link: None\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3514221.3517843\n",
      "PDF Link: https://dl.acm.org/doi/pdf/10.1145/3514221.3517843\n",
      "Title:DB-BERT: A Database Tuning Tool that \"Reads the Manual\"\n",
      "Authors: ImmanuelTrummer\n",
      "Abstract: DB-BERT is a database tuning tool that exploits information gained via natural language analysis of manuals and other relevant text documents. It uses text to identify database system parameters to tune as well as recommended parameter values. DB-BERT applies large, pre-trained language models (specifically, the BERT model) for text analysis. During an initial training phase, it fine-tunes model weights in order to translate natural language hints into recommended settings. At run time, DB-BERT learns to aggregate, adapt, and prioritize hints to achieve optimal performance for a specific database system and benchmark. Both phases are iterative and use reinforcement learning to guide the selection of tuning settings to evaluate (penalizing settings that the database system rejects while rewarding settings that improve performance). In our experiments, we leverage hundreds of text documents about database tuning as input for DB-BERT. We compare DB-BERT against various baselines, considering different benchmarks (TPC-C and TPC-H), metrics (throughput and run time), as well as database systems (Postgres and MySQL). In all cases, DB-BERT finds the best parameter settings among all compared methods. The code of DB-BERT is available online at https://itrummer.github.io/dbbert/.\n",
      "Submission Date: 11 June 2022\n",
      "DOI Link: https://doi.org/10.1145/3514221.3517843\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3703412.3703429\n",
      "PDF Link: https://dl.acm.org/doi/pdf/10.1145/3703412.3703429\n",
      "Title:Tab2Graph: Transforming Heterogeneous Tables as Graphs\n",
      "Authors: RajatSingh, RaajitaBhamidipaty, AnjaliSharma, SrikantaBedathur\n",
      "Abstract: Tables continue to be one of the most widely used data formats for representing information due to their flexibility and intuitive appeal. Despite this, extracting meaningful insights and gaining a comprehensive understanding from these tables remains challenging. Several factors contribute to this – including the sheer volume of tabular content, the difficulty of their use in modern deep-learning techniques, and more. Significant effort has been put into developing advanced deep-learning models that can learn dense representations for tabular data and utilize these representations to perform various downstream tasks. In this paper, we investigate various methods for transforming a large entity-centric heterogeneous tabular corpus into a graph. We demonstrate how the accuracy of different deep learning models varies with changes in graph structure for the Missing Value Imputation (MVI) task. We show that by selecting an appropriate table-to-graph transformation, namely a dual-node heterogeneous graph, and leveraging powerful graph models that are also scalable, we can achieve better performance in low resource settings as compared to the state-of-the-art attention model while requiring 30 times less training time.\n",
      "Submission Date: 05 March 2025\n",
      "DOI Link: https://doi.org/10.1145/3703412.3703429\n",
      "Processing link: https://dl.acm.org/doi/10.14778/3554821.3554890\n",
      "PDF Link: None\n",
      "Title:Transformers for tabular data representation: a tutorial on models and applications\n",
      "Authors: GilbertBadaro, PaoloPapotti\n",
      "Abstract: In the last few years, the natural language processing community witnessed advances in neural representations of free texts with transformer-based language models (LMs). Given the importance of knowledge available in relational tables, recent research efforts extend LMs by developing neural representations for tabular data. In this tutorial, we present these proposals with two main goals. First, we introduce to a database audience the potentials and the limitations of current models. Second, we demonstrate the large variety of data applications that benefit from the transformer architecture. The tutorial aims at encouraging database researchers to engage and contribute to this new direction, and at empowering practitioners with a new set of tools for applications involving text and tabular data.\n",
      "Submission Date: 01 August 2022\n",
      "DOI Link: https://doi.org/10.14778/3554821.3554890\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3664597\n",
      "PDF Link: https://dl.acm.org/doi/pdf/10.1145/3664597\n",
      "Title:Deep Learning for Code Intelligence: Survey, Benchmark and Toolkit\n",
      "Authors: YaoWan, ZhangqianBi, YangHe, JianguoZhang, HongyuZhang, YuleiSui, GuandongXu, HaiJin, PhilipYu\n",
      "Abstract: Code intelligence leverages machine learning techniques to extract knowledge from extensive code corpora, with the aim of developing intelligent tools to improve the quality and productivity of computer programming. Currently, there is already a thriving research community focusing on code intelligence, with efforts ranging from software engineering, machine learning, data mining, natural language processing, and programming languages. In this paper, we conduct a comprehensive literature review on deep learning for code intelligence, from the aspects of code representation learning, deep learning techniques, and application tasks. We also benchmark several state-of-the-art neural models for code intelligence, and provide an open-source toolkit tailored for the rapid prototyping of deep-learning-based code intelligence models. In particular, we inspect the existing code intelligence models under the basis of code representation learning, and provide a comprehensive overview to enhance comprehension of the present state of code intelligence. Furthermore, we publicly release the source code and data resources to provide the community with a ready-to-use benchmark, which can facilitate the evaluation and comparison of existing and future code intelligence models (https://xcodemind.github.io). At last, we also point out several challenging and promising directions for future research.\n",
      "Submission Date: 03 October 2024\n",
      "DOI Link: https://doi.org/10.1145/3664597\n",
      "Processing link: https://dl.acm.org/doi/proceedings/10.1145/3582768\n",
      "PDF Link: None\n",
      "Title:None\n",
      "Author: None\n",
      "Abstract: None\n",
      "Submission Date: None\n",
      "DOI Link: None\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3637528.3671452\n",
      "PDF Link: https://dl.acm.org/doi/pdf/10.1145/3637528.3671452\n",
      "Title:Reasoning and Planning with Large Language Models in Code Development\n",
      "Authors: HaoDing, ZiweiFan, IngoGuehring, GauravGupta, WooseokHa, JunHuan, LinboLiu, BehroozOmidvar-Tehrani, ShiqiWang, HaoZhou\n",
      "Abstract: Large Language Models (LLMs) are revolutionizing the field of code development by leveraging their deep understanding of code patterns, syntax, and semantics to assist developers in various tasks, from code generation and testing to code understanding and documentation. In this survey, accompanying our proposed lecture-style tutorial for KDD 2024, we explore the multifaceted impact of LLMs on the code development, delving into techniques for generating a high-quality code, creating comprehensive test cases, automatically generating documentation, and engaging in an interactive code reasoning. Throughout the survey, we highlight some crucial components surrounding LLMs, including pre-training, fine-tuning, prompt engineering, iterative refinement, agent planning, and hallucination mitigation. We put forward that such ingredients are essential to harness the full potential of these powerful AI models in revolutionizing software engineering and paving the way for a more efficient, effective, and innovative future in code development.\n",
      "Submission Date: 24 August 2024\n",
      "DOI Link: https://doi.org/10.1145/3637528.3671452\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3555041.3589411\n",
      "PDF Link: https://dl.acm.org/doi/pdf/10.1145/3555041.3589411\n",
      "Title:Models and Practice of Neural Table Representations\n",
      "Authors: MadelonHulsebos, XiangDeng, HuanSun, PaoloPapotti\n",
      "Abstract: In the last few years, the natural language processing community witnessed advances in neural representations of free-form text with transformer-based language models (LMs). Given the importance of knowledge available in relational tables, recent research efforts extend LMs by developing neural representations for tabular data. In this tutorial, we present these proposals with three main goals. First, we aim at introducing the potentials and limitations of current models to a database audience. Second, we want the attendees to see the benefit of such line of work in a large variety of data applications. Third, we would like to empower the audience with a new set of tools and to inspire them to tackle some of the important directions for neural table representations, including model and system design, evaluation, application and deployment. To achieve these goals, the tutorial is organized in two parts. The first part covers the background for neural table representations, including a survey of the most important systems. The second part is designed as a hands-on session, where attendees will use their laptop to explore this new framework and test neural models involving text and tabular data.\n",
      "Submission Date: 05 June 2023\n",
      "DOI Link: https://doi.org/10.1145/3555041.3589411\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3665252.3665263\n",
      "PDF Link: None\n",
      "Title:Unicorn: A Unified Multi-Tasking Matching Model\n",
      "Authors: JuFan, JianhongTu, GuoliangLi, PengWang, XiaoyongDu, XiaofengJia, SongGao, NanTang\n",
      "Abstract: Data matching, which decides whether two data elements (e.g., string, tuple, column, or knowledge graph entity) are the \"same\" (a.k.a. a match), is a key concept in data integration. The widely used practice is to build task-specific or even dataset-specific solutions, which are hard to generalize and disable the opportunities of knowledge sharing that can be learned from different datasets and multiple tasks. In this paper, we propose Unicorn, a unified model for generally supporting common data matching tasks. Building such a unified model is challenging due to heterogeneous formats of input data elements and various matching semantics of multiple tasks. To address the challenges, Unicorn employs one generic Encoder that converts any pair of data elements (a, b) into a learned representation, and uses a Matcher, which is a binary classifier, to decide whether a matches b. To align matching semantics of multiple tasks, Unicorn adopts a mixture-of-experts model that enhances the learned representation into a better representation. We conduct extensive experiments using 20 datasets on 7 well-studied data matching tasks, and find that our unified model can achieve better performance on most tasks and on average, compared with the state-of-the-art specific models trained for ad-hoc tasks and datasets separately. Moreover, Unicorn can also well serve new matching tasks with zero-shot learning.\n",
      "Submission Date: 14 May 2024\n",
      "DOI Link: https://doi.org/10.1145/3665252.3665263\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3637528.3671470\n",
      "PDF Link: https://dl.acm.org/doi/pdf/10.1145/3637528.3671470\n",
      "Title:A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models\n",
      "Authors: WenqiFan, YujuanDing, LiangboNing, ShijieWang, HengyunLi, DaweiYin, Tat-SengChua, QingLi\n",
      "Abstract: As one of the most advanced techniques in AI, Retrieval-Augmented Generation (RAG) can offer reliable and up-to-date external knowledge, providing huge convenience for numerous tasks. Particularly in the era of AI-Generated Content (AIGC), the powerful capacity of retrieval in providing additional knowledge enables RAG to assist existing generative AI in producing high-quality outputs. Recently, Large Language Models (LLMs) have demonstrated revolutionary abilities in language understanding and generation, while still facing inherent limitations such as hallucinations and out-of-date internal knowledge. Given the powerful abilities of RAG in providing the latest and helpful auxiliary information, Retrieval-Augmented Large Language Models (RA-LLMs) have emerged to harness external and authoritative knowledge bases, rather than solely relying on the model's internal knowledge, to augment the quality of the generated content of LLMs. In this survey, we comprehensively review existing research studies in RA-LLMs, covering three primary technical perspectives: Furthermore, to deliver deeper insights, we discuss current limitations and several promising directions for future research. Updated information about this survey can be found at: https://advanced-recommender-systems.github.io/RAG-Meets-LLMs/\n",
      "Submission Date: 24 August 2024\n",
      "DOI Link: https://doi.org/10.1145/3637528.3671470\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3626111.3628176\n",
      "PDF Link: https://dl.acm.org/doi/pdf/10.1145/3626111.3628176\n",
      "Title:A Holistic View of AI-driven Network Incident Management\n",
      "Authors: PouyaHamadanian, BehnazArzani, SadjadFouladi, Siva Kesava ReddyKakarla, RodrigoFonseca, DenizcanBillor, AhmadCheema, EdetNkposong, RanveerChandra\n",
      "Abstract: We discuss the potential improvement large language models (LLM) can provide in incident management and how they can overhaul the ways operators conduct incident management today. We propose a holistic framework for building an AI helper for incident management and discuss the several avenues of future research needed to achieve it. We thoroughly analyze the fundamental requirements the community should consider when designing such helpers. Our work is based on discussions with operators of a large public cloud provider and their prior experiences both in incident management and with attempts to improve the incident management experience through various forms of automation.\n",
      "Submission Date: 28 November 2023\n",
      "DOI Link: https://doi.org/10.1145/3626111.3628176\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3640310.3674091\n",
      "PDF Link: https://dl.acm.org/doi/pdf/10.1145/3640310.3674091\n",
      "Title:Text2VQL: Teaching a Model Query Language to Open-Source Language Models with ChatGPT\n",
      "Authors: José Antonio HernándezLópez, MátéFöldiák, DánielVarró\n",
      "Abstract: While large language models (LLMs) like ChatGPT has demonstrated impressive capabilities in addressing various software engineering tasks, their use in a model-driven engineering (MDE) context is still in an early stage. Since the technology is proprietary and accessible solely through an API, its use may be incompatible with the strict protection of intellectual properties in industrial models. While there are open-source LLM alternatives, they often lack the power of proprietary models and require extensive data fine-tuning to realize their full potential. Furthermore, open-source datasets tailored for MDE tasks are scarce, posing challenges for training such models effectively. In this work, we introduce Text2VQL, a framework that generates graph queries captured in the VIATRA Query Language (VQL) from natural language specifications using open-source LLMs. Initially, we create a high-quality synthetic dataset comprising pairs of queries and their corresponding natural language descriptions using ChatGPT and VIATRA parser. Leveraging this dataset, we use parameter-efficient tuning to specialize three open-source LLMs, namely, DeepSeek Coder 1b, DeepSeek Coder 7b, and CodeLlama 7b for VQL query generation. Our experimental evaluation demonstrates that the fine-tuned models outperform the base models in query generation, highlighting the usefulness of our synthetic dataset. Moreover, one of the fine-tuned models achieves performance comparable to ChatGPT.\n",
      "Submission Date: 22 September 2024\n",
      "DOI Link: https://doi.org/10.1145/3640310.3674091\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3578741.3578744\n",
      "PDF Link: None\n",
      "Title:Answering questions over tables based on TAPAS and graph attention model\n",
      "Authors: TingyiZhang, YuboLiu, JieWu, JianmingLiao\n",
      "Abstract: Question answering over tables is seen as a semantic parsing task in which the question is translated to a logical form (e.g. an SQL statement) that can be executed against the table to retrieve the answer. However, the generated logical form is only an intermediate step in retrieving the answer, and collecting such logical form is time and money consuming, and requires some SQL syntax for the worker annotating the dataset. To address these issues, some models have been proposed to directly answer questions over tables without generating logical forms. TAPAS encodes table as input by extending BERT’s architecture, pre-trains on millions of table-text pairs extracted from Wikipedia, and is used in the downstream tasks of question answering over tables. However, in the downstream task of question answering over tables, TAPAS only uses two fully connected layers to select table cells and a corresponding aggregate operator, which we believe does not fully exploit the capability of the TAPAS encoder. According to the characteristics of question answering over tables, We propose a graph attention model to utilize and fuse feature vectors extracted from TAPAS encoder. Our experimental results on the WikiSQL dataset show that the accuracy of the TAPAS-GAT containing TAPAS encoder and graph attention model is 87.0%, which exceeds the accuracy of the original TAPAS containing TAPAS encoder and two fully connected layers. In addition, the TAPAS is limited to the text length of the input table question pair, typically 512 tokens, which leads to the inability of TAPAS to handle larger tables. We propose a method to reduce the size of the table by extracting the columns in the table that are relevant to the question, and we call such a preprocessing operation as a snapshot. After taking a snapshot of the table, the accuracy of our model on WIkiSQL dataset rises to 89.8%.\n",
      "Submission Date: 06 March 2023\n",
      "DOI Link: https://doi.org/10.1145/3578741.3578744\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3442381.3449992\n",
      "PDF Link: None\n",
      "Title:Beyond I.I.D.: Three Levels of Generalization for Question Answering on Knowledge Bases\n",
      "Authors: YuGu, SueKase, MichelleVanni, BrianSadler, PercyLiang, XifengYan, YuSu\n",
      "Abstract: Existing studies on question answering on knowledge bases (KBQA) mainly operate with the standard i.i.d. assumption, i.e., training distribution over questions is the same as the test distribution. However, i.i.d. may be neither achievable nor desirable on large-scale KBs because 1) true user distribution is hard to capture and 2) randomly sampling training examples from the enormous space would be data-inefficient. Instead, we suggest that KBQA models should have three levels of built-in generalization: i.i.d., compositional, and zero-shot. To facilitate the development of KBQA models with stronger generalization, we construct and release a new large-scale, high-quality dataset with 64,331 questions, GrailQA, and provide evaluation settings for all three levels of generalization. In addition, we propose a novel BERT-based KBQA model. The combination of our dataset and model enables us to thoroughly examine and demonstrate, for the first time, the key role of pre-trained contextual embeddings like BERT in the generalization of KBQA.1\n",
      "Submission Date: 03 June 2021\n",
      "DOI Link: https://doi.org/10.1145/3442381.3449992\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3626111.3628206\n",
      "PDF Link: None\n",
      "Title:Simplifying Cloud Management with Cloudless Computing\n",
      "Authors: YimingQiu, Patrick Tser JernKon, JiarongXing, YiboHuang, HongyiLiu, XinyuWang, PengHuang, MosharafChowdhury, AngChen\n",
      "Abstract: Cloud computing has transformed the IT industry, but managing cloud infrastructures remains a difficult task. We make a case for putting today's management practices, known as \"Infrastructure-as-Code,\" on a firmer ground via a principled design. We call this end goal Cloudless Computing: it aims to simplify cloud infrastructure management tasks by supporting them \"as-a-service,\" analogous to serverless computing that relieves users of the burden of managing server instances. By assisting tenants with these tasks, cloud resources will be presented to their users more readily without the undue burden of complex control. We describe the research problems by examining the typical lifecycle of today's cloud infrastructure management, and identify places where a cloudless approach will advance the state of the art.\n",
      "Submission Date: 28 November 2023\n",
      "DOI Link: https://doi.org/10.1145/3626111.3628206\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3641399.3641403\n",
      "PDF Link: None\n",
      "Title:Accelerating Software Development Using Generative AI: ChatGPT Case Study\n",
      "Authors: AshaRajbhoj, AkankshaSomase, PiyushKulkarni, VinayKulkarni\n",
      "Abstract: The Software Development Life Cycle (SDLC) comprises multiple phases, each requiring Subject Matter Experts (SMEs) with phase-specific skills. The efficacy and quality of deliverables of each phase are skill dependent. In recent times, Generative AI techniques, including Large-scale Language Models (LLMs) like GPT, have become significant players in software engineering. These models, trained on extensive text data, can offer valuable contributions to software development. Interacting with LLMs involves feeding prompts with the context information and guiding the generation of textual responses. The quality of the response is dependent on the quality of the prompt given. This paper proposes a systematic prompting approach based on meta-model concepts for SDLC phases. The approach is validated using ChatGPT for small but complex business application development. We share the approach and our experience, learnings, benefits obtained, and the challenges encountered while applying the approach using ChatGPT. Our experience indicates that Generative AI techniques, such as ChatGPT, have the potential to reduce the skills barrier and accelerate software development substantially.\n",
      "Submission Date: 22 February 2024\n",
      "DOI Link: https://doi.org/10.1145/3641399.3641403\n",
      "Processing link: https://dl.acm.org/doi/proceedings/10.1145/3708359\n",
      "PDF Link: None\n",
      "Title:None\n",
      "Author: None\n",
      "Abstract: None\n",
      "Submission Date: None\n",
      "DOI Link: None\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3555041.3589406\n",
      "PDF Link: None\n",
      "Title:Demystifying Artificial Intelligence for Data Preparation\n",
      "Authors: ChengliangChai, NanTang, JuFan, YuyuLuo\n",
      "Abstract: Data preparation -- the process of discovering, integrating, transforming, cleaning, and annotating data -- is one of the oldest, hardest, yet inevitable data management problems. Unfortunately, data preparation is known to be iterative, requires high human cost, and is error-prone. Recent advances in artificial intelligence (AI) have shown very promising results on many data preparation tasks. At a high level, AI for data preparation (AI4DP) should have the following abilities. First, the AI model should capture real-world knowledge so as to solve various tasks. Second, it is important to easily adapt to new datasets/tasks. Third, data preparation is a complicated pipeline with many operations, which results in a large number of candidates to select the optimum, and thus it is crucial to effectively and efficiently explore the large space of possible pipelines. In this tutorial, we will cover three important topics to address the above issues: demystifying foundation models to inject knowledge for data preparation, tuning and adapting pre-trained language models for data preparation, and orchestrating data preparation pipelines for different downstream applications.\n",
      "Submission Date: 05 June 2023\n",
      "DOI Link: https://doi.org/10.1145/3555041.3589406\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3627673.3679589\n",
      "PDF Link: None\n",
      "Title:Inferring Visualization Intent from Conversation\n",
      "Authors: HaotianLi, NithinChalapathi, HuaminQu, AlvinCheung, Aditya G.Parameswaran\n",
      "Abstract: During visual data analysis, users often explore visualizations one at a time, with each visualization leading to new directions of exploration. We consider a conversational approach to visualization, where users specify their needs at each step in natural language, with a visualization being returned in turn. Prior work has shown that visualization generation can be boiled down to the identification of visualization intent and visual encodings. Recognizing that the latter is a well-studied problem with standard solutions, we focus on the former, i.e., identifying visualization intent during conversation. We develop Luna, a framework that comprises a novel combination of language models adapted from BERT and rule-based inference, that together predict various aspects of visualization intent. We compare Luna with other conversational NL-to-visualization and NL-to-SQL approaches (adapted to visualization intent), including GPT-3.5 and GPT-4, and demonstrate that Luna has 14.3% higher accuracy than the state-of-the-art. We also apply Luna to a usage scenario on a dataset of police misconduct, showcasing its benefits relative to other approaches.\n",
      "Submission Date: 21 October 2024\n",
      "DOI Link: https://doi.org/10.1145/3627673.3679589\n",
      "Processing link: https://dl.acm.org/doi/10.1109/JCDL57899.2023.00028\n",
      "PDF Link: None\n",
      "Title:Binding Data Narrations - Corroborating the Plausibility of Scientific Narratives by Open Research Data\n",
      "Authors: DenisNagel, TillAffeldt, NilsVoges, UlrichGüntzer, Wolf-TiloBalke\n",
      "Abstract: Narratives determine our worldviews, but need evidence to be believable. For scientific narratives, hard evidence usually is provided by specially curated research data and experiments within each publication. The aim is to strengthen the narratives' overall plausibility: the less plausible a narrative is, the more it is bound to be challenged. As recent advances in NLP enabled the scientific community to tackle important problems in fact-checking and more profound semantic interpretations of structured data, there is now also hope to unlock the rich narrative knowledge that such data sets can offer. Yet, current strategies to extract such narrative knowledge still heavily rely on exhaustive bottom-up analysis to cast insights from data into a human-understandable form. In this paper, we take a novel integration-based approach to design a system that reduces the task of finding narrative evidence to applying a sequence of simpler top-down matching tasks. Our BiND system builds upon an expressive definition of structured narratives. It uses them as templates for schema and instance matching against web tables, thereby computing flexible bindings between narratives and data. By combining structured narratives with a carefully chosen selection of statistical metrics to assess the inherent relationships between different attributes of the matched data, our system allows us to reliably identify the most plausible witnesses for a given narrative. We demonstrate the applicability of our system in the real world on the vast open data repository of the World Health Organization (WHO).\n",
      "Submission Date: 04 September 2024\n",
      "DOI Link: https://doi.org/10.1109/JCDL57899.2023.00028\n",
      "Processing link: https://dl.acm.org/doi/proceedings/10.1145/3617023\n",
      "PDF Link: None\n",
      "Title:None\n",
      "Author: None\n",
      "Abstract: None\n",
      "Submission Date: None\n",
      "DOI Link: None\n",
      "Processing link: https://dl.acm.org/doi/10.14778/3717755.3717772\n",
      "PDF Link: None\n",
      "Title:Sphinteract: Resolving Ambiguities in NL2SQL through User Interaction\n",
      "Authors: FuhengZhao, ShaleenDeep, FotisPsallidas, AvriliaFloratou, DivyakantAgrawal, Amr ElAbbadi\n",
      "Abstract: Translating natural language questions into SQL queries (NL2SQL) is a challenging task of great practical importance. Prior work has extensively studied how to address NL2SQL using Large Language Models (LLMs) with solutions ranging from careful prompt engineering, to fine-tuning existing LLMs, or even training custom models. However, a remaining challenging problem in NL2SQL is the inherent ambiguity in the natural language questions asked by users. In this paper, we introduce Sphinteract, a framework designed to assist LLMs in generating high-quality SQL answers that accurately reflect the user intent. Our key insight to resolve ambiguity is to take into account minimal user feedback interactively. We introduce the Summarize, Review, Ask (SRA) paradigm, which guides LLMs in identifying ambiguities in NL2SQL tasks and generates targeted questions for the user to answer. We propose three different methods of how to process user feedback and generate SQL queries based on user input. Our experiments on the challenging KaggleDBQA and BIRD benchmarks demonstrate that by means of asking clarification questions to the user, LLMs can efficiently incorporate the feedback, resulting in accuracy improvements of up to 42%.\n",
      "Submission Date: 20 May 2025\n",
      "DOI Link: https://doi.org/10.14778/3717755.3717772\n",
      "Processing link: https://dl.acm.org/doi/10.14778/3574245.3574258\n",
      "PDF Link: None\n",
      "Title:Can Foundation Models Wrangle Your Data?\n",
      "Authors: AvanikaNarayan, InesChami, LaurelOrr, ChristopherRé\n",
      "Abstract: Foundation Models (FMs) are models trained on large corpora of data that, at very large scale, can generalize to new tasks without any task-specific finetuning. As these models continue to grow in size, innovations continue to push the boundaries of what these models can do on language and image tasks. This paper aims to understand an underexplored area of FMs: classical data tasks like cleaning and integration. As a proof-of-concept, we cast five data cleaning and integration tasks as prompting tasks and evaluate the performance of FMs on these tasks. We find that large FMs generalize and achieve SoTA performance on data cleaning and integration tasks, even though they are not trained for these data tasks. We identify specific research challenges and opportunities that these models present, including challenges with private and domain specific data, and opportunities to make data management systems more accessible to non-experts. We make our code and experiments publicly available at: https://github.com/HazyResearch/fm_data_tasks.\n",
      "Submission Date: 01 December 2022\n",
      "DOI Link: https://doi.org/10.14778/3574245.3574258\n",
      "Processing link: https://dl.acm.org/doi/10.1109/JCDL57899.2023.00029\n",
      "PDF Link: None\n",
      "Title:Enriching Simple Keyword Queries for Domain-Aware Narrative Retrieval\n",
      "Authors: HermannKroll, Christin KatharinaKreutz, PascalSackhoff, Wolf-TiloBalke\n",
      "Abstract: Providing effective access paths to content is a key task in digital libraries. Oftentimes, such access paths are realized through advanced query languages, which, on the one hand, users may find challenging to learn or use, and on the other, requires libraries to convert their content into a high quality structured representation. As a remedy, narrative information access proposes to query library content through structured patterns directly, to ensure validity and coherence of information. However, users still find it challenging to express their information needs in such patterns. Therefore, this work bridges the gap by introducing a method that deduces patterns from keyword searches. Moreover, our user studies with participants from the biomedical domain show their acceptance of our prototypical system.\n",
      "Submission Date: 04 September 2024\n",
      "DOI Link: https://doi.org/10.1109/JCDL57899.2023.00029\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3691620.3695503\n",
      "PDF Link: https://dl.acm.org/doi/pdf/10.1145/3691620.3695503\n",
      "Title:Contextualized Data-Wrangling Code Generation in Computational Notebooks\n",
      "Authors: JunjieHuang, DayaGuo, ChenglongWang, JiazhenGu, ShuaiLu, Jeevana PriyaInala, CongYan, JianfengGao, NanDuan, Michael R.Lyu\n",
      "Abstract: Data wrangling, the process of preparing raw data for further analysis in computational notebooks, is a crucial yet time-consuming step in data science. Code generation has the potential to automate the data wrangling process to reduce analysts' overhead by translating user intents into executable code. Precisely generating data wrangling code necessitates a comprehensive consideration of the rich context present in notebooks, including textual context, code context and data context. However, notebooks often interleave multiple non-linear analysis tasks into linear sequence of code blocks, where the contextual dependencies are not clearly reflected. Directly training models with source code blocks fails to fully exploit the contexts for accurate wrangling code generation. To bridge the gap, we aim to construct a high quality datasets with clear and rich contexts to help training models for data wrangling code generation tasks. In this work, we first propose an automated approach, CoCoMine to mine data-wrangling code generation examples with clear multi-modal contextual dependency. It first adopts data flow analysis to identify the code blocks containing data wrangling codes. Then, CoCoMine extracts the contextualized data-wrangling code examples through tracing and replaying notebooks. With CoCoMine, we construct CoCoNote, a dataset containing 58,221 examples for Contextualized Data-wrangling Code generation in Notebooks. To demonstrate the effectiveness of our dataset, we finetune a range of pretrained code models and prompt various large language models on our task. Furthermore, we also propose Data-Coder, which encodes data context and code&textual contexts separately to enhance code generation. Experiment results demonstrate the significance of incorporating data context in data-wrangling code generation and the effectiveness of our model. We release code and data at https://github.com/Jun-jie-Huang/CoCoNote.\n",
      "Submission Date: 27 October 2024\n",
      "DOI Link: https://doi.org/10.1145/3691620.3695503\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3299869.3300105\n",
      "PDF Link: https://dl.acm.org/doi/pdf/10.1145/3299869.3300105\n",
      "Title:Bootstrapping an End-to-End Natural Language Interface for Databases\n",
      "Authors: NathanielWeir, PrasetyaUtama\n",
      "Abstract: The ability to extract insights from data is critical for decision making. Intuitive natural language interfaces to databases provide non-technical users with an effective way to formulate complex questions and information needs efficiently and effectively. A recent trend in the area of Natural Language Interfaces for Databases (NLIDBs) has been the use of neural machine translation models to synthesize executable Structured Query Language (SQL) queries from natural language utterances. The main bottleneck in this type of approach is the acquisition of examples for training the model. Recent work has assumed access to a rich manually-curated training set for a given target database. However, this assumption ignores the large manual overhead required to curate the training set for any new database. As a result, NLIDB systems that can simply 'plug in' to any new database and perform effectively for naive users have yet to make their way into commercial products. Here we present DBPal, an end-to-end NLIDB framework in which a neural translation model is trained for any new database schema with minimal manual overhead. In addition to being the first off-the-shelf, neural machine translationbased system of its kind, the contributions of our project are 1) its use of a synthetic training set generation pipeline used to bootstrap a translation model without requiring manually curated data, and 2) its use of state-of-the-art multi-task and cross-domain learning techniques that increases the robustness of the translation model towards unseen linguistic phenomena in new domains. In experiments we show that our system can achieve competitive performance on the recently released benchmarks for nl-to-sql translation. Through ablation experiments we show the benefit of using cross-domain learning techniques on the performance of the system. In a user study we show that DBPal outperforms a well-known rule-based NLIDB and performs comparably to an approach using a similar neural model that relies on manually curated data.\n",
      "Submission Date: 25 June 2019\n",
      "DOI Link: https://doi.org/10.1145/3299869.3300105\n",
      "Processing link: https://dl.acm.org/doi/10.14778/3625054.3625066\n",
      "PDF Link: None\n",
      "Title:Can Large Language Models Predict Data Correlations from Column Names?\n",
      "Authors: ImmanuelTrummer\n",
      "Abstract: Recent publications suggest using natural language analysis on database schema elements to guide tuning and profiling efforts. The underlying hypothesis is that state-of-the-art language processing methods, so-called language models, are able to extract information on data properties from schema text. This paper examines that hypothesis in the context of data correlation analysis: is it possible to find column pairs with correlated data by analyzing their names via language models? First, the paper introduces a novel benchmark for data correlation analysis, created by analyzing thousands of Kaggle data sets (and available for download). Second, it uses that data to study the ability of language models to predict correlation, based on column names. The analysis covers different language models, various correlation metrics, and a multitude of accuracy metrics. It pinpoints factors that contribute to successful predictions, such as the length of column names as well as the ratio of words. Finally, the study analyzes the impact of column types on prediction performance. The results show that schema text can be a useful source of information and inform future research efforts, targeted at NLP-enhanced database tuning and data profiling.\n",
      "Submission Date: 01 September 2023\n",
      "DOI Link: https://doi.org/10.14778/3625054.3625066\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3539618.3591708\n",
      "PDF Link: None\n",
      "Title:Large Language Models are Versatile Decomposers: Decomposing Evidence and Questions for Table-based Reasoning\n",
      "Authors: YunhuYe, BinyuanHui, MinYang, BinhuaLi, FeiHuang, YongbinLi\n",
      "Abstract: Table-based reasoning has shown remarkable progress in a wide range of table-based tasks. It is a challenging task, which requires reasoning over both free-form natural language (NL) questions and (semi-)structured tabular data. However, previous table-based reasoning solutions usually suffer from significant performance degradation on ''huge'' evidence (tables). In addition, most existing methods struggle to reason over complex questions since the essential information is scattered in different places. To alleviate the above challenges, we exploit large language models (LLMs) as decomposers for effective table-based reasoning, which (i) decompose huge evidence (a huge table) into sub-evidence (a small table) to mitigate the interference of useless information for table reasoning, and (ii) decompose a complex question into simpler sub-questions for text reasoning. First, we use a powerful LLM to decompose the evidence involved in the current question into the sub-evidence that retains the relevant information and excludes the remaining irrelevant information from the ''huge'' evidence. Second, we propose a novel ''parsing-execution-filling'' strategy to decompose a complex question into simper step-by-step sub-questions by generating intermediate SQL queries as a bridge to produce numerical and logical sub-questions with a powerful LLM. Finally, we leverage the decomposed sub-evidence and sub-questions to get the final answer with a few in-context prompting examples. Extensive experiments on three benchmark datasets (TabFact, WikiTableQuestion, and FetaQA) demonstrate that our method achieves significantly better results than competitive baselines for table-based reasoning. Notably, our method outperforms human performance for the first time on the TabFact dataset. In addition to impressive overall performance, our method also has the advantage of interpretability, where the returned results are to some extent tractable with the generated sub-evidence and sub-questions. For reproducibility, we release our source code and data at: https://github.com/AlibabaResearch/DAMO-ConvAI.\n",
      "Submission Date: 18 July 2023\n",
      "DOI Link: https://doi.org/10.1145/3539618.3591708\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3297280.3297523\n",
      "PDF Link: None\n",
      "Title:Meet cyrus: the query by voice mobile assistant for the tutoring and formative assessment of SQL learners\n",
      "Authors: Josue EspinosaGodinez, Hasan M.Jamil\n",
      "Abstract: Being declarative, SQL stands a better chance at being the programming language for conceptual computing next to natural language programming. We examine the possibility of using SQL as a back-end for natural language database programming. Distinctly from keyword based SQL querying, keyword dependence and SQL's table structure constraints are significantly less pronounced in our approach. We present a mobile device voice query interface, called Cyrus, to arbitrary relational databases. Cyrus supports a large type of query classes, sufficient for an entry level database class. Cyrus is also application independent, allows test database adaptation, and not limited to specific sets of keywords or natural language sentence structures. It's cooperative error reporting is more intuitive, and iOS based mobile platform is also more accessible compared to most contemporary mobile and voice enabled systems.\n",
      "Submission Date: 08 April 2019\n",
      "DOI Link: https://doi.org/10.1145/3297280.3297523\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3698831\n",
      "PDF Link: None\n",
      "Title:CtxPipe: Context-aware Data Preparation Pipeline Construction for Machine Learning\n",
      "Authors: HaotianGao, ShaofengCai, Tien Tuan AnhDinh, ZhiyongHuang, Beng ChinOoi\n",
      "Abstract: Machine learning models are only as good as their training data. Simple models trained on well-chosen features extracted from the raw data often outperform complex models trained directly on the raw data. Data preparation pipelines, which clean and derive features from the data, are therefore important for machine learning applications. However, constructing such pipelines is a resource-intensive process that involves deep human expertise. Our goal is to design an efficient framework for automatically finding high-quality data preparation pipelines. The main challenge is how to explore a large search space of pipeline components with the objective of computing features that maximize the performance of the downstream models. Existing solutions are limited in terms of feature quality, which results in low accuracies of the downstream models, while incurring significant runtime overhead. We present CtxPipe, a novel framework that addresses the limitations of previous works by leveraging contextual information to improve the pipeline construction process. Specifically, it uses pre-trained embedding models to capture the data semantics, which are then used to guide the selection of pipeline components. We implement CtxPipe with deep reinforcement learning and evaluate it against state-of-the-art automated pipeline construction solutions. Our comprehensive experiments demonstrate that CtxPipe outperforms all of the baselines in both model performance and runtime cost.\n",
      "Submission Date: 20 December 2024\n",
      "DOI Link: https://doi.org/10.1145/3698831\n",
      "Processing link: https://dl.acm.org/doi/10.14778/3681954.3681960\n",
      "PDF Link: None\n",
      "Title:Combining Small Language Models and Large Language Models for Zero-Shot NL2SQL\n",
      "Authors: JuFan, ZihuiGu, SongyueZhang, YuxinZhang, ZuiChen, LeiCao, GuoliangLi, SamuelMadden, XiaoyongDu, NanTang\n",
      "Abstract: Zero-shot natural language to SQL (NL2SQL) aims to generalize pretrained NL2SQL models to new environments (e.g., new databases and new linguistic phenomena) without any annotated NL2SQL samples from these environments. Existing approaches either use small language models (SLMs) like BART and T5, or prompt large language models (LLMs). However, SLMs may struggle with complex natural language reasoning, and LLMs may not precisely align schemas to identify the correct columns or tables. In this paper, we propose a ZeroNL2SQL framework, which divides NL2SQL into smaller sub-tasks and utilizes both SLMs and LLMs. ZeroNL2SQL first fine-tunes SLMs for better generalizability in SQL structure identification and schema alignment, producing an SQL sketch. It then uses LLMs's language reasoning capability to fill in the missing information in the SQL sketch. To support ZeroNL2SQL, we propose novel database serialization and question-aware alignment methods for effective sketch generation using SLMs. Additionally, we devise a multi-level matching strategy to recommend the most relevant values to LLMs, and select the optimal SQL query via an execution-based strategy. Comprehensive experiments show that ZeroNL2SQL achieves the best zero-shot NL2SQL performance on benchmarks, i.e., outperforming the state-of-the-art SLM-based methods by 5.5% to 16.4% and exceeding LLM-based methods by 10% to 20% on execution accuracy.\n",
      "Submission Date: 01 July 2024\n",
      "DOI Link: https://doi.org/10.14778/3681954.3681960\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3386723.3387820\n",
      "PDF Link: None\n",
      "Title:Inferring SQL Queries Using Interactivity\n",
      "Authors: KaramAhkouk, MustaphaMachkour, JilaliAntari\n",
      "Abstract: Interactivity in language processing plays a pivotal role to allow models to better understand how to build the appropriate output. In the task of Natural Language to SQL, the fact of including the users' interactivity can be one of the practical solutions that haven't been studied deeply in the existing works published in the last decade. Using databases by users with limited familiarity in SQL will create an additional obstacle for these users to better exploit the content stored in the database systems. In this paper we present the already published studies and we discuss the utility of using the interactivity to definitely improve the query generation process in order to construct a model that generalize for unseen and complex sentences and to automatically generate the appropriate outputs.\n",
      "Submission Date: 18 May 2020\n",
      "DOI Link: https://doi.org/10.1145/3386723.3387820\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3580305.3599395\n",
      "PDF Link: https://dl.acm.org/doi/pdf/10.1145/3580305.3599395\n",
      "Title:Investigating Trojan Attacks on Pre-trained Language Model-powered Database Middleware\n",
      "Authors: PeiranDong, SongGuo, JunxiaoWang\n",
      "Abstract: The recent success of pre-trained language models (PLMs) such as BERT has resulted in the development of various beneficial database middlewares, including natural language query interfaces and entity matching. This shift has been greatly facilitated by the extensive external knowledge of PLMs. However, as PLMs are often provided by untrusted third parties, their lack of standardization and regulation poses significant security risks that have yet to be fully explored. This paper investigates the security threats posed by malicious PLMs to these emerging database middleware. We specifically propose a novel type of Trojan attack, where a maliciously designed PLM causes unexpected behavior in the database middleware. These Trojan attacks possess the following characteristics: (1) Triggerability: The Trojan-infected database middleware will function normally with normal input, but will likely malfunction when triggered by the attacker. (2) Imperceptibility: There is no need for noticeable modification of the input to trigger the Trojan. (3) Generalizability: The Trojan is capable of targeting a variety of downstream tasks, not just one specific task. We thoroughly evaluate the impact of these Trojan attacks through experiments and analyze potential countermeasures and their limitations. Our findings could aid in the creation of stronger mechanisms for the implementation of PLMs in database middleware.\n",
      "Submission Date: 04 August 2023\n",
      "DOI Link: https://doi.org/10.1145/3580305.3599395\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3578337.3605127\n",
      "PDF Link: None\n",
      "Title:Dense Retrieval Adaptation using Target Domain Description\n",
      "Authors: HeliaHashemi, YongZhuang, Sachith Sri RamKothur, SrivasPrasad, EdgarMeij, W. BruceCroft\n",
      "Abstract: In information retrieval (IR), domain adaptation is the process of adapting a retrieval model to a new domain whose data distribution is different from the source domain. Existing methods in this area focus on unsupervised domain adaptation where they have access to the target document collection or supervised (often few-shot) domain adaptation where they additionally have access to (limited) labeled data in the target domain. There also exists research on improving zero-shot performance of retrieval models with no adaptation. This paper introduces a new category of domain adaptation in IR that is as-yet unexplored. Here, similar to the zero-shot setting, we assume the retrieval model does not have access to the target document collection. In contrast, it does have access to a brief textual description that explains the target domain. We define a taxonomy of domain attributes in retrieval tasks to understand different properties of a source domain that can be adapted to a target domain. We introduce a novel automatic data construction pipeline that produces a synthetic document collection, query set, and pseudo relevance labels, given a textual domain description. Extensive experiments on five diverse target domains show that adapting dense retrieval models using the constructed synthetic data leads to effective retrieval performance on the target domain.\n",
      "Submission Date: 09 August 2023\n",
      "DOI Link: https://doi.org/10.1145/3578337.3605127\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3712060\n",
      "PDF Link: https://dl.acm.org/doi/pdf/10.1145/3712060\n",
      "Title:Natural Language Processing for Dialects of a Language: A Survey\n",
      "Authors: AdityaJoshi, RajDabre, DipteshKanojia, ZhuangLi, HaolanZhan, GholamrezaHaffari, DorisDippold\n",
      "Abstract: State-of-the-art natural language processing (NLP) models are trained on massive training corpora, and report a superlative performance on evaluation datasets. This survey delves into an important attribute of these datasets: the dialect of a language. Motivated by the performance degradation of NLP models for dialectal datasets and its implications for the equity of language technologies, we survey past research in NLP for dialects in terms of datasets, and approaches. We describe a wide range of NLP tasks in terms of two categories: natural language understanding (NLU) (for tasks such as dialect classification, sentiment analysis, parsing, and NLU benchmarks) and natural language generation (NLG) (for summarisation, machine translation, and dialogue systems). The survey is also broad in its coverage of languages which include English, Arabic, German, among others. We observe that past work in NLP concerning dialects goes deeper than mere dialect classification, and extends to several NLU and NLG tasks. For these tasks, we describe classical machine learning using statistical models, along with the recent deep learning-based approaches based on pre-trained language models. We expect that this survey will be useful to NLP researchers interested in building equitable language technologies by rethinking LLM benchmarks and model architectures.\n",
      "Submission Date: 10 February 2025\n",
      "DOI Link: https://doi.org/10.1145/3712060\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3660807\n",
      "PDF Link: https://dl.acm.org/doi/pdf/10.1145/3660807\n",
      "Title:Do Large Language Models Pay Similar Attention Like Human Programmers When Generating Code?\n",
      "Authors: BonanKou, ShengmaiChen, ZhijieWang, LeiMa, TianyiZhang\n",
      "Abstract: Large Language Models (LLMs) have recently been widely used for code generation. Due to the complexity and opacity of LLMs, little is known about how these models generate code. We made the first attempt to bridge this knowledge gap by investigating whether LLMs attend to the same parts of a task description as human programmers during code generation. An analysis of six LLMs, including GPT-4, on two popular code generation benchmarks revealed a consistent misalignment between LLMs' and programmers' attention. We manually analyzed 211 incorrect code snippets and found five attention patterns that can be used to explain many code generation errors. Finally, a user study showed that model attention computed by a perturbation-based method is often favored by human programmers. Our findings highlight the need for human-aligned LLMs for better interpretability and programmer trust.\n",
      "Submission Date: 12 July 2024\n",
      "DOI Link: https://doi.org/10.1145/3660807\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3706598.3713913\n",
      "PDF Link: https://dl.acm.org/doi/pdf/10.1145/3706598.3713913\n",
      "Title:Jupybara: Operationalizing a Design Space for Actionable Data Analysis and Storytelling with LLMs\n",
      "Authors: Huichen WillWang, LarryBirnbaum, VidyaSetlur\n",
      "Abstract: Mining and conveying actionable insights from complex data is a key challenge of exploratory data analysis (EDA) and storytelling. To address this challenge, we present a design space for actionable EDA and storytelling. Synthesizing theory and expert interviews, we highlight how semantic precision, rhetorical persuasion, and pragmatic relevance underpin effective EDA and storytelling. We also show how this design space subsumes common challenges in actionable EDA and storytelling, such as identifying appropriate analytical strategies and leveraging relevant domain knowledge. Building on the potential of LLMs to generate coherent narratives with commonsense reasoning, we contribute Jupybara, an AI-enabled assistant for actionable EDA and storytelling implemented as a Jupyter Notebook extension. Jupybara employs two strategies—design-space-aware prompting and multi-agent architectures—to operationalize our design space. An expert evaluation confirms Jupybara’s usability, steerability, explainability, and reparability, as well as the effectiveness of our strategies in operationalizing the design space framework with LLMs.\n",
      "Submission Date: 25 April 2025\n",
      "DOI Link: https://doi.org/10.1145/3706598.3713913\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3663363\n",
      "PDF Link: None\n",
      "Title:Multi-Task Learning in Natural Language Processing: An Overview\n",
      "Authors: ShijieChen, YuZhang, QiangYang\n",
      "Abstract: Deep learning approaches have achieved great success in the field of Natural Language Processing (NLP). However, directly training deep neural models often suffer from overfitting and data scarcity problems that are pervasive in NLP tasks. In recent years, Multi-Task Learning (MTL), which can leverage useful information of related tasks to achieve simultaneous performance improvement on these tasks, has been used to handle these problems. In this article, we give an overview of the use of MTL in NLP tasks. We first review MTL architectures used in NLP tasks and categorize them into four classes, including parallel architecture, hierarchical architecture, modular architecture, and generative adversarial architecture. Then we present optimization techniques on loss construction, gradient regularization, data sampling, and task scheduling to properly train a multi-task model. After presenting applications of MTL in a variety of NLP tasks, we introduce some benchmark datasets. Finally, we make a conclusion and discuss several possible research directions in this field.\n",
      "Submission Date: 25 July 2024\n",
      "DOI Link: https://doi.org/10.1145/3663363\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3571884.3597130\n",
      "PDF Link: https://dl.acm.org/doi/pdf/10.1145/3571884.3597130\n",
      "Title:Programming by Voice: Exploring User Preferences and Speaking Styles\n",
      "Authors: SadiaNowrin, KeithVertanen\n",
      "Abstract: Programming by voice is a potentially useful method for individuals with motor impairments. Spoken programs can be challenging for a standard speech recognizer with a language model trained on written text mined from sources such as web pages. Having an effective language model that captures the variability in spoken programs may be necessary for accurate recognition. In this work, we explore how novice and expert programmers speak code without requiring them to adhere to strict grammar rules. We investigate two approaches to collect data by having programmers speak either highlighted or missing lines of code. We observed that expert programmers spoke more naturally, while novice programmers spoke more syntactically. A commercial speech recognizer had a high error rate on our spoken programs. However, by adapting the recognizer’s language model with our spoken code transcripts, we were able to substantially reduce the error rate by 27% relative to the baseline on unseen spoken code.\n",
      "Submission Date: 19 July 2023\n",
      "DOI Link: https://doi.org/10.1145/3571884.3597130\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3491102.3517612\n",
      "PDF Link: None\n",
      "Title:OneLabeler: A Flexible System for Building Data Labeling Tools\n",
      "Authors: YuZhang, YunWang, HaidongZhang, BinZhu, SimingChen, DongmeiZhang\n",
      "Abstract: Labeled datasets are essential for supervised machine learning. Various data labeling tools have been built to collect labels in different usage scenarios. However, developing labeling tools is time-consuming, costly, and expertise-demanding on software development. In this paper, we propose a conceptual framework for data labeling and OneLabeler based on the conceptual framework to support easy building of labeling tools for diverse usage scenarios. The framework consists of common modules and states in labeling tools summarized through coding of existing tools. OneLabeler supports configuration and composition of common software modules through visual programming to build data labeling tools. A module can be a human, machine, or mixed computation procedure in data labeling. We demonstrate the expressiveness and utility of the system through ten example labeling tools built with OneLabeler. A user study with developers provides evidence that OneLabeler supports efficient building of diverse data labeling tools.\n",
      "Submission Date: 28 April 2022\n",
      "DOI Link: https://doi.org/10.1145/3491102.3517612\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3555041.3589678\n",
      "PDF Link: None\n",
      "Title:DataChat: An Intuitive and Collaborative Data Analytics Platform\n",
      "Authors: Rogers Jeffrey LeoJohn, DylanBacon, JundaChen, UshmalRamesh, JiatongLi, DeepanDas, RobertClaus, AmosKendall, Jignesh M.Patel\n",
      "Abstract: Enterprises invest in data platforms with the aim of extracting meaningful information through analytics. Typically, experts create analytics pipelines that feed into dashboards and provide answers to predetermined questions. This approach makes analytics a spectator sport for most people and introduces operational bottlenecks to leveraging those investments. To improve the value derived from data, many organizations are opting to open up their data assets and allow access to a wider range of users. However, using programming languages such as SQL and Python for analytics can be difficult for most enterprise users. DataChat provides a simplified data science approach that is intuitive, powerful, and accessible to all data users. The platform is built on a library of data functions that are cleanly abstracted to maximize efficiency and ease of use while maintaining a rich suite of tools necessary for data science. With these functions, users can create data analysis pipelines by using a simple point-and-click interface in a spreadsheet view or by using natural English interfaces. Modern sharing and collaboration features are central to all aspects of the platform, allowing teams to easily bridge expertise gaps. A deeper understanding of results is facilitated by providing automatically-generated English explanations of how they were derived. By enhancing these aspects of data science and human-to-human communication, the platform addresses the needs that many organizations are encountering as their analytics needs mature.\n",
      "Submission Date: 05 June 2023\n",
      "DOI Link: https://doi.org/10.1145/3555041.3589678\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3654966\n",
      "PDF Link: None\n",
      "Title:PreLog: A Pre-trained Model for Log Analytics\n",
      "Authors: Van-HoangLe, HongyuZhang\n",
      "Abstract: Large-scale software-intensive systems often produce a large volume of logs to record runtime status and events for troubleshooting purposes. The rich information in log data enables a variety of system management and diagnosis tasks. Over the years, many approaches have been proposed for automated log analytics. However, these approaches usually design separate models for each specific task, which cannot be generalized to other tasks. They are also not robust when dealing with logs from heterogeneous sources. In this paper, we propose PreLog, a novel pre-trained model for log analytics. PreLog is pre-trained on a large amount of unlabelled log data to capture the semantic meaning of logs. We design two log-specific pre-training objectives, including entry-level and sequence-level objectives, which enable PreLog to better understand the hidden structure and semantics of logs. To perform downstream log analytics tasks, we leverage a prompt tuning paradigm to convert downstream tasks' objectives into a similar form as the pre-training stage. We have conducted extensive experiments on two main log analytics tasks (i.e., log parsing and log-based anomaly detection). Experimental results show that PreLog achieves better or comparable results in comparison with the state-of-the-art, task-specific approaches. PreLog is cost-effective and can be uniformly applied to many log analytics tasks through the prompt tuning paradigm.\n",
      "Submission Date: 30 May 2024\n",
      "DOI Link: https://doi.org/10.1145/3654966\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3665930\n",
      "PDF Link: None\n",
      "Title:BUNNI: Learning Repair Actions in Rule-driven Data Cleaning\n",
      "Authors: GiansalvatoreMecca, PaoloPapotti, DonatelloSantoro, EnzoVeltri\n",
      "Abstract: In this work, we address the challenging and open problem of involving non-expert users in the data repairing problem as first-class citizens. Despite a large number of proposals that have been devoted to cleaning data from the point of view of expert users (IT staff and data scientists), there is a lack of studies from the perspective of non-expert ones. Given a set of available data quality rules, we exploit machine learning techniques to guide the user to identify the dirty values for each violation and repair them. We show that with a low user effort, it is possible to identify the values in tuples that can be trusted and the ones that are most likely errors. We show experimentally how this machine learning approach leads to a unique clean solution with high quality in scenarios where other approaches fail.\n",
      "Submission Date: 24 June 2024\n",
      "DOI Link: https://doi.org/10.1145/3665930\n",
      "Processing link: https://dl.acm.org/doi/10.14778/3611540.3611557\n",
      "PDF Link: None\n",
      "Title:Real-Time Workload Pattern Analysis for Large-Scale Cloud Databases\n",
      "Authors: JiaqiWang, TianyiLi, AnniWang, XiaozeLiu, LuChen, JieChen, JianyeLiu, JunyangWu, FeifeiLi, YunjunGao\n",
      "Abstract: Hosting database services on cloud systems has become a common practice. This has led to the increasing volume of database workloads, which provides the opportunity for pattern analysis. Discovering workload patterns from a business logic perspective is conducive to better understanding the trends and characteristics of the database system. However, existing workload pattern discovery systems are not suitable for large-scale cloud databases which are commonly employed by the industry. This is because the workload patterns of large-scale cloud databases are generally far more complicated than those of ordinary databases. In this paper, we propose Alibaba Workload Miner (AWM), a real-time system for discovering workload patterns in complicated large-scale workloads. AW M encodes and discovers the SQL query patterns logged from user requests and optimizes the querying processing based on the discovered patterns. First, Data Collection & Preprocessing Module collects streaming query logs and encodes them into high-dimensional feature embeddings with rich semantic contexts and execution features. Next, Online Workload Mining Module separates encoded query by business groups and discovers the workload patterns for each group. Meanwhile, Offline Training Module collects labels and trains the classification model using the labels. Finally, Pattern-based Optimizing Module optimizes query processing in cloud databases by exploiting discovered patterns. Extensive experimental results on one synthetic dataset and two real-life datasets (extracted from Alibaba Cloud databases) show that AW M enhances the accuracy of pattern discovery by 66% and reduce the latency of online inference by 22%, compared with the state-of-the-arts.\n",
      "Submission Date: 01 August 2023\n",
      "DOI Link: https://doi.org/10.14778/3611540.3611557\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3514221.3517906\n",
      "PDF Link: None\n",
      "Title:Annotating Columns with Pre-trained Language Models\n",
      "Authors: YoshihikoSuhara, JinfengLi, YuliangLi, DanZhang, ÇağatayDemiralp, ChenChen, Wang-ChiewTan\n",
      "Abstract: Inferring meta information about tables, such as column headers or relationships between columns, is an active research topic in data management as we find many tables are missing some of this information. In this paper, we study the problem of annotating table columns (i.e., predicting column types and the relationships between columns) using only information from the table itself. We develop a multi-task learning framework (called Doduo) based on pre-trained language models, which takes the entire table as input and predicts column types/relations using a single model. Experimental results show that Doduo establishes new state-of-the-art performance on two benchmarks for the column type prediction and column relation prediction tasks with up to 4.0% and 11.9% improvements, respectively. We report that Doduo can already outperform the previous state-of-the-art performance with a minimal number of tokens, only 8 tokens per column. We release a toolbox (https://github.com/megagonlabs/doduo) and confirm the effectiveness of Doduo on a real-world data science problem through a case study.\n",
      "Submission Date: 11 June 2022\n",
      "DOI Link: https://doi.org/10.1145/3514221.3517906\n",
      "Processing link: https://dl.acm.org/doi/proceedings/10.1145/3665939\n",
      "PDF Link: None\n",
      "Title:None\n",
      "Author: None\n",
      "Abstract: None\n",
      "Submission Date: None\n",
      "DOI Link: None\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3510003.3510125\n",
      "PDF Link: None\n",
      "Title:Cross-domain deep code search with meta learning\n",
      "Authors: YitianChai, HongyuZhang, BeijunShen, XiaodongGu\n",
      "Abstract: Recently, pre-trained programming language models such as CodeBERT have demonstrated substantial gains in code search. Despite their success, they rely on the availability of large amounts of parallel data to fine-tune the semantic mappings between queries and code. This restricts their practicality in domain-specific languages with relatively scarce and expensive data. In this paper, we propose CDCS, a novel approach for domain-specific code search. CDCS employs a transfer learning framework where an initial program representation model is pre-trained on a large corpus of common programming languages (such as Java and Python), and is further adapted to domain-specific languages such as Solidity and SQL. Unlike cross-language CodeBERT, which is directly fine-tuned in the target language, CDCS adapts a few-shot meta-learning algorithm called MAML to learn the good initialization of model parameters, which can be best reused in a domain-specific language. We evaluate the proposed approach on two domain-specific languages, namely Solidity and SQL, with model transferred from two widely used languages (Python and Java). Experimental results show that CDCS significantly outperforms conventional pre-trained code models that are directly fine-tuned in domain-specific languages, and it is particularly effective for scarce data.\n",
      "Submission Date: 05 July 2022\n",
      "DOI Link: https://doi.org/10.1145/3510003.3510125\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3639279\n",
      "PDF Link: None\n",
      "Title:DTT: An Example-Driven Tabular Transformer for Joinability by Leveraging Large Language Models\n",
      "Authors: ArashDargahi Nobari, DavoodRafiei\n",
      "Abstract: Many organizations rely on data from government and third-party sources, and those sources rarely follow the same data formatting. This introduces challenges in integrating data from multiple sources or aligning external sources with internal databases. Commercial database systems do not offer adequate support for integrating data from heterogeneous sources, and manual integration is both time-consuming and inefficient. State-of-the-art data integration approaches that rely on similarity functions and textual transformations often fail to handle challenging cases where multiple mappings are required, or the mappings go beyond simple textual transformations. In this paper, we study the potentials of deep neural models for transforming tables for joinability. In particular, we cast the problem as a prediction task and develop a framework that leverages large deep-learning language models to transform tabular data from a source formatting to a desired target representation. Our framework can efficiently learn the patterns for mapping a source formatting into an expected target using just a few examples, which can then be used for tasks such as table joining, filling in missing values, and error detection. Compared to state-of-the-art mapping and joining approaches, our framework delivers noticeably more accurate and scalable performance on both real-world and synthetic datasets. Our experimental evaluation also shows that the performance of the proposed framework using our fine-tuned model is at par or better than large language models such as GPT-3, despite the significant difference in size, and that using large language models within our framework improves their performance.\n",
      "Submission Date: 26 March 2024\n",
      "DOI Link: https://doi.org/10.1145/3639279\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3510003.3510203\n",
      "PDF Link: None\n",
      "Title:Jigsaw: large language models meet program synthesis\n",
      "Authors: NamanJain, SkandaVaidyanath, ArunIyer, NagarajanNatarajan, SureshParthasarathy, SriramRajamani, RahulSharma\n",
      "Abstract: Large pre-trained language models such as GPT-3 [10], Codex [11], and Google's language model [7] are now capable of generating code from natural language specifications of programmer intent. We view these developments with a mixture of optimism and caution. On the optimistic side, such large language models have the potential to improve productivity by providing an automated AI pair programmer for every programmer in the world. On the cautionary side, since these large language models do not understand program semantics, they offer no guarantees about quality of the suggested code. In this paper, we present an approach to augment these large language models with post-processing steps based on program analysis and synthesis techniques, that understand the syntax and semantics of programs. Further, we show that such techniques can make use of user feedback and improve with usage. We present our experiences from building and evaluating such a tool Jigsaw, targeted at synthesizing code for using Python Pandas API using multi-modal inputs. Our experience suggests that as these large language models evolve for synthesizing code from intent, Jigsaw has an important role to play in improving the accuracy of the systems.\n",
      "Submission Date: 05 July 2022\n",
      "DOI Link: https://doi.org/10.1145/3510003.3510203\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3404835.3462909\n",
      "PDF Link: https://dl.acm.org/doi/pdf/10.1145/3404835.3462909\n",
      "Title:Retrieving Complex Tables with Multi-Granular Graph Representation Learning\n",
      "Authors: FeiWang, KexuanSun, MuhaoChen, JayPujara, PedroSzekely\n",
      "Abstract: The task of natural language table retrieval (NLTR) seeks to retrieve semantically relevant tables based on natural language queries. Existing learning systems for this task often treat tables as plain text based on the assumption that tables are structured as dataframes. However, tables can have complex layouts which indicate diverse dependencies between subtable structures, such as nested headers. As a result, queries may refer to different spans of relevant content that is distributed across these structures. Moreover, such systems fail to generalize to novel scenarios beyond those seen in the training set. Prior methods are still distant from a generalizable solution to the NLTR problem, as they fall short in handling complex table layouts or queries over multiple granularities. To address these issues, we propose Graph-based Table Retrieval (GTR), a generalizable NLTR framework with multi-granular graph representation learning. In our framework, a table is first converted into a tabular graph, with cell nodes, row nodes and column nodes to capture content at different granularities. Then the tabular graph is input to a Graph Transformer model that can capture both table cell content and the layout structures. To enhance the robustness and generalizability of the model, we further incorporate a self-supervised pre-training task based on graph-context matching. Experimental results on two benchmarks show that our method leads to significant improvements over the current state-of-the-art systems. Further experiments demonstrate promising performance of our method on cross-dataset generalization, and enhanced capability of handling complex tables and fulfilling diverse query intents.\n",
      "Submission Date: 11 July 2021\n",
      "DOI Link: https://doi.org/10.1145/3404835.3462909\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3588938\n",
      "PDF Link: None\n",
      "Title:Unicorn: A Unified Multi-tasking Model for Supporting Matching Tasks in Data Integration\n",
      "Authors: JianhongTu, JuFan, NanTang, PengWang, GuoliangLi, XiaoyongDu, XiaofengJia, SongGao\n",
      "Abstract: Data matching - which decides whether two data elements (e.g., string, tuple, column, or knowledge graph entity) are the \"same\" (a.k.a. a match) - is a key concept in data integration, such as entity matching and schema matching. The widely used practice is to build task-specific or even dataset-specific solutions, which are hard to generalize and disable the opportunities of knowledge sharing that can be learned from different datasets and multiple tasks. In this paper, we propose Unicorn, a unified model for generally supporting common data matching tasks. Unicorn can enable knowledge sharing by learning from multiple tasks and multiple datasets, and can also support zero-shot prediction for new tasks with zero labeled matching/non-matching pairs. However, building such a unified model is challenging due to heterogeneous formats of input data elements and various matching semantics of multiple tasks. To address the challenges, Unicorn employs one generic Encoder that converts any pair of data elements (a, b) into a learned representation, and uses a Matcher, which is a binary classifier, to decide whether a matches b. To align matching semantics of multiple tasks, Unicorn adopts a mixture-of-experts model that enhances the learned representation into a better representation. We conduct extensive experiments using 20 datasets on seven well-studied data matching tasks, and find that our unified model can achieve better performance on most tasks and on average, compared with the state-of-the-art specific models trained for ad-hoc tasks and datasets separately. Moreover, Unicorn can also well serve new matching tasks with zero-shot learning.\n",
      "Submission Date: 30 May 2023\n",
      "DOI Link: https://doi.org/10.1145/3588938\n",
      "Processing link: https://dl.acm.org/doi/proceedings/10.1145/3639477\n",
      "PDF Link: None\n",
      "Title:None\n",
      "Author: None\n",
      "Abstract: None\n",
      "Submission Date: None\n",
      "DOI Link: None\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3686803\n",
      "PDF Link: None\n",
      "Title:Generative AI for Self-Adaptive Systems: State of the Art and Research Roadmap\n",
      "Authors: JialongLi, MingyueZhang, NianyuLi, DannyWeyns, ZhiJin, KenjiTei\n",
      "Abstract: Self-adaptive systems (SASs) are designed to handle changes and uncertainties through a feedback loop with four core functionalities: monitoring, analyzing, planning, and execution. Recently, generative artificial intelligence (GenAI), especially the area of large language models, has shown impressive performance in data comprehension and logical reasoning. These capabilities are highly aligned with the functionalities required in SASs, suggesting a strong potential to employ GenAI to enhance SASs. However, the specific benefits and challenges of employing GenAI in SASs remain unclear. Yet, providing a comprehensive understanding of these benefits and challenges is complex due to several reasons: limited publications in the SAS field, the technological and application diversity within SASs, and the rapid evolution of GenAI technologies. To that end, this article aims to provide researchers and practitioners a comprehensive snapshot that outlines the potential benefits and challenges of employing GenAI’s within SAS. Specifically, we gather, filter, and analyze literature from four distinct research fields and organize them into two main categories to potential benefits: (i) enhancements to the autonomy of SASs centered around the specific functions of the MAPE-K feedback loop, and (ii) improvements in the interaction between humans and SASs within human-on-the-loop settings. From our study, we outline a research roadmap that highlights the challenges of integrating GenAI into SASs. The roadmap starts with outlining key research challenges that need to be tackled to exploit the potential for applying GenAI in the field of SAS. The roadmap concludes with a practical reflection, elaborating on current shortcomings of GenAI and proposing possible mitigation strategies.\n",
      "Submission Date: 30 September 2024\n",
      "DOI Link: https://doi.org/10.1145/3686803\n",
      "Processing link: https://dl.acm.org/doi/proceedings/10.1145/3690931\n",
      "PDF Link: None\n",
      "Title:None\n",
      "Author: None\n",
      "Abstract: None\n",
      "Submission Date: None\n",
      "DOI Link: None\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3722552\n",
      "PDF Link: None\n",
      "Title:From Matching to Generation: A Survey on Generative Information Retrieval\n",
      "Authors: XiaoxiLi, JiajieJin, YujiaZhou, YuyaoZhang, PeitianZhang, YutaoZhu, ZhichengDou\n",
      "Abstract: Information Retrieval (IR) systems are crucial tools for users to access information, which have long been dominated by traditional methods relying on similarity matching. With the advancement of pre-trained language models, Generative Information Retrieval (GenIR) emerges as a novel paradigm, attracting increasing attention. Based on the form of information provided to users, current research in GenIR can be categorized into two aspects: (1) Generative Retrieval (GR) leverages the generative model’s parameters for memorizing documents, enabling retrieval by directly generating relevant document identifiers without explicit indexing. (2) Reliable Response Generation employs language models to directly generate information users seek, breaking the limitations of traditional IR in terms of document granularity and relevance matching while offering flexibility, efficiency, and creativity to meet practical needs. This article aims to systematically review the latest research progress in GenIR. We will summarize the advancements in GR regarding model training and structure, document identifier, incremental learning, and so on, as well as progress in reliable response generation in aspects of internal knowledge memorization, external knowledge augmentation, and so on. We also review the evaluation, challenges, and future developments in GenIR systems. This review aims to offer a comprehensive reference for researchers, encouraging further development in the GenIR field (Github Repository: https://github.com/RUC-NLPIR/GenIR-Survey).\n",
      "Submission Date: 09 May 2025\n",
      "DOI Link: https://doi.org/10.1145/3722552\n",
      "Processing link: https://dl.acm.org/doi/10.1109/TASLP.2022.3164218\n",
      "PDF Link: None\n",
      "Title:From LSAT: The Progress and Challenges of Complex Reasoning\n",
      "Authors: SiyuanWang, ZhongkunLiu, WanjunZhong, MingZhou, ZhongyuWei, ZhuminChen, NanDuan\n",
      "Abstract: Complex reasoning aims to draw a correct inference based on complex rules. As a hallmark of human intelligence, it involves a degree of explicit reading comprehension, interpretation of logical knowledge and complex rule application. In this paper, we take a step forward in complex reasoning by systematically studying the three challenging and domain-general tasks of the Law School Admission Test (LSAT), including analytical reasoning, logical reasoning and reading comprehension. We propose a hybrid reasoning system to integrate these three tasks and achieve impressive overall performance on the LSAT tests. The experimental results demonstrate that our system endows itself a certain complex reasoning ability, especially the fundamental reading comprehension and challenging logical reasoning capacities. Further analysis also shows the effectiveness of combining the pre-trained models with the task-specific reasoning module, and integrating symbolic knowledge into discrete interpretable reasoning steps in complex reasoning. We further shed a light on the potential future directions, like unsupervised symbolic knowledge extraction, model interpretability, few-shot learning and comprehensive benchmark for complex reasoning.\n",
      "Submission Date: 01 April 2022\n",
      "DOI Link: https://doi.org/10.1109/TASLP.2022.3164218\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3596254\n",
      "PDF Link: https://dl.acm.org/doi/pdf/10.1145/3596254\n",
      "Title:Understanding In-Situ Programming for Smart Home Automation\n",
      "Authors: XiaoyiLiu, YingtianShi, ChunYu, ChengGao, TianaoYang, ChenLiang, YuanchunShi\n",
      "Abstract: Programming a smart home is an iterative process in which users configure and test the automation during the in-situ experience with IoT space. However, current end-user programming mechanisms are primarily preset configurations on GUI and fail to leverage in-situ behaviors and context. This paper proposed in-situ programming (ISP) as a novel programming paradigm for AIoT automation that extensively leverages users' natural in-situ interaction with the smart environment. We built a Wizard-of-Oz system and conducted a user-enactment study to explore users' behavior models in this paradigm. We identified a dynamic programming flow in which participants iteratively configure and confirm through query, control, edit, and test. We especially identified a novel method \"snapshot\" for automation configuration and a novel method \"simulation\" for automation testing, in which participants leverage ambient responses and in-situ interaction. Based on our findings, we proposed design spaces on dynamic programming flow, coherency and clarity of interface, and state and scene management to build an ideal in-situ programming experience.\n",
      "Submission Date: 12 June 2023\n",
      "DOI Link: https://doi.org/10.1145/3596254\n",
      "Processing link: https://dl.acm.org/doi/proceedings/10.1145/3584371\n",
      "PDF Link: None\n",
      "Title:None\n",
      "Author: None\n",
      "Abstract: None\n",
      "Submission Date: None\n",
      "DOI Link: None\n",
      "Processing link: https://dl.acm.org/doi/10.14778/3494124.3494149\n",
      "PDF Link: None\n",
      "Title:Ember: no-code context enrichment via similarity-based keyless joins\n",
      "Authors: SahaanaSuri, Ihab F.Ilyas, ChristopherRé, TheodorosRekatsinas\n",
      "Abstract: Structured data, or data that adheres to a pre-defined schema, can suffer from fragmented context: information describing a single entity can be scattered across multiple datasets or tables tailored for specific business needs, with no explicit linking keys. Context enrichment, or rebuilding fragmented context, using keyless joins is an implicit or explicit step in machine learning (ML) pipelines over structured data sources. This process is tedious, domain-specific, and lacks support in now-prevalent no-code ML systems that let users create ML pipelines using just input data and high-level configuration files. In response, we propose Ember, a system that abstracts and automates keyless joins to generalize context enrichment. Our key insight is that Ember can enable a general keyless join operator by constructing an index populated with task-specific embeddings. Ember learns these embeddings by leveraging Transformer-based representation learning techniques. We describe our architectural principles and operators when developing Ember, and empirically demonstrate that Ember allows users to develop no-code context enrichment pipelines for five domains, including search, recommendation and question answering, and can exceed alternatives by up to 39% recall, with as little as a single line configuration change.\n",
      "Submission Date: 01 November 2021\n",
      "DOI Link: https://doi.org/10.14778/3494124.3494149\n",
      "Processing link: https://dl.acm.org/doi/10.14778/3476249.3476253\n",
      "PDF Link: None\n",
      "Title:PATSQL: efficient synthesis of SQL queries from example tables with quick inference of projected columns\n",
      "Authors: KeitaTakenouchi, TakashiIshio, JojiOkada, YujiSakata\n",
      "Abstract: SQL is one of the most popular tools for data analysis, and it is now used by an increasing number of users without having expertise in databases. Several studies have proposed programming-by-example approaches to help such non-experts to write correct SQL queries. While existing methods support a variety of SQL features such as aggregation and nested query, they suffer a significant increase in computational cost as the scale of example tables increases. In this paper, we propose an efficient algorithm utilizing properties known in relational algebra to synthesize SQL queries from input and output tables. Our key insight is that a projection operator in a program sketch can be lifted above other operators by applying transformation rules in relational algebra, while preserving the semantics of the program. This enables a quick inference of appropriate columns in the projection operator, which is an essential component in synthesis but causes combinatorial explosions in prior work. We also introduce a novel form of constraints and its top-down propagation mechanism for efficient sketch completion. We implemented this algorithm in our tool PATSQL and evaluated it on 226 queries from prior benchmarks and Kaggle's tutorials. As a result, PATSQL solved 68% of the benchmarks and found 89% of the solutions within a second. Our tool is available at https://naist-se.github.io/patsql/.\n",
      "Submission Date: 01 July 2021\n",
      "DOI Link: https://doi.org/10.14778/3476249.3476253\n",
      "Processing link: https://dl.acm.org/doi/proceedings/10.1145/3579654\n",
      "PDF Link: None\n",
      "Title:None\n",
      "Author: None\n",
      "Abstract: None\n",
      "Submission Date: None\n",
      "DOI Link: None\n",
      "Processing link: https://dl.acm.org/doi/10.14778/3407790.3407841\n",
      "PDF Link: None\n",
      "Title:Scrutinizer: a mixed-initiative approach to large-scale, data-driven claim verification\n",
      "Authors: GeorgiosKaragiannis, MohammedSaeed, PaoloPapotti, ImmanuelTrummer\n",
      "Abstract: Organizations spend significant amounts of time and money to manually fact check text documents summarizing data. The goal of the Scrutinizer system is to reduce verification overheads by supporting human fact checkers in translating text claims into SQL queries on an database. Scrutinizer coordinates teams of human fact checkers. It reduces verification time by proposing queries or query fragments to the users. Those proposals are based on claim text classifiers, that gradually improve during the verification of a large document. In addition, Scrutinizer uses tentative execution of query candidates to narrow down the set of alternatives. The verification process is controlled by a cost-based optimizer. It optimizes the interaction with users and prioritizes claim verifications. For the latter, it considers expected verification overheads as well as the expected claim utility as training samples for the classifiers. We evaluate the Scrutinizer system using simulations and a user study with professional fact checkers, based on actual claims and data. Our experiments consistently demonstrate significant savings in verification time, without reducing result accuracy.\n",
      "Submission Date: 01 July 2020\n",
      "DOI Link: https://doi.org/10.14778/3407790.3407841\n",
      "Processing link: https://dl.acm.org/doi/10.14778/3407790.3407858\n",
      "PDF Link: None\n",
      "Title:ATHENA++: natural language querying for complex nested SQL queries\n",
      "Authors: JaydeepSen, ChuanLei, AbdulQuamar, FatmaÖzcan, VasilisEfthymiou, AyushiDalmia, GregStager, AshishMittal, DiptikalyanSaha, KarthikSankaranarayanan\n",
      "Abstract: Natural Language Interfaces to Databases (NLIDB) systems eliminate the requirement for an end user to use complex query languages like SQL, by translating the input natural language (NL) queries to SQL automatically. Although a significant volume of research has focused on this space, most state-of-the-art systems can at best handle simple select-project-join queries. There has been little to no research on extending the capabilities of NLIDB systems to handle complex business intelligence (BI) queries that often involve nesting as well as aggregation. In this paper, we present Athena++, an end-to-end system that can answer such complex queries in natural language by translating them into nested SQL queries. In particular, Athena++ combines linguistic patterns from NL queries with deep domain reasoning using ontologies to enable nested query detection and generation. We also introduce a new benchmark data set (FIBEN), which consists of 300 NL queries, corresponding to 237 distinct complex SQL queries on a database with 152 tables, conforming to an ontology derived from standard financial ontologies (FIBO and FRO). We conducted extensive experiments comparing Athena++ with two state-of-the-art NLIDB systems, using both FIBEN and the prominent Spider benchmark. Athena++ consistently outperforms both systems across all benchmark data sets with a wide variety of complex queries, achieving 88.33% accuracy on FIBEN benchmark, and 78.89% accuracy on Spider benchmark, beating the best reported accuracy results on the dev set by 8%.\n",
      "Submission Date: 01 July 2020\n",
      "DOI Link: https://doi.org/10.14778/3407790.3407858\n",
      "Processing link: https://dl.acm.org/doi/10.1145/1559845.1560000\n",
      "PDF Link: None\n",
      "Title:Answering web queries using structured data sources\n",
      "Authors: SteliosPaparizos, AlexandrosNtoulas, JohnShafer, RakeshAgrawal\n",
      "Abstract: In web search today, a user types a few keywords which are then matched against a large collection of unstructured web pages. This leaves a lot to be desired for when the best answer to a query is contained in structured data stores and/or when the user includes some structural semantics in the query. In our work, we include information from structured data sources into web results. Such sources can vary from fully relational DBs, to flat tables and XML files. In addition, we take advantage of information in such sources to automatically extract corresponding semantics from the query and use them appropriately in improving the overall relevance of results. For this demonstration, we show how we effectively capture, annotate and translate web user queries such as 'popular digital camera around $425' returning results from a shopping-like DB.\n",
      "Submission Date: 29 June 2009\n",
      "DOI Link: https://doi.org/10.1145/1559845.1560000\n",
      "Processing link: https://dl.acm.org/doi/proceedings/10.1145/3626111\n",
      "PDF Link: None\n",
      "Title:None\n",
      "Author: None\n",
      "Abstract: None\n",
      "Submission Date: None\n",
      "DOI Link: None\n",
      "Processing link: https://dl.acm.org/doi/proceedings/10.1145/3663741\n",
      "PDF Link: None\n",
      "Title:None\n",
      "Author: None\n",
      "Abstract: None\n",
      "Submission Date: None\n",
      "DOI Link: None\n",
      "Processing link: https://dl.acm.org/doi/proceedings/10.1145/3701716\n",
      "PDF Link: None\n",
      "Title:None\n",
      "Author: None\n",
      "Abstract: None\n",
      "Submission Date: None\n",
      "DOI Link: None\n",
      "Processing link: https://dl.acm.org/doi/proceedings/10.1145/3640544\n",
      "PDF Link: None\n",
      "Title:None\n",
      "Author: None\n",
      "Abstract: None\n",
      "Submission Date: None\n",
      "DOI Link: None\n",
      "Processing link: https://dl.acm.org/doi/proceedings/10.1145/3654777\n",
      "PDF Link: None\n",
      "Title:None\n",
      "Author: None\n",
      "Abstract: None\n",
      "Submission Date: None\n",
      "DOI Link: None\n",
      "Processing link: https://dl.acm.org/doi/proceedings/10.1145/3605098\n",
      "PDF Link: None\n",
      "Title:None\n",
      "Author: None\n",
      "Abstract: None\n",
      "Submission Date: None\n",
      "DOI Link: None\n",
      "Processing link: https://dl.acm.org/doi/10.1145/276675.276694\n",
      "PDF Link: https://dl.acm.org/doi/pdf/10.1145/276675.276694\n",
      "Title:Beyond SGML\n",
      "Authors: RogerPrice\n",
      "Abstract: None\n",
      "Submission Date: 11 May 1998\n",
      "DOI Link: https://doi.org/10.1145/276675.276694\n",
      "Processing link: https://dl.acm.org/doi/proceedings/10.1145/3687997\n",
      "PDF Link: None\n",
      "Title:None\n",
      "Author: None\n",
      "Abstract: None\n",
      "Submission Date: None\n",
      "DOI Link: None\n",
      "Processing link: https://dl.acm.org/doi/proceedings/10.1145/3698204\n",
      "PDF Link: None\n",
      "Title:None\n",
      "Author: None\n",
      "Abstract: None\n",
      "Submission Date: None\n",
      "DOI Link: None\n",
      "Processing link: https://dl.acm.org/doi/proceedings/10.1145/3626772\n",
      "PDF Link: None\n",
      "Title:None\n",
      "Author: None\n",
      "Abstract: None\n",
      "Submission Date: None\n",
      "DOI Link: None\n",
      "Processing link: https://dl.acm.org/doi/proceedings/10.1145/3641399\n",
      "PDF Link: None\n",
      "Title:None\n",
      "Author: None\n",
      "Abstract: None\n",
      "Submission Date: None\n",
      "DOI Link: None\n",
      "Processing link: https://dl.acm.org/doi/proceedings/10.1145/3713082\n",
      "PDF Link: None\n",
      "Title:None\n",
      "Author: None\n",
      "Abstract: None\n",
      "Submission Date: None\n",
      "DOI Link: None\n",
      "Processing link: https://dl.acm.org/doi/proceedings/10.5555/3694718\n",
      "PDF Link: None\n",
      "Title:None\n",
      "Author: None\n",
      "Abstract: None\n",
      "Submission Date: None\n",
      "DOI Link: None\n",
      "Processing link: https://dl.acm.org/doi/proceedings/10.1145/3703412\n",
      "PDF Link: None\n",
      "Title:None\n",
      "Author: None\n",
      "Abstract: None\n",
      "Submission Date: None\n",
      "DOI Link: None\n",
      "Processing link: https://dl.acm.org/doi/proceedings/10.1145/3706468\n",
      "PDF Link: None\n",
      "Title:None\n",
      "Author: None\n",
      "Abstract: None\n",
      "Submission Date: None\n",
      "DOI Link: None\n",
      "Processing link: https://dl.acm.org/doi/proceedings/10.1145/3587281\n",
      "PDF Link: None\n",
      "Title:None\n",
      "Author: None\n",
      "Abstract: None\n",
      "Submission Date: None\n",
      "DOI Link: None\n",
      "Processing link: https://dl.acm.org/doi/proceedings/10.1145/3589132\n",
      "PDF Link: None\n",
      "Title:None\n",
      "Author: None\n",
      "Abstract: None\n",
      "Submission Date: None\n",
      "DOI Link: None\n",
      "Processing link: https://dl.acm.org/doi/proceedings/10.1145/3640310\n",
      "PDF Link: None\n",
      "Title:None\n",
      "Author: None\n",
      "Abstract: None\n",
      "Submission Date: None\n",
      "DOI Link: None\n",
      "Processing link: https://dl.acm.org/doi/proceedings/10.1145/3702879\n",
      "PDF Link: None\n",
      "Title:None\n",
      "Author: None\n",
      "Abstract: None\n",
      "Submission Date: None\n",
      "DOI Link: None\n",
      "Processing link: https://dl.acm.org/doi/proceedings/10.1145/3578741\n",
      "PDF Link: None\n",
      "Title:None\n",
      "Author: None\n",
      "Abstract: None\n",
      "Submission Date: None\n",
      "DOI Link: None\n",
      "Processing link: https://dl.acm.org/doi/proceedings/10.1145/3641554\n",
      "PDF Link: None\n",
      "Title:None\n",
      "Author: None\n",
      "Abstract: None\n",
      "Submission Date: None\n",
      "DOI Link: None\n",
      "Processing link: https://dl.acm.org/doi/proceedings/10.1145/3696410\n",
      "PDF Link: None\n",
      "Title:None\n",
      "Author: None\n",
      "Abstract: None\n",
      "Submission Date: None\n",
      "DOI Link: None\n",
      "Processing link: https://dl.acm.org/doi/proceedings/10.1145/3571884\n",
      "PDF Link: None\n",
      "Title:None\n",
      "Author: None\n",
      "Abstract: None\n",
      "Submission Date: None\n",
      "DOI Link: None\n",
      "Processing link: https://dl.acm.org/doi/proceedings/10.1145/3487553\n",
      "PDF Link: None\n",
      "Title:None\n",
      "Author: None\n",
      "Abstract: None\n",
      "Submission Date: None\n",
      "DOI Link: None\n",
      "Processing link: https://dl.acm.org/doi/proceedings/10.1145/3597503\n",
      "PDF Link: None\n",
      "Title:None\n",
      "Author: None\n",
      "Abstract: None\n",
      "Submission Date: None\n",
      "DOI Link: None\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3674399.3674433\n",
      "PDF Link: https://dl.acm.org/doi/pdf/10.1145/3674399.3674433\n",
      "Title:LLM-Enhanced Chinese NL2SQL Translation Task Under Resource-Limited Condition\n",
      "Authors: XichonglangXiao, HaoXu\n",
      "Abstract: With the development of big data and artificial intelligence technology, data has become an important production factor and core resource. There is also a growing demand for real-time accurate, convenient and fast data analysis in the military field.NL2SQL technology can be embedded into various intelligent platforms, data analysis tools or intelligent assistants, realizing seamless dialogue between users and data, responding instantly to complex analytical requests, and providing timely and accurate support of decision-making for commanders. However, the Chinese NL2SQL task has a low success rate compared to the English task due to the base model’s bias in converting Chinese entities, difficulty in linking schemas, and unclear thought chain. In this paper, based on the llama3-8b model, we explored the NL2SQL technique under resource-constrained conditions.By analyzing the characteristics of the model’s erroneous output results under regular prompts,target refinements of Chinese prompts are designed.And through supervised fine-tuning, we have made the model’s accuracy rate on the dev set increase from the initial 46% to 70%.\n",
      "Submission Date: 30 July 2024\n",
      "DOI Link: https://doi.org/10.1145/3674399.3674433\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3698300.3698320\n",
      "PDF Link: None\n",
      "Title:Data Security Protection and Analysis of ERP System Based on NL2SQL with Large Language Model and Encrypted Database\n",
      "Authors: LimiaoXie, YingyingLi, JianfengZhang, NingJia, LinXiong, GanshengDeng\n",
      "Abstract: In the era of big data, enterprises have higher and higher requirements for data security, especially when dealing with massive amounts of sensitive information in ERP systems, data security issues become particularly important. To address this challenge, In this paper, we propose a multi-layer encryption scheme based on a encrypted database, including device-level encryption, user-level encryption, table-level encryption, field-level encryption, and row-level authentication, aiming to protect the data information of the ERP system in a multi-dimensional way. To verify the effectiveness of the scheme, this paper applies it on the human resource data of the ERP system to ensure that the data storage, transmission, and access processes are in an encrypted state in the big data environment. In addition, this paper incorporates NL2SQL with Large Language Model(LLM) to realize conversational data analysis, generating SQL queries through natural language to cope with the complex and changing query requirements in the big data environment, and to enhance the flexibility and intelligence of data access. The research results show that the proposed multi-layer encryption scheme and conversational data analysis method not only significantly improves the data security of the ERP system in the big data environment, but also optimizes the efficiency of the enterprise in the process of big data analysis and retrieval, and mends the natural defects of the NL2SQL security protection, which guarantees the data security for the landing of LLM applications.\n",
      "Submission Date: 14 December 2024\n",
      "DOI Link: https://doi.org/10.1145/3698300.3698320\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3689236.3695386\n",
      "PDF Link: None\n",
      "Title:Research on Tobacco Data Query Application Based on NL2SQL\n",
      "Authors: TongShen, YeHua, LeiYuan, YimingChen\n",
      "Abstract: Natural Language to SQL (NL2SQL) is an important direction in the field of natural language processing. This paper focuses on Chinese and tobacco industry data queries as research subjects and constructs a domain-specific natural language data query model. The Chinese NL2SQL task is deconstructed into two classification problems, using a general classification model and a conditional value retrieval model to combine and form a complete SQL statement. Additionally, BiLSTM and attention mechanisms are utilized to generate feature vectors, improving the accuracy of SQL statement generation. Moreover, a vector library containing tobacco industry vocabulary is trained, and a tobacco industry dataset is constructed. Experiments on this dataset show that the model proposed in this paper has higher accuracy and can effectively meet the data query needs of the tobacco industry.\n",
      "Submission Date: 03 December 2024\n",
      "DOI Link: https://doi.org/10.1145/3689236.3695386\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3318464.3380589\n",
      "PDF Link: None\n",
      "Title:DBPal: A Fully Pluggable NL2SQL Training Pipeline\n",
      "Authors: NathanielWeir, PrasetyaUtama, AlexGalakatos, AndrewCrotty, AmirIlkhechi, ShekarRamaswamy, RohinBhushan, NadjaGeisler, BenjaminHättasch, SteffenEger, UgurCetintemel, CarstenBinnig\n",
      "Abstract: Natural language is a promising alternative interface to DBMSs because it enables non-technical users to formulate complex questions in a more concise manner than SQL. Recently, deep learning has gained traction for translating natural language to SQL, since similar ideas have been successful in the related domain of machine translation. However, the core problem with existing deep learning approaches is that they require an enormous amount of training data in order to provide accurate translations. This training data is extremely expensive to curate, since it generally requires humans to manually annotate natural language examples with the corresponding SQL queries (or vice versa). Based on these observations, we propose DBPal, a new approach that augments existing deep learning techniques in order to improve the performance of models for natural language to SQL translation. More specifically, we present a novel training pipeline that automatically generates synthetic training data in order to (1) improve overall translation accuracy, (2) increase robustness to linguistic variation, and (3) specialize the model for the target database. As we show, our DBPal training pipeline is able to improve both the accuracy and linguistic robustness of state-of-the-art natural language to SQL translation models.\n",
      "Submission Date: 31 May 2020\n",
      "DOI Link: https://doi.org/10.1145/3318464.3380589\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3448016.3457261\n",
      "PDF Link: None\n",
      "Title:Synthesizing Natural Language to Visualization (NL2VIS) Benchmarks from NL2SQL Benchmarks\n",
      "Authors: YuyuLuo, NanTang, GuoliangLi, ChengliangChai, WenboLi, XuediQin\n",
      "Abstract: Natural language (NL) is a promising interaction paradigm for data visualization (VIS). However, there are not any NL to VIS (NL2VIS) benchmarks available. Our goal is to provide the first NL2VIS benchmark to enable and push the field of NL2VIS, especially with deep learning technologies. In this paper, we propose a NL2VIS synthesizer (NL2SQL-to-NL2VIS) that synthesizes NL2VIS benchmarks by piggybacking NL2SQL benchmarks. The intuition is based on the semantic connection between SQL queries and VIS queries: SQL queries specify what data is needed and VIS queries additionally need to specify how to visualize. However, different from SQL that has well-defined syntax, VIS languages (e.g., Vega-Lite, VizQL, ggplot2) are syntactically very different. To provide NL2VIS benchmarks that can support many VIS languages, we use a unified intermediate representation, abstract syntax trees (ASTs), for both SQL and VIS queries. We can synthesize multiple VIS trees through adding/deleting nodes to/from an SQL tree. Each VIS tree can then be converted to (any) VIS language. The NL for VIS will be modified based on the NL for SQL to reflect corresponding tree edits. We produce the first NL2VIS benchmark (nvBench), by applying NL2SQL-to-NL2VIS on a popular NL2SQL benchmark Spider, which covers 105 domains, supports seven common types of visualizations, and contains 25,750 (NL, VIS) pairs. Our method reduces the man-hour to 5.7% of developing a NL2VIS benchmark from scratch (or building a NL2VIS benchmark from scratch takes 17.5× man-hours of our method). Extensive human validation, through 23 experts and 312 crowd workers, demonstrates the high-quality of nvBench. In order to verify that nvBench can enable learning-based approaches, we develop a SEQ2VIS model. Our experimental results show that SEQ2VIS works well and significantly outperforms the state-of-the-art methods of the NL2VIS task.\n",
      "Submission Date: 18 June 2021\n",
      "DOI Link: https://doi.org/10.1145/3448016.3457261\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3371158.3371198\n",
      "PDF Link: None\n",
      "Title:A Natural Language and Interactive End-to-End Querying and Reporting System\n",
      "Authors: Salil RajeevJoshi, BharathVenkatesh, DawnThomas, YueJiao, ShouryaRoy\n",
      "Abstract: Natural language query understanding for unstructured textual sources has seen significant progress over the last couple of decades. For structured data, while the ecosystem has evolved with regard to data storage and retrieval mechanisms, the query language has remained predominantly SQL (or SQL-like). Towards making the latter more natural there has been recent research emphasis on Natural Language Interface to DataBases (NLIDB) systems. Piggybacking on the rise of 'deep learning' systems, the state-of-the-art NLIDB solutions over large parallel and standard benchmarks (viz, WikiSQL and Spider) primarily rely on attention based sequence-to-sequence models. Building industry grade NLIDB solutions for making big data ecosystem accessible by truly natural and unstructured querying mechanism presents several challenges. These include lack of availability of parallel corpora, diversity in underlying data schema, wide variability in the nature of queries to context and dialog management in interactive systems. In this paper, we present an end-to-end system Query Enterprise Data (QED) towards making enterprise descriptive analytics and reporting easier and natural. We elaborate in detail how we addressed the challenges mentioned above and novel features such as handling incomplete queries in incremental fashion as well as highlight the role of an assistive user interface that provides a better user experience. Finally, we conclude the paper with observations and lessons learnt from the experience of transferring and deploying a research solution to industry grade practical deployment.\n",
      "Submission Date: 15 January 2020\n",
      "DOI Link: https://doi.org/10.1145/3371158.3371198\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3650114\n",
      "PDF Link: https://dl.acm.org/doi/pdf/10.1145/3650114\n",
      "Title:Insights into Natural Language Database Query Errors: from Attention Misalignment to User Handling Strategies\n",
      "Authors: ZhengNing, YuanTian, ZhengZhang, TianyiZhang, Toby Jia-JunLi\n",
      "Abstract: Querying structured databases with natural language (NL2SQL) has remained a difficult problem for years. Recently, the advancement of machine learning (ML), natural language processing (NLP), and large language models (LLM) have led to significant improvements in performance, with the best model achieving ∼85% percent accuracy on the benchmark Spider dataset. However, there is a lack of a systematic understanding of the types, causes, and effectiveness of error-handling mechanisms of errors for erroneous queries nowadays. To bridge the gap, a taxonomy of errors made by four representative NL2SQL models was built in this work, along with an in-depth analysis of the errors. Second, the causes of model errors were explored by analyzing the model-human attention alignment to the natural language query. Last, a within-subjects user study with 26 participants was conducted to investigate the effectiveness of three interactive error-handling mechanisms in NL2SQL. Findings from this article shed light on the design of model structure and error discovery and repair strategies for natural language data query interfaces in the future.\n",
      "Submission Date: 17 December 2024\n",
      "DOI Link: https://doi.org/10.1145/3650114\n",
      "Processing link: https://dl.acm.org/doi/10.14778/3681954.3682003\n",
      "PDF Link: None\n",
      "Title:The Dawn of Natural Language to SQL: Are We Fully Ready?\n",
      "Authors: BoyanLi, YuyuLuo, ChengliangChai, GuoliangLi, NanTang\n",
      "Abstract: Translating users' natural language questions into SQL queries (i.e., nl2sql) significantly lowers the barriers to accessing relational databases. The emergence of Large Language Models has introduced a novel paradigm in nl2sql tasks, enhancing capabilities dramatically. However, this raises a critical question: Are we fully prepared to deploy nl2sql models in production? To address the posed questions, we present a multi-angle nl2sql evaluation framework, NL2SQL360, to facilitate the design and test of new nl2sql methods for researchers. Through NL2SQL360, we conduct a detailed comparison of leading nl2sql methods across a range of application scenarios, such as different data domains and sql characteristics, offering valuable insights for selecting the most appropriate nl2sql methods for specific needs. Moreover, we explore the nl2sql design space, leveraging NL2SQL360 to automate the identification of an optimal nl2sql solution tailored to user-specific needs. Specifically, NL2SQL360 identifies an effective nl2sql method, SuperSQL, distinguished under the Spider dataset using the execution accuracy metric. Remarkably, SuperSQL achieves competitive performance with execution accuracy of 87% and 62.66% on the Spider and BIRD test sets, respectively.\n",
      "Submission Date: 01 July 2024\n",
      "DOI Link: https://doi.org/10.14778/3681954.3682003\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3581641.3584067\n",
      "PDF Link: None\n",
      "Title:An Empirical Study of Model Errors and User Error Discovery and Repair Strategies in Natural Language Database Queries\n",
      "Authors: ZhengNing, ZhengZhang, TianyiSun, YuanTian, TianyiZhang, Toby Jia-JunLi\n",
      "Abstract: Recent advances in machine learning (ML) and natural language processing (NLP) have led to significant improvement in natural language interfaces for structured databases (NL2SQL). Despite the great strides, the overall accuracy of NL2SQL models is still far from being perfect (∼ 75% on the Spider benchmark). In practice, this requires users to discern incorrect SQL queries generated by a model and manually fix them when using NL2SQL models. Currently, there is a lack of comprehensive understanding about the common errors in auto-generated SQLs and the effective strategies to recognize and fix such errors. To bridge the gap, we (1) performed an in-depth analysis of errors made by three state-of-the-art NL2SQL models; (2) distilled a taxonomy of NL2SQL model errors; and (3) conducted a within-subjects user study with 26 participants to investigate the effectiveness of three representative interactive mechanisms for error discovery and repair in NL2SQL. Findings from this paper shed light on the design of future error discovery and repair strategies for natural language data query interfaces.\n",
      "Submission Date: 27 March 2023\n",
      "DOI Link: https://doi.org/10.1145/3581641.3584067\n",
      "Processing link: https://dl.acm.org/doi/10.14778/3583140.3583165\n",
      "PDF Link: None\n",
      "Title:CatSQL: Towards Real World Natural Language to SQL Applications\n",
      "Authors: HanFu, ChangLiu, BinWu, FeifeiLi, JianTan, JianlingSun\n",
      "Abstract: Natural language to SQL (NL2SQL) techniques provide a convenient interface to access databases, especially for non-expert users, to conduct various data analytics. Existing methods often employ either a rule-base approach or a deep learning based solution. The former is hard to generalize across different domains. Though the latter generalizes well, it often results in queries with syntactic or semantic errors, thus may be even not executable. In this work, we bridge the gap between the two and design a new framework to significantly improve both accuracy and runtime. In particular, we develop a novel CatSQL sketch, which constructs a template with slots that initially serve as placeholders, and tightly integrates with a deep learning model to fill in these slots with meaningful contents based on the database schema. Compared with the widely used sequence-to-sequence-based approaches, our sketch-based method does not need to generate keywords which are boilerplates in the template, and can achieve better accuracy and run much faster. Compared with the existing sketch-based approaches, our CatSQL sketch is more general and versatile, and can leverage the values already filled in on certain slots to derive the rest ones for improved performance. In addition, we propose the Semantics Correction technique, which is the first that leverages database domain knowledge in a deep learning based NL2SQL solution. Semantics Correction is a post-processing routine, which checks the initially generated SQL queries by applying rules to identify and correct semantic errors. This technique significantly improves the NL2SQL accuracy. We conduct extensive evaluations on both single-domain and cross-domain benchmarks and demonstrate that our approach significantly outperforms the previous ones in terms of both accuracy and throughput. In particular, on the state-of-the-art NL2SQL benchmark Spider, our CatSQL prototype outperforms the best of the previous solutions by 4 points on accuracy, while still achieving a throughput up to 63 times higher.\n",
      "Submission Date: 01 February 2023\n",
      "DOI Link: https://doi.org/10.14778/3583140.3583165\n",
      "Processing link: https://dl.acm.org/doi/10.14778/3401960.3401970\n",
      "PDF Link: None\n",
      "Title:Natural language to SQL: where are we today?\n",
      "Authors: HyeonjiKim, Byeong-HoonSo, Wook-ShinHan, HongraeLee\n",
      "Abstract: Translating natural language to SQL (NL2SQL) has received extensive attention lately, especially with the recent success of deep learning technologies. However, despite the large number of studies, we do not have a thorough understanding of how good existing techniques really are and how much is applicable to real-world situations. A key difficulty is that different studies are based on different datasets, which often have their own limitations and assumptions that are implicitly hidden in the context or datasets. Moreover, a couple of evaluation metrics are commonly employed but they are rather simplistic and do not properly depict the accuracy of results, as will be shown in our experiments. To provide a holistic view of NL2SQL technologies and access current advancements, we perform extensive experiments under our unified framework using eleven of recent techniques over 10+ benchmarks including a new benchmark (WTQ) and TPC-H. We provide a comprehensive survey of recent NL2SQL methods, introducing a taxonomy of them. We reveal major assumptions of the methods and classify translation errors through extensive experiments. We also provide a practical tool for validation by using existing, mature database technologies such as query rewrite and database testing. We then suggest future research directions so that the translation can be used in practice.\n",
      "Submission Date: 01 June 2020\n",
      "DOI Link: https://doi.org/10.14778/3401960.3401970\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3397481.3450667\n",
      "PDF Link: None\n",
      "Title:DIY: Assessing the Correctness of Natural Language to SQL Systems\n",
      "Authors: ArpitNarechania, AdamFourney, BongshinLee, GonzaloRamos\n",
      "Abstract: Designing natural language interfaces for querying databases remains an important goal pursued by researchers in natural language processing, databases, and HCI. These systems receive natural language as input, translate it into a formal database query, and execute the query to compute a result. Because the responses from these systems are not always correct, it is important to provide people with mechanisms to assess the correctness of the generated query and computed result. However, this assessment can be challenging for people who lack expertise in query languages. We present Debug-It-Yourself (DIY), an interactive technique that enables users to assess the responses from a state-of-the-art natural language to SQL (NL2SQL) system for correctness and, if possible, fix errors. DIY provides users with a sandbox where they can interact with (1) the mappings between the question and the generated query, (2) a small-but-relevant subset of the underlying database, and (3) a multi-modal explanation of the generated query. End-users can then employ a back-of-the-envelope calculation debugging strategy to evaluate the system’s response. Through an exploratory study with 12 users, we investigate how DIY helps users assess the correctness of the system’s answers and detect & fix errors. Our observations reveal the benefits of DIY while providing insights about end-user debugging strategies and underscore opportunities for further improving the user experience.\n",
      "Submission Date: 14 April 2021\n",
      "DOI Link: https://doi.org/10.1145/3397481.3450667\n",
      "Processing link: https://dl.acm.org/doi/10.14778/3705829.3705843\n",
      "PDF Link: None\n",
      "Title:LEAP: LLM-Powered End-to-End Automatic Library for Processing Social Science Queries on Unstructured Data\n",
      "Authors: ChuxuanHu, AustinPeters, DanielKang\n",
      "Abstract: Social scientists are increasingly interested in analyzing the semantic information (e.g., emotion) of unstructured data (e.g., Tweets), where the semantic information is not natively present. Performing this analysis in a cost-efficient manner requires using machine learning (ML) models to extract the semantic information and subsequently analyze the now structured data. However, this process remains challenging for domain experts. To demonstrate the challenges in social science analytics, we collect a dataset, QUIET-ML, of 120 real-world social science queries in natural language and their ground truth answers. Existing systems struggle with these queries since (1) they require selecting and applying ML models, and (2) more than a quarter of these queries are vague, making standard tools like natural language to SQL systems unsuited. To address these issues, we develop LEAP, an end-to-end library that answers social science queries in natural language with ML. LEAP filters vague queries to ensure that the answers are deterministic and selects from internally supported and user-defined ML functions to extend the unstructured data to structured tables with necessary annotations. LEAP further generates and executes code to respond to these natural language queries. LEAP achieves a 100% pass @ 3 and 92% pass @ 1 on QUIET-ML, with a $1.06 average end-to-end cost, of which code generation costs $0.02.\n",
      "Submission Date: 01 October 2024\n",
      "DOI Link: https://doi.org/10.14778/3705829.3705843\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3637528.3671583\n",
      "PDF Link: None\n",
      "Title:Know Your Needs Better: Towards Structured Understanding of Marketer Demands with Analogical Reasoning Augmented LLMs\n",
      "Authors: JunjieWang, DanYang, BinbinHu, YueShen, WenZhang, JinjieGu\n",
      "Abstract: In this paper, we explore a new way for user targeting, where non-expert marketers could select their target users solely given demands in natural language form. The key to this issue is how to transform natural languages into practical structured logical languages, i.e., the structured understanding of marketer demands. In practical scenarios, the demands of non-expert marketers are often abstract and diverse. Considering the impressive natural language processing ability of large language models (LLMs), we try to leverage LLMs to solve this issue. To stimulate the LLMs' reasoning ability, the chain-of-thought (CoT) prompting method is widely used, but existing methods still have some limitations in our scenario: (1) Previous methods either use simple \"Let's think step by step\" spells or provide fixed examples in demonstrations without considering compatibility between prompts and concrete questions, making LLMs ineffective when the marketers' demands are abstract and diverse. (2) Previous methods are often implemented in closed-source models or excessively large models, which is not suitable in industrial practical scenarios. Based on these, we propose ARALLM (i.e., Analogical Reasoning Augmented Large Language Models) consisting of two modules: Analogical Reasoning based Prompting and Reasoning-Augmented Multi-Task Model Distillation. Then, we adopt a retrieval-based method to conduct analogical reasoning with the help of the reasoning library. The experimental results show that this prompting strategy achieves better performance than the ordinary prompting method. Beyond that, we distill knowledge from super LLMs (GPT-3.5) to fine-tune smaller student LLMs in a multi-task training paradigm, enabling the models to be easily deployed in practical environments. Part of our data and code can be found at https://github.com/alipay/Analogic-Reasoning-Augmented-Large-Language-Model.\n",
      "Submission Date: 24 August 2024\n",
      "DOI Link: https://doi.org/10.1145/3637528.3671583\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3663742.3663972\n",
      "PDF Link: None\n",
      "Title:Rethinking Table Retrieval from Data Lakes\n",
      "Authors: Jan-MichaBodensohn, CarstenBinnig\n",
      "Abstract: Table retrieval from data lakes has recently become important for many downstream tasks, including data discovery and table question answering. Existing table retrieval approaches estimate each table's relevance to a particular information need and return a ranking of the most relevant tables. This approach is not ideal since (1) the returned tables often include irrelevant data and (2) the required information may be scattered across multiple tables. To address these issues, we propose the idea of fine-grained structured table retrieval and present our vision of R2D2, a system which slices tables into small tiles that are later composed into a structured result that is tailored to the user-provided information need. An initial evaluation of our approach demonstrates how our idea can improve table retrieval and relevant downstream tasks such as table question answering.\n",
      "Submission Date: 09 June 2024\n",
      "DOI Link: https://doi.org/10.1145/3663742.3663972\n",
      "Processing link: https://dl.acm.org/doi/10.14778/3685800.3685918\n",
      "PDF Link: None\n",
      "Title:Harmonizing ML and Databases: A Symphony of Data (VLDB 2024 Keynote)\n",
      "Authors: FatmaOzcan\n",
      "Abstract: Large language models (LLMs) are rapidly transforming the landscape of computing and daily life, demonstrating immense potential across diverse applications like natural language processing, machine translation, and code generation. This talk delves into the impact of LLMs on database research. Specifically, we'll examine how LLMs are fueling innovation in natural language interfaces for data interaction, highlighting current limitations and advocating for semantic data models and enhanced context to improve the accuracy of these solutions. Drawing inspiration from LLMs, we'll introduce a novel paradigm for database cost modeling, leveraging pre-trained models and fine-tuning techniques. We'll share our early-stage prototype, initial results, and outline a research roadmap highlighting numerous exciting challenges in this evolving field.\n",
      "Submission Date: 01 August 2024\n",
      "DOI Link: https://doi.org/10.14778/3685800.3685918\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3650215.3650255\n",
      "PDF Link: None\n",
      "Title:M-TBQA: Multimodal Table-Based Question Answering\n",
      "Authors: JingwenZeng, ZhidongWu, RongrongZheng, WentingXue, ChenhuiWang, XiaoyangYu, TaoZhang, ShaozuYuan, TiangangZhu\n",
      "Abstract: In recent years, there has been considerable interest in the research on table-based question answering (TBQA). These studies aim to understand the table content and generate the answer for the given table. With the rapid growth of the Internet, table content is no longer confined to pure text but also includes images. However, most previous methods overlook the important visual information linked to table cells and focus solely on parsing questions to logic form using textual tabular data. This limitation prevents the exploration of the multimodal application of TBQA. Therefore, we propose a novel task multimodal table-based question answering (M-TBQA), which is required to perform multimodal question answering on tabular data with images. Specially, M-TBQA initially identifies candidate rows relevant to the question using a table-relevance net, and then predicts the expected answer using an answer prediction net. This approach effectively harnesses multimodal information from both tabular data and images to predict answers accurately. Additionally, it highlights the significant role of images in the M-TBQA task. To facilitate related research in the further, the dataset will be released at https://github.com/cooperResearch001/M-TBQA/tree/main\n",
      "Submission Date: 16 April 2024\n",
      "DOI Link: https://doi.org/10.1145/3650215.3650255\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3665601.3669846\n",
      "PDF Link: None\n",
      "Title:CMDBench: A Benchmark for Coarse-to-fine Multimodal Data Discovery in Compound AI Systems\n",
      "Authors: YanlinFeng, SajjadurRahman, AaronFeng, VincentChen, EserKandogan\n",
      "Abstract: Compound AI systems (CASs) that employ LLMs as agents to accomplish knowledge-intensive tasks via interactions with tools and data retrievers have garnered significant interest within database and AI communities. While these systems have the potential to supplement typical analysis workflows of data analysts in enterprise data platforms, unfortunately, CASs are subject to the same data discovery challenges that analysts have encountered over the years — silos of multimodal data sources, created across teams and departments within an organization, make it difficult to identify appropriate data sources for accomplishing the task at hand. Existing data discovery benchmarks do not model such multimodality and multiplicity of data sources. Moreover, benchmarks of CASs prioritize only evaluating end-to-end task performance. To catalyze research on evaluating the data discovery performance of multimodal data retrievers in CASs within a real-world setting, we propose CMDBench, a benchmark modeling the complexity of enterprise data platforms. We adapt existing datasets and benchmarks in open-domain — from question answering and complex reasoning tasks to natural language querying over structured data — to evaluate coarse- and fine-grained data discovery and task execution performance. Our experiments reveal the impact of data retriever design on downstream task performance — 46% drop in task accuracy on average — across various modalities, data sources, and task difficulty. The results indicate the need to develop optimization strategies to identify appropriate LLM agents and retrievers for efficient execution of CASs over enterprise data.\n",
      "Submission Date: 09 June 2024\n",
      "DOI Link: https://doi.org/10.1145/3665601.3669846\n",
      "Processing link: https://dl.acm.org/doi/10.14778/3611540.3611639\n",
      "PDF Link: None\n",
      "Title:Modernization of Databases in the Cloud Era: Building Databases that Run Like Legos\n",
      "Authors: FeifeiLi\n",
      "Abstract: Utilizing cloud for common and critical computing infrastructures has already become the norm across the board. The rapid evolvement of the underlying cloud infrastructure and the revolutionary development of AI present both challenges and opportunities for building new database architectures and systems. It is crucial to modernize database systems in the cloud era, so that next generation cloud native databases may run like legos-they are adaptive, flexible, reliable, and smart towards dynamic workloads and varying requirements. That said, we observe four critical trends and requirements for the modernization of cloud databases: embracing cloud-native architecture, full integration with cloud platform and orchestration, co-design for data fabric, and moving towards being AI augmented. Modernizing database systems by adopting these critical trends and addressing key challenges associated with them provide ample opportunities for data management communities from both academia and industry to explore. We will provide an in-depth case study of how we modernize PolarDB with respect to embracing these four trends in the cloud era. Our ultimate goal is to build databases that run just like playing with legos, so that a database system fits for rich and dynamic workloads and requirements in a self-adaptive, performant, easy-/intuitive-to use, reliable, and intelligent manner.\n",
      "Submission Date: 01 August 2023\n",
      "DOI Link: https://doi.org/10.14778/3611540.3611639\n",
      "Processing link: https://dl.acm.org/doi/10.14778/3685800.3685838\n",
      "PDF Link: None\n",
      "Title:LLM for Data Management\n",
      "Authors: GuoliangLi, XuanheZhou, XinyangZhao\n",
      "Abstract: Machine learning techniques have been verified to be effective in optimizing data management systems and are widely researched in recent years. However, traditional small-sized ML models often struggle to generalize to new scenarios, and have limited context understanding ability (e.g., inputting discrete features only). The emergence of LLMs offers a promising solution to these challenges. LLMs have been trained over a vast number of scenarios and tasks and acquire human-competitive capabilities like context understanding and summarization, which can be highly beneficial for data management tasks (e.g., natural language based data analytics). In this tutorial, we present how to utilize LLMs to optimize data management systems and review new techniques for addressing these technical challenges, including hallucination of LLMs, high cost of interacting with LLMs, and low accuracy for processing complicated tasks. First, we discuss retrieval augmented generation (RAG) techniques to address the hallucination problem. Second, we present vector database techniques to improve the latency. Third, we present LLM agent techniques for processing complicated tasks by generating multi-round pipelines. We also showcase some real-world data management scenarios that can be well optimized by LLMs, including query rewrite, database diagnosis and data analytics. Finally, we summarize some open research challenges.\n",
      "Submission Date: 01 August 2024\n",
      "DOI Link: https://doi.org/10.14778/3685800.3685838\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3654992\n",
      "PDF Link: None\n",
      "Title:Automated Data Visualization from Natural Language via Large Language Models: An Exploratory Study\n",
      "Authors: YangWu, YaoWan, HongyuZhang, YuleiSui, WucaiWei, WeiZhao, GuandongXu, HaiJin\n",
      "Abstract: The Natural Language to Visualization (NL2Vis) task aims to transform natural-language descriptions into visual representations for a grounded table, enabling users to gain insights from vast amounts of data. Recently, many deep learning-based approaches have been developed for NL2Vis. Despite the considerable efforts made by these approaches, challenges persist in visualizing data sourced from unseen databases or spanning multiple tables. Taking inspiration from the remarkable generation capabilities of Large Language Models (LLMs), this paper conducts an empirical study to evaluate their potential in generating visualizations, and explore the effectiveness of in-context learning prompts for enhancing this task. In particular, we first explore the ways of transforming structured tabular data into sequential text prompts, as to feed them into LLMs and analyze which table content contributes most to the NL2Vis. Our findings suggest that transforming structured tabular data into programs is effective, and it is essential to consider the table schema when formulating prompts. Furthermore, we evaluate two types of LLMs: finetuned models (e.g., T5-Small) and inference-only models (e.g., GPT-3.5), against state-of-the-art methods, using the NL2Vis benchmarks (i.e., nvBench). The experimental results reveal that LLMs outperform baselines, with inference-only models consistently exhibiting performance improvements, at times even surpassing fine-tuned models when provided with certain few-shot demonstrations through in-context learning. Finally, we analyze when the LLMs fail in NL2Vis, and propose to iteratively update the results using strategies such as chain-of-thought, role-playing, and code-interpreter. The experimental results confirm the efficacy of iterative updates and hold great potential for future study.\n",
      "Submission Date: 30 May 2024\n",
      "DOI Link: https://doi.org/10.1145/3654992\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3538712.3538744\n",
      "PDF Link: https://dl.acm.org/doi/pdf/10.1145/3538712.3538744\n",
      "Title:Building Natural Language Interfaces for Databases in Practice\n",
      "Authors: ClaudeLehmann, DennisGehrig, StefanHoldener, CarloSaladin, João PedroMonteiro, KurtStockinger\n",
      "Abstract: Natural language interfaces to databases have recently made substantial progress due to advances in machine learning. Users no longer need technical knowledge to search for insights in their database. However, research is largely focused on increasing the one-shot accuracy, instead of building systems that interact with and guide a user’s search. In this demo, we present Veezoo, an AI-powered data analytics platform that enables users to directly talk to their databases.\n",
      "Submission Date: 23 August 2022\n",
      "DOI Link: https://doi.org/10.1145/3538712.3538744\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3626772.3657665\n",
      "PDF Link: None\n",
      "Title:A Question-Answering Assistant over Personal Knowledge Graph\n",
      "Authors: LingyuanLiu, HuifangDu, XiaolianZhang, MengyingGuo, HaofenWang, MengWang\n",
      "Abstract: We develop a Personal Knowledge Graph Question-Answering (PKGQA) assistant, seamlessly integrating information from multiple mobile applications into a unified and user-friendly query interface to offer users convenient information retrieval and personalized knowledge services. Based on a fine-grained schema customized for PKG, the PKGQA system in this paper comprises Symbolic Semantic Parsing, Frequently Asked Question (FAQ) Semantic Matching, and Neural Semantic Parsing modules, which are designed to take into account both accuracy and efficiency. The PKGQA system achieves high accuracy on the constructed dataset and demonstrates good performance in answering complex questions. Our system is implemented through an Android application, which is shown in https://youtu.be/p732U5KPEq4.\n",
      "Submission Date: 11 July 2024\n",
      "DOI Link: https://doi.org/10.1145/3626772.3657665\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3637528.3671505\n",
      "PDF Link: None\n",
      "Title:NL2Code-Reasoning and Planning with LLMs for Code Development\n",
      "Authors: YeXing, JunHuan, Wee HyongTok, CongShen, JohannesGehrke, KatherineLin, ArjunGuha, OmerTripp, Murali KrishnaRamanathan\n",
      "Abstract: There is huge value in making software development more productive with AI. An important component of this vision is the capability to translate natural language to a programming language (\"NL2Code\") and thus to significantly accelerate the speed at which code is written. This workshop gathers researchers, practitioners, and users from industry and academia that are working on NL2Code, specifically on the problem of using large language models to convert statements posed in a human language to a formal programming language.\n",
      "Submission Date: 24 August 2024\n",
      "DOI Link: https://doi.org/10.1145/3637528.3671505\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3626246.3655017\n",
      "PDF Link: None\n",
      "Title:Eighth Workshop on Human-In-the-Loop Data Analytics (HILDA)\n",
      "Authors: Jean-DanielFekete, KexinRong, BehroozOmidvar-Tehrani, RoeeShraga\n",
      "Abstract: HILDA brings together researchers and practitioners to exchange ideas and results on human-data interaction. It explores how data management and analysis can be made more effective when taking into account the people who design and build these processes as well as those who are impacted by their results. Following the past two years, we plan to continue to focus on this year's workshop on early-stage research that is promising and exciting, which includes pairing each accepted paper with a mentor. The theme for this edition of the workshop is HILDA and Large Language Models. However, the workshop is not limited to this theme and other topics are also of interest. In this summary, we describe the workshop, its main focus areas, our review and mentorship plan as well as the keynote and panel sessions.\n",
      "Submission Date: 09 June 2024\n",
      "DOI Link: https://doi.org/10.1145/3626246.3655017\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3701716.3715183\n",
      "PDF Link: https://dl.acm.org/doi/pdf/10.1145/3701716.3715183\n",
      "Title:Let the Augmentation Path Speak\n",
      "Authors: DaominJi, HuiLuo, ZhifengBao, ShaziaSadiq, J. ShaneCulpepper\n",
      "Abstract: In this work, we introduce a novel tool AugPath, for discovering relevant tabular data from a data lake to augment a base table, thereby supporting a wide range of downstream tasks, such and training data augmentation and table question answering (Q&A). Unlike traditional methods, such as unionable and joinable table search, which rely on one-hop and direct relationships for table augmentation, AugPath focuses on augmentation paths-sequences of interconnected tables linked to the base table through both direct and indirect relationships. By exploring these multi-step connections, AugPath enables more comprehensive and informative data augmentations, uncovering insights that traditional methods might overlook. Specifically, given a base table and a natural language statement, AugPath aims to identify and rank augmentation paths based on three core components: (1) a User Intent Extractor that utilizes a large language model (LLM) to analyze user intent and convert natural language statements into specific and actionable data requirements; (2) a Candidate Path Retriever that identifies all possible augmentation paths within a data lake that can be used for augmenting the base table; and (3) a Path Utility Evaluator that scores and ranks the paths using a novel utility metric, which considers both their relevance to the query and the diversity of the data they provide. AugPath enables users to discover augmentation paths that enhance common downstream tasks, such as training data augmentation and single/multiple table Q&A.\n",
      "Submission Date: 23 May 2025\n",
      "DOI Link: https://doi.org/10.1145/3701716.3715183\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3540250.3549140\n",
      "PDF Link: None\n",
      "Title:NL2Viz: natural language to visualization via constrained syntax-guided synthesis\n",
      "Authors: ZhengkaiWu, VuLe, AshishTiwari, SumitGulwani, ArjunRadhakrishna, IvanRadiček, GustavoSoares, XinyuWang, ZhenwenLi, TaoXie\n",
      "Abstract: Recent development in NL2CODE (Natural Language to Code) research allows end-users, especially novice programmers to create a concrete implementation of their ideas such as data visualization by providing natural language (NL) instructions. An NL2CODE system often fails to achieve its goal due to three major challenges: the user's words have contextual semantics, the user may not include all details needed for code generation, and the system results are imperfect and require further refinement. To address the aforementioned three challenges for NL to Visualization, we propose a new approach and its supporting tool named NL2VIZ with three salient features: (1) leveraging not only the user's NL input but also the data and program context that the NL query is upon, (2) using hard/soft constraints to reflect different confidence levels in the constraints retrieved from the user input and data/program context, and (3) providing support for result refinement and reuse. We implement NL2VIZ in the Jupyter Notebook environment and evaluate NL2VIZ on a real-world visualization benchmark and a public dataset to show the effectiveness of NL2VIZ. We also conduct a user study involving 6 data scientist professionals to demonstrate the usability of NL2VIZ, the readability of the generated code, and NL2VIZ's effectiveness in helping users generate desired visualizations effectively and efficiently.\n",
      "Submission Date: 09 November 2022\n",
      "DOI Link: https://doi.org/10.1145/3540250.3549140\n",
      "Processing link: https://dl.acm.org/doi/proceedings/10.1145/3698300\n",
      "PDF Link: None\n",
      "Title:None\n",
      "Author: None\n",
      "Abstract: None\n",
      "Submission Date: None\n",
      "DOI Link: None\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3663649.3664371\n",
      "PDF Link: None\n",
      "Title:Integrating LLMs into Database Systems Education\n",
      "Authors: KishorePrakash, ShashwatRao, RayanHamza, JackLukich, VatsalChaudhari, ArnabNandi\n",
      "Abstract: Large Language Models (LLMs) have sparked a drastic improvement in the ways computers can understand, process, and generate language. As LLM-based offerings become mainstream, we explore the incorporation of such LLMs into introductory or undergraduate database systems education. Students and instructors are both faced with the calculator dilemma: while the use of LLM-based tools may “solve” tasks such as assignments and exams, do they impede or accelerate the learning itself? We review deficiencies of using existing off-the-shelf tools for learning, and further articulate the differentiated needs of database systems students as opposed to trained data practitioners. Building on our exploration, we outline a vision that integrates LLMs into database education in a principled manner, keeping pedagogical best practices in mind. If implemented correctly, we posit that LLMs can drastically amplify the impact of existing instruction, minimizing costs and barriers towards learning database systems fundamentals.\n",
      "Submission Date: 02 July 2024\n",
      "DOI Link: https://doi.org/10.1145/3663649.3664371\n",
      "Processing link: https://dl.acm.org/doi/10.14778/3611540.3611624\n",
      "PDF Link: None\n",
      "Title:Lingua Manga : A Generic Large Language Model Centric System for Data Curation\n",
      "Authors: ZuiChen, LeiCao, SamMadden\n",
      "Abstract: Data curation is a wide-ranging area which contains many critical but time-consuming data processing tasks. However, the diversity of such tasks makes it challenging to develop a general-purpose data curation system. To address this issue, we present Lingua Manga, a user-friendly and versatile system that utilizes pre-trained large language models. Lingua Manga offers automatic optimization for achieving high performance and label efficiency while facilitating flexible and rapid development. Through three example applications with distinct objectives and users of varying levels of technical proficiency, we demonstrate that Lingua Manga can effectively assist both skilled programmers and low-code or even no-code users in addressing data curation challenges.\n",
      "Submission Date: 01 August 2023\n",
      "DOI Link: https://doi.org/10.14778/3611540.3611624\n",
      "Processing link: https://dl.acm.org/doi/proceedings/10.1145/3674399\n",
      "PDF Link: None\n",
      "Title:None\n",
      "Author: None\n",
      "Abstract: None\n",
      "Submission Date: None\n",
      "DOI Link: None\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3627673.3679713\n",
      "PDF Link: None\n",
      "Title:Aligning Large Language Models to a Domain-specific Graph Database for NL2GQL\n",
      "Authors: YuanyuanLiang, KerenTan, TingyuXie, WenbiaoTao, SiyuanWang, YunshiLan, WeiningQian\n",
      "Abstract: Graph Databases (Graph DB) find extensive application across diverse domains such as finance, social networks, and medicine. Yet, the translation of Natural Language (NL) into the Graph Query Language (GQL), referred to as NL2GQL, poses significant challenges owing to its intricate and specialized nature. Some approaches have sought to utilize Large Language Models (LLMs) to address analogous tasks like text2SQL. Nonetheless, in the realm of NL2GQL tasks tailored to a particular domain, the absence of domain-specific NL-GQL data pairs adds complexity to aligning LLMs with the graph DB. To tackle this challenge, we present a well-defined pipeline. Initially, we use ChatGPT to generate NL-GQL data pairs, leveraging the provided graph DB and two mutual verification self-instruct methods which ensure consistency between NL and GQL. Subsequently, we employ the generated data to fine-tune LLMs, ensuring alignment between LLMs and the graph DB. Moreover, we find the importance of relevant schema in efficiently generating accurate GQLs. Thus, we introduce a method to extract relevant schema as the input context. We evaluate our method using two carefully constructed datasets derived from graph DBs in the finance and medicine domains, named FinGQL and MediGQL. Experimental results reveal that our approach significantly outperforms a set of baseline methods, with improvements of 5.90 and 6.36 absolute points on EM, and 6.00 and 7.09 absolute points on EX for FinGQL and MediGQL, respectively\n",
      "Submission Date: 21 October 2024\n",
      "DOI Link: https://doi.org/10.1145/3627673.3679713\n",
      "Processing link: https://dl.acm.org/doi/proceedings/10.1145/3663742\n",
      "PDF Link: None\n",
      "Title:None\n",
      "Author: None\n",
      "Abstract: None\n",
      "Submission Date: None\n",
      "DOI Link: None\n",
      "Processing link: https://dl.acm.org/doi/proceedings/10.1145/3581641\n",
      "PDF Link: None\n",
      "Title:None\n",
      "Author: None\n",
      "Abstract: None\n",
      "Submission Date: None\n",
      "DOI Link: None\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3490099.3511161\n",
      "PDF Link: None\n",
      "Title:GridBook: Natural Language Formulas for the Spreadsheet Grid\n",
      "Authors: SrutiSrinivasa Ragavan, ZhitaoHou, YunWang, Andrew DGordon, HaidongZhang, DongmeiZhang\n",
      "Abstract: Writing formulas on the spreadsheet grid is arguably the most widely practiced form of programming. Still, studies highlight the difficulties experienced by end-user programmers when learning and using traditional formulas, especially for slightly complex tasks. The purpose of GridBook is to ease these difficulties by supporting formulas expressed in natural language within the grid; it is the first system to do so. GridBook builds on a parser utilizing deep learning to understand analysis intents from the natural language input within a spreadsheet cell. GridBook also leverages the spatial context between cells to infer the analysis parameters underspecified in the natural language input. Natural language enables users to analyze data easily and flexibly, to build queries on the results of previous analyses, and to view results intelligibly within the grid—thus taking spreadsheets one step closer to computational notebooks. We evaluated GridBook via two comparative lab studies, with 20 data analysts new only to GridBook. In our studies, there were no significant differences, in terms of time and cognitive load, in participants’ data analysis using GridBook and spreadsheets; however, data analysis with GridBook was significantly faster than with computational notebooks. Our study uncovers insights into the application of natural language as a special purpose programming language for end-user programming in spreadsheets.\n",
      "Submission Date: 22 March 2022\n",
      "DOI Link: https://doi.org/10.1145/3490099.3511161\n",
      "Processing link: https://dl.acm.org/doi/proceedings/10.1145/3665601\n",
      "PDF Link: None\n",
      "Title:None\n",
      "Author: None\n",
      "Abstract: None\n",
      "Submission Date: None\n",
      "DOI Link: None\n",
      "Processing link: https://dl.acm.org/doi/proceedings/10.1145/3689236\n",
      "PDF Link: None\n",
      "Title:None\n",
      "Author: None\n",
      "Abstract: None\n",
      "Submission Date: None\n",
      "DOI Link: None\n",
      "Processing link: https://dl.acm.org/doi/proceedings/10.1145/3538712\n",
      "PDF Link: None\n",
      "Title:None\n",
      "Author: None\n",
      "Abstract: None\n",
      "Submission Date: None\n",
      "DOI Link: None\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3448016.3452822\n",
      "PDF Link: None\n",
      "Title:Towards Enhancing Database Education: Natural Language Generation Meets Query Execution Plans\n",
      "Authors: WeiguoWang, Sourav S.Bhowmick, HuiLi, ShafiqJoty, SiyuanLiu, PengChen\n",
      "Abstract: The database systems course is offered as part of an undergraduate computer science degree program in many major universities. A key learning goal of learners taking such a course is to understand how sql queries are processed in a rdbms in practice. Since aquery execution plan (qep ) describes the execution steps of a query, learners can acquire the understanding by perusing the qep s generated by a rdbms. Unfortunately, in practice, it is often daunting for a learner to comprehend these qep s containing vendor-specific implementation details, hindering her learning process. In this paper, we present a novel, end-to-end,generic system called lantern that generates a natural language description of a qep to facilitate understanding of the query execution steps. It takes as input an sql query and its qep, and generates a natural language description of the execution strategy deployed by the underlying rdbms. Specifically, it deploys adeclarative framework called pool that enablessubject matter experts to efficiently create and maintain natural language descriptions of physical operators used in qep s. Arule-based framework called rule-lantern is proposed that exploits pool to generate natural language descriptions of qep s. Despite the high accuracy of rule-lantern, our engagement with learners reveal that, consistent with existing psychology theories, perusing such rule-based descriptions lead toboredom due to repetitive statements across different qep s. To address this issue, we present a noveldeep learning-based language generation framework called neural -lantern that infuses language variability in the generated description by exploiting a set ofparaphrasing tools andword embedding. Our experimental study with real learners shows the effectiveness of lantern in facilitating comprehension of qep s.\n",
      "Submission Date: 18 June 2021\n",
      "DOI Link: https://doi.org/10.1145/3448016.3452822\n",
      "Processing link: https://dl.acm.org/doi/proceedings/10.1145/3663649\n",
      "PDF Link: None\n",
      "Title:None\n",
      "Author: None\n",
      "Abstract: None\n",
      "Submission Date: None\n",
      "DOI Link: None\n",
      "Processing link: https://dl.acm.org/doi/proceedings/10.1145/3540250\n",
      "PDF Link: None\n",
      "Title:None\n",
      "Author: None\n",
      "Abstract: None\n",
      "Submission Date: None\n",
      "DOI Link: None\n",
      "Processing link: https://dl.acm.org/doi/proceedings/10.1145/3650215\n",
      "PDF Link: None\n",
      "Title:None\n",
      "Author: None\n",
      "Abstract: None\n",
      "Submission Date: None\n",
      "DOI Link: None\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3539618.3591759\n",
      "PDF Link: None\n",
      "Title:RHB-Net: A Relation-aware Historical Bridging Network for Text2SQL Auto-Completion\n",
      "Authors: BolongZheng, LeiBi, RuijieXi, LuChen, YunjunGao, XiaofangZhou, Christian S.Jensen\n",
      "Abstract: Test2SQL, a natural language interface to database querying, has seen considerable improvement, in part due to advances in deep learning. However, despite recent improvement, existing Text2SQL proposals allow only input in the form of complete questions. This leaves behind users who struggle to formulate complete questions, e.g., because they lack database expertise or are unfamiliar with the underlying database schema. To address this shortcoming, we study the novel problem of Text2SQL Auto-Completion (TSAC) that extends Text2SQL to also take partial or incomplete questions as input. Specifically, the TSAC problem is to predict the complete, executable SQL query. To solve the problem, we propose a novel Relation-aware Historical Bridging Network (RHB-Net) that consists of a relation-aware union encoder and an extraction-generation sensitive decoder. RHB-Net models relations between questions and database schemas and predicts the ambiguous intents expressed in partial queries. We also propose two optimization strategies: historical query bridging that fuses historical database queries, and a dynamic context construction that prevents repeated generation of the same SQL elements. Extensive experiments with real-world data offer evidence that RHB-Net is capable of outperforming baseline algorithms.\n",
      "Submission Date: 18 July 2023\n",
      "DOI Link: https://doi.org/10.1145/3539618.3591759\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3712704\n",
      "PDF Link: https://dl.acm.org/doi/pdf/10.1145/3712704\n",
      "Title:QATCH: Automatic Evaluation of SQL-Centric Tasks on Proprietary Data\n",
      "Authors: SimonePapicchio, PaoloPapotti, LucaCagliero\n",
      "Abstract: Tabular Representation Learning (TRL) and Large Language Models (LLMs) have become established for tackling Question Answering (QA) and Semantic Parsing (SP) tasks on tabular data. State-of-the-art models are pre-trained and evaluated on large open-domain datasets. However, the performance on existing QA and SP benchmarks is not necessarily representative of that achieved on proprietary data as the characteristics of the input and the complexity of the posed queries show high variability. To tackle this challenge, our goal is to allow end-users to evaluate TRL and LLM performance on their own proprietary data. We present Query-Aided TRL CHecklist (QATCH), a toolbox to automatically generate a testing checklist tailored to QA and SP. QATCH provides a testing suite highlighting models’ strengths and weaknesses on relational tables unseen at training time. The proposed toolbox relies on a SQL query generator that crafts tests of varying types and complexity including, amongst others, tests on null values, projection, selections, joins, group by, and having clauses. QATCH also supports a set of general cross-task performance metrics providing more insights into SQL-related model capabilities than currently used metrics. The empirical results, achieved by state-of-the-art TRL models and LLMs, show substantial performance differences (1) between existing benchmarks and proprietary data, (2) across queries of different complexity.\n",
      "Submission Date: 16 April 2025\n",
      "DOI Link: https://doi.org/10.1145/3712704\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3469213.3470416\n",
      "PDF Link: None\n",
      "Title:Research on Key Technologies of Customer Service Oriented Knowledge Q&A Robot\n",
      "Authors: LintanSun, WeiHan, YetengAn, ZhiminLi, RuiYang, ZixingYang\n",
      "Abstract: Dialogue robot, as the entrance service of intelligent system, has received extensive attention in recent years, especially in the field of customer service. Compared with manual customer service, dialogue robot is more efficient, more personalized and lower in cost, and can be expanded in terms of knowledge reserve and business scope. In this paper, based on the background of operation and maintenance customer service in electric power industry, the knowledge of electric power operation and maintenance is managed and serviced based on knowledge map and Text2SQL technology, and the scalable quick knowledge Q&A service is realized, which is integrated with the business system in the form of dialogue robot. In this paper, the related technologies of knowledge Q&A robot are studied and implemented.\n",
      "Submission Date: 18 August 2021\n",
      "DOI Link: https://doi.org/10.1145/3469213.3470416\n",
      "Processing link: https://dl.acm.org/doi/10.5555/3586589.3586934\n",
      "PDF Link: https://dl.acm.org/doi/pdf/10.5555/3586589.3586934\n",
      "Title:Constraint reasoning embedded structured prediction\n",
      "Authors: NanJiang, MaosenZhang, Willem-JanVan Hoeve, YexiangXue\n",
      "Abstract: Many real-world structured prediction problems need machine learning to capture data distribution and constraint reasoning to ensure structure validity. Nevertheless, constrained structured prediction is still limited in real-world applications because of the lack of tools to bridge constraint satisfaction and machine learning. In this paper, we propose COnstraint REasoning embedded Structured Prediction (Core-Sp), a scalable constraint reasoning and machine learning integrated approach for learning over structured domains. We propose to embed decision diagrams, a popular constraint reasoning tool, as a fully-differentiable module into deep neural networks for structured prediction. We also propose an iterative search algorithm to automate the searching process of the best Core-Sp structure. We evaluate Core-Sp on three applications: vehicle dispatching service planning, if-then program synthesis, and text2SQL generation. The proposed Core-Sp module demonstrates superior performance over state-of-the-art approaches in all three applications. The structures generated with Core-Sp satisfy 100% of the constraints when using exact decision diagrams. In addition, Core-Sp boosts learning performance by reducing the modeling space via constraint satisfaction.\n",
      "Submission Date: 01 January 2022\n",
      "DOI Link: None\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3650203.3663334\n",
      "PDF Link: https://dl.acm.org/doi/pdf/10.1145/3650203.3663334\n",
      "Title:Towards Efficient Data Wrangling with LLMs using Code Generation\n",
      "Authors: XueLi, TillDöhmen\n",
      "Abstract: While LLM-based data wrangling approaches that process each row of data have shown promising benchmark results, computational costs still limit their suitability for real-world use cases on large datasets. We revisit code generation using LLMs for various data wrangling tasks, which show promising results particularly for data transformation tasks (up to 37.2 points improvement on F1 score) at much lower computational costs. We furthermore identify shortcomings of code generation methods especially for semantically challenging tasks, and consequently propose an approach that combines program generation with a routing mechanism using LLMs.\n",
      "Submission Date: 09 June 2024\n",
      "DOI Link: https://doi.org/10.1145/3650203.3663334\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3649217.3653557\n",
      "PDF Link: https://dl.acm.org/doi/pdf/10.1145/3649217.3653557\n",
      "Title:Chatbot Development Using LangChain: A Case Study to Foster Critical Thinking and Creativity\n",
      "Authors: LauraFarinetti, LorenzoCanale\n",
      "Abstract: Critical thinking and creativity are fundamental skills for engineers and computer scientists. The emergence of Large Language Models (LLMs) able to create chatbots that use natural language is an opportunity for educators to foster these skills. The well-known risk of generative AI for potential misinformation offers fertile ground to practice critical thinking. This paper describes a hands-on experience within a database course, where students had to develop a chatbot using the LangChain framework, and to evaluate it from different points of view. The students were free to choose the domain of their chatbot. The learning goal was twofold: on the one hand, to make them practice with state-of-the-art technologies, and on the other hand to stimulate critical analysis on their output. The paper discusses the students' evaluation of the chatbots under several metrics, including document retrieval, syntax and grammar accuracy, semantic relevance and information reliability. Students' assessments were also compared to the teachers' ones, to gain an insight on the critical attitude of the students and to offer a ground for discussion. The experience was stimulating and appreciated by the students. The final results highlight that the majority of students successfully produced chatbot responses that were grammatically and syntactically correct, and that consistently extracted pertinent sections from documents, yielding semantically relevant outputs. Despite these achievements, a significant portion of students expressed reservations about the reliability of the chatbot's responses to prompts, gaining awareness of LLMs' capability to generate responses that make sense to humans but may be potentially misleading.\n",
      "Submission Date: 03 July 2024\n",
      "DOI Link: https://doi.org/10.1145/3649217.3653557\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3650203.3663333\n",
      "PDF Link: https://dl.acm.org/doi/pdf/10.1145/3650203.3663333\n",
      "Title:Reactive Dataflow for Inflight Error Handling in ML Workflows\n",
      "Authors: AbhilashJindal, KaustubhBeedkar, VishalSingh, J. NausheenMohammed, TusharSingla, AmanGupta, KeertiChoudhary\n",
      "Abstract: Modern data analytics pipelines comprise traditional data transformation operations and pre-trained ML models deployed as user-defined functions (UDFs). Such pipelines, which we call ML workflows, generally produce erroneous results due to data errors inadvertently introduced by ML models. Model errors are one of the main obstacles to improved accuracy of ML workflows. In this paper, we present Popper, a dataflow system---for expressing ML workflows---that natively supports inflight error handling. Users can extend ML workflows expressed in Popper by plugging in error handlers to improve accuracy. We propose reactive dataflow, a novel cyclic graph-based dataflow model that provides convenient abstractions for interleaving dataflow operators with user-defined error handlers for detecting and correcting errors on the fly. We also propose an efficient execution strategy amenable to pipeline parallel execution of reactive dataflow. We discuss open research challenges for making error handling a first-class citizen in dataflow systems and present preliminary evaluation of our prototypical system, which shows the effectiveness and benefits of inflight error handling in ML workflows.\n",
      "Submission Date: 09 June 2024\n",
      "DOI Link: https://doi.org/10.1145/3650203.3663333\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3397271.3401120\n",
      "PDF Link: None\n",
      "Title:Web Table Retrieval using Multimodal Deep Learning\n",
      "Authors: RoeeShraga, HaggaiRoitman, GuyFeigenblat, MustafaCannim\n",
      "Abstract: We address the web table retrieval task, aiming to retrieve and rank web tables as whole answers to a given information need. To this end, we formally define web tables as multimodal objects. We then suggest a neural ranking model, termed MTR, which makes a novel use of Gated Multimodal Units (GMUs) to learn a joint-representation of the query and the different table modalities. We further enhance this model with a co-learning approach which utilizes automatically learned query-independent and query-dependent \"helper'' labels. We evaluate the proposed solution using both ad hoc queries (WikiTables) and natural language questions (GNQtables). Overall, we demonstrate that our approach surpasses the performance of previously studied state-of-the-art baselines.\n",
      "Submission Date: 25 July 2020\n",
      "DOI Link: https://doi.org/10.1145/3397271.3401120\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3447548.3467279\n",
      "PDF Link: None\n",
      "Title:Table2Charts: Recommending Charts by Learning Shared Table Representations\n",
      "Authors: MengyuZhou, QingtaoLi, XinyiHe, YuejiangLi, YiboLiu, WeiJi, ShiHan, YiningChen, DaxinJiang, DongmeiZhang\n",
      "Abstract: It is common for people to create different types of charts to explore a multi-dimensional dataset (table). However, to recommend commonly composed charts in real world, one should take the challenges of efficiency, imbalanced data and table context into consideration. In this paper, we propose Table2Charts framework which learns common patterns from a large corpus of (table, charts) pairs. Based on deep Q-learning with copying mechanism and heuristic searching, Table2Charts does table-to-sequence generation, where each sequence follows a chart template. On a large spreadsheet corpus with 165k tables and 266k charts, we show that Table2Charts could learn a shared representation of table fields so that recommendation tasks on different chart types could mutually enhance each other. Table2Charts outperforms other chart recommendation systems in both multi-type task (with doubled recall numbers R@3=0.61 and R@1=0.43) and human evaluations.\n",
      "Submission Date: 14 August 2021\n",
      "DOI Link: https://doi.org/10.1145/3447548.3467279\n",
      "Processing link: https://dl.acm.org/doi/proceedings/10.1145/3650203\n",
      "PDF Link: None\n",
      "Title:None\n",
      "Author: None\n",
      "Abstract: None\n",
      "Submission Date: None\n",
      "DOI Link: None\n",
      "Processing link: https://dl.acm.org/doi/proceedings/10.1145/3649217\n",
      "PDF Link: None\n",
      "Title:None\n",
      "Author: None\n",
      "Abstract: None\n",
      "Submission Date: None\n",
      "DOI Link: None\n",
      "Processing link: https://dl.acm.org/doi/10.14778/3636218.3636225\n",
      "PDF Link: None\n",
      "Title:ScienceBenchmark: A Complex Real-World Benchmark for Evaluating Natural Language to SQL Systems\n",
      "Authors: YiZhang, JanDeriu, GeorgeKatsogiannis-Meimarakis, CatherineKosten, GeorgiaKoutrika, KurtStockinger\n",
      "Abstract: Natural Language to SQL systems (NL-to-SQL) have recently shown improved accuracy (exceeding 80%) for natural language to SQL query translation due to the emergence of transformer-based language models, and the popularity of the Spider benchmark. However, Spider mainly contains simple databases with few tables, columns, and entries, which do not reflect a realistic setting. Moreover, complex real-world databases with domain-specific content have little to no training data available in the form of NL/SQL-pairs leading to poor performance of existing NL-to-SQL systems. In this paper, we introduce ScienceBenchmark, a new complex NL-to-SQL benchmark for three real-world, highly domain-specific databases. For this new benchmark, SQL experts and domain experts created high-quality NL/SQL-pairs for each domain. To garner more data, we extended the small amount of human-generated data with synthetic data generated using GPT-3. We show that our benchmark is highly challenging, as the top performing systems on Spider achieve a very low performance on our benchmark. Thus, the challenge is many-fold: creating NL-to-SQL systems for highly complex domains with a small amount of hand-made training data augmented with synthetic data. To our knowledge, ScienceBenchmark is the first NL-to-SQL benchmark designed with complex real-world scientific databases, containing challenging training and test data carefully validated by domain experts.\n",
      "Submission Date: 01 December 2023\n",
      "DOI Link: https://doi.org/10.14778/3636218.3636225\n",
      "Processing link: https://dl.acm.org/doi/10.1145/2949741.2949743\n",
      "PDF Link: None\n",
      "Title:Technical Perspective: Natural Language to SQL Translation by Iteratively Exploring a Middle Ground\n",
      "Authors: Jeffrey F.Naughton\n",
      "Abstract: No abstract available.\n",
      "Submission Date: 02 June 2016\n",
      "DOI Link: https://doi.org/10.1145/2949741.2949743\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3183713.3193562\n",
      "PDF Link: https://dl.acm.org/doi/pdf/10.1145/3183713.3193562\n",
      "Title:DBPal: A Learned NL-Interface for Databases\n",
      "Authors: FuatBasik, BenjaminHättasch, AmirIlkhechi, ArifUsta, ShekarRamaswamy, PrasetyaUtama, NathanielWeir, CarstenBinnig, UgurCetintemel\n",
      "Abstract: In this demo, we present DBPal, a novel data exploration tool with a natural language interface. DBPal leverages recent advances in deep models to make query understanding more robust in the following ways: First, DBPal uses novel machine translation models to translate natural language statements to SQL, making the translation process more robust to paraphrasing and linguistic variations. Second, to support the users in phrasing questions without knowing the database schema and the query features, DBPal provides a learned auto-completion model that suggests to users partial query extensions during query formulation and thus helps to write complex queries.\n",
      "Submission Date: 27 May 2018\n",
      "DOI Link: https://doi.org/10.1145/3183713.3193562\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3701717.3733846\n",
      "PDF Link: https://dl.acm.org/doi/pdf/10.1145/3701717.3733846\n",
      "Title:Navigating the Challenges of AI-Driven Data Processing\n",
      "Authors: GeorgiaKoutrika\n",
      "Abstract: AI-driven data processing is revolutionizing the way researchers analyze vast datasets, enabling intuitive interactions and insightful answers. However, the integration of AI in data processing also introduces several challenges that must be addressed to ensure its reliability and trustworthiness. Key issues include hallucinations, where AI systems generate incorrect information; bias, which can lead to unfair outcomes; ethical considerations, such as privacy and misuse; explainability, to ensure transparency; and answer provenance, to verify the accuracy of AI outputs. These challenges can undermine the effectiveness of AI systems and potentially lead to incorrect or even harmful decisions. This talk explores these issues and discuss mitigation strategies.\n",
      "Submission Date: 09 June 2025\n",
      "DOI Link: https://doi.org/10.1145/3701717.3733846\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3718491.3718667\n",
      "PDF Link: None\n",
      "Title:Train an Intelligent Database with ChatGPT\n",
      "Authors: YifengJiang\n",
      "Abstract: The integration of AI into database management has the potential to reduce the complexities of SQL, making databases more accessible to non-technical users. Traditional database systems often require users to possess specialized knowledge in SQL, which creates significant barriers for non-technical professionals who need to query or manipulate data. This issue is particularly evident in industries such as marketing and finance, where professionals are often required to interact with databases but lack the necessary coding expertise. This research focuses on developing a Java-based system that utilizes ChatGPT to convert natural language into SQL commands, allowing non-technical users to interact with databases in a more intuitive and user-friendly manner. The primary research question addresses how AI, specifically ChatGPT, can bridge the gap between natural language and complex SQL syntax, enabling seamless database interactions without requiring users to learn SQL. The methodology involves configuring a MySQL environment, integrating the OpenAI API, and iteratively refining the system to handle basic database operations such as querying, inserting, and deleting data. The data for this study is sourced from a pre-existing MySQL database, which includes various sample datasets commonly used for testing database operations. The database contains multiple tables with different types of data, allowing the system to perform a variety of SQL operations. The results show that this system successfully lowers the barriers to database access, significantly improving the ease of use for non-technical users. However, limitations remain in handling more complex SQL queries and occasional inaccuracies in generated SQL commands. This paper concludes that AI-driven tools, like ChatGPT, have great potential to enhance database usability. Future work will focus on improving the accuracy of generated SQL commands, expanding the system's ability to handle complex queries, and refining the user interface to improve user experience.\n",
      "Submission Date: 02 April 2025\n",
      "DOI Link: https://doi.org/10.1145/3718491.3718667\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3568812.3603454\n",
      "PDF Link: None\n",
      "Title:Toward a Fundamental Understanding of SQL Education\n",
      "Authors: DaphneMiedema\n",
      "Abstract: Relational databases are ubiquitous in industry and have been for several decades. As such, almost all Computer Science bachelor degrees include one or more courses that teach about databases and their corresponding query language called Structured Query Language (SQL). However, many learners struggle with learning the language, making many mistakes and finding the problems hard to solve. In this paper, we explore the research done to identify learners’ issues as well as showcase some research that can support these learners.\n",
      "Submission Date: 13 September 2023\n",
      "DOI Link: https://doi.org/10.1145/3568812.3603454\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3627673.3679210\n",
      "PDF Link: https://dl.acm.org/doi/pdf/10.1145/3627673.3679210\n",
      "Title:LLM-PQA: LLM-enhanced Prediction Query Answering\n",
      "Authors: ZiyuLi, WenjieZhao, AsteriosKatsifodimos, RihanHai\n",
      "Abstract: The advent of Large Language Models (LLMs) provides an opportunity to change the way queries are processed, moving beyond the constraints of conventional SQL-based database systems. However, using an LLM to answer a prediction query is still challenging, since an external ML model has to be employed and inference has to be performed in order to provide an answer. This paper introduces LLM-PQA, a novel tool that addresses prediction queries formulated in natural language. LLM-PQA is the first to combine the capabilities of LLMs and retrieval-augmented mechanism for the needs of prediction queries by integrating data lakes and model zoos. This integration provides users with access to a vast spectrum of heterogeneous data and diverse ML models, facilitating dynamic prediction query answering. In addition, LLM-PQA can dynamically train models on demand, based on specific query requirements, ensuring reliable and relevant results even when no pre-trained model in a model zoo, available for the task.\n",
      "Submission Date: 21 October 2024\n",
      "DOI Link: https://doi.org/10.1145/3627673.3679210\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3732790\n",
      "PDF Link: https://dl.acm.org/doi/pdf/10.1145/3732790\n",
      "Title:Novice Perceptions on Effective Elements of PostgreSQL Error Messages\n",
      "Authors: ToniTaipalus, HilkkaGrahn, SaimaRitonummi, ValtteriSiitonen, TeroVartiainen, DenisZhidkikh\n",
      "Abstract: SQL compiler error messages are the primary way users receive feedback when they encounter syntax errors or other issues in their SQL queries. Effective error messages can enhance the user experience by providing clear, informative, and actionable feedback. Despite the age of SQL compilers, it still remains largely unclear what contributes to an effective SQL error message. With 2,052 answers yielded by 165 participants for qualitative analysis, this study is an attempt to understand what novices perceive as effective elements in SQL error messages. The results uniformly indicate that communicating the precise error position, articulating what is wrong in the query with clear natural language, and showing hints on how to fix the error are perceived as the most effective elements for error recovery. These insights have potential to be utilized in providing more effective error messages in SQL compilers and SQL learning environments, and for guiding generative AI for enhanced error messages in order to minimize frustration caused by cryptic error messages, improving learning and adoption, and reducing debugging time.\n",
      "Submission Date: 10 June 2025\n",
      "DOI Link: https://doi.org/10.1145/3732790\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3663649.3664368\n",
      "PDF Link: https://dl.acm.org/doi/pdf/10.1145/3663649.3664368\n",
      "Title:A Feasibility Study on Automated SQL Exercise Generation with ChatGPT-3.5\n",
      "Authors: WillemAerts, GeorgeFletcher, DaphneMiedema\n",
      "Abstract: SQL is the standard for database query languages and is taught in most introductory database courses. Query languages are illustrated and tested through toy examples: small, accessible, instances of databases. These are not always engaging, but coming up with new examples and questions is time-consuming. Existing research in Computer Science Education has shown that Large Language Models (LLMs) can generate coding exercises. However, this has not been demonstrated for SQL yet but could save teachers much time. In this paper, we study whether it is feasible to have ChatGPT-3.5 generate database schemas and associated SQL questions for teachers through a two-part study. Through a survey of educators, we found that creating a story and database schema for the SQL part is more time-consuming than the questions themselves. In our prompt engineering study, we identified prompts that were successful at creating database schemas, mock data, and exercises. However, although ChatGPT could help reduce the time required to create exams, some participants indicated that they are skeptical about using LLMs.\n",
      "Submission Date: 02 July 2024\n",
      "DOI Link: https://doi.org/10.1145/3663649.3664368\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3373477.3373478\n",
      "PDF Link: None\n",
      "Title:ISQNL: interpretable SQL query synthesizer from natural language input\n",
      "Authors: Shubham MilindPhal, Yatish HR, Tanmay SanjayHukkeri, AbhiramNatarajan, PrathikaGonchigar, DeepamalaN\n",
      "Abstract: Databases serve as the forefront for most systems today. Structured query language (SQL) is used to access and manipulate the data stored in a relational database. However, most end users have limited knowledge of SQL and thus face difficulties in accessing such systems. In this paper we describe a novel system (ISQNL) to convert a query provided in Natural Language (English) to an SQL query. By applying several natural language processing techniques ISQNL achieves this conversion without the need for any elaborate schema specific training/modification during setup and is robust enough to handle dynamically changing database states or database schema. ISQNL has demonstrated remarkable accuracy in SQL query synthesis when tested on large sets of natural language input. This paper discusses the methodology and key challenges involved in building ISQNL.\n",
      "Submission Date: 15 January 2020\n",
      "DOI Link: https://doi.org/10.1145/3373477.3373478\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3626246.3653374\n",
      "PDF Link: https://dl.acm.org/doi/pdf/10.1145/3626246.3653374\n",
      "Title:Measures in SQL\n",
      "Authors: JulianHyde, JohnFremlin\n",
      "Abstract: SQL has attained widespread adoption, but Business Intelligence tools still use their own higher level languages based upon a multidimensional paradigm. Composable calculations are what is missing from SQL, and we propose a new kind of column, called a measure, that attaches a calculation to a table. Like regular tables, tables with measures are composable and closed when used in queries. SQL-with-measures has the power, conciseness and reusability of multidimensional languages but retains SQL semantics. Measure invocations can be expanded in place to simple, clear SQL. To define the evaluation semantics for measures, we introduce context-sensitive expressions (a way to evaluate multidimensional expressions that is consistent with existing SQL semantics), a concept called evaluation context, and several operations for setting and modifying the evaluation context.\n",
      "Submission Date: 09 June 2024\n",
      "DOI Link: https://doi.org/10.1145/3626246.3653374\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3581906.3581922\n",
      "PDF Link: None\n",
      "Title:Question Answering Engines for Geospatial Knowledge Graphs\n",
      "Authors: DharmenPunjani, EleniTsalapati\n",
      "Abstract: None\n",
      "Submission Date: 14 June 2023\n",
      "DOI Link: https://doi.org/10.1145/3581906.3581922\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3613904.3641910\n",
      "PDF Link: None\n",
      "Title:SQL Puzzles: Evaluating Micro Parsons Problems With Different Feedbacks as Practice for Novices\n",
      "Authors: ZihanWu, Barbara J.Ericson\n",
      "Abstract: This paper investigates using micro Parsons problems as a novel practice approach for learning Structured Query Language (SQL). In micro Parsons problems learners arrange predefined code fragments to form a SQL statement instead of typing the code. SQL is a standard language for working with relational databases. Targeting beginner-level SQL statements, we evaluated the efficacy of micro Parsons problems with block-based feedback and execution-based feedback compared to traditional text-entry problems. To delve into learners’ experiences and preferences for the three problem types, we conducted a within-subjects think-aloud study with 12 participants. We found that learners reported very different preferences. Factors they considered included perceived learning, task authenticity, and prior knowledge. Next, we conducted two between-subjects classroom studies to evaluate the effectiveness of micro Parsons problems with different feedback types versus text-entry problems for SQL practice. We found that learners who practiced by solving Parsons problems with block-based feedback had a significantly higher learning gain than those who practiced with traditional text-entry problems.\n",
      "Submission Date: 11 May 2024\n",
      "DOI Link: https://doi.org/10.1145/3613904.3641910\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3318464.3383128\n",
      "PDF Link: None\n",
      "Title:State of the Art and Open Challenges in Natural Language Interfaces to Data\n",
      "Authors: FatmaŐzcan, AbdulQuamar, JaydeepSen, ChuanLei, VasilisEfthymiou\n",
      "Abstract: Recent advances in natural language understanding and processing resulted in renewed interest in natural language based interfaces to data, which provide an easy mechanism for non-technical users to access and query the data. While early systems only allowed simple selection queries over a single table, some recent work supports complex BI queries, with many joins and aggregation, and even nested queries. There are various approaches in the literature for interpreting user's natural language query. Rule-based systems try to identify the entities in the query, and understand the intended relationships between those entities. Recent years have seen the emergence and popularity of neural network based approaches which try to interpret the query holistically, by learning the patterns. In this tutorial, we will review these natural language interface solutions in terms of their interpretation approach, as well as the complexity of the queries they can generate. We will also discuss open research challenges.\n",
      "Submission Date: 31 May 2020\n",
      "DOI Link: https://doi.org/10.1145/3318464.3383128\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3654979\n",
      "PDF Link: https://dl.acm.org/doi/pdf/10.1145/3654979\n",
      "Title:Table-GPT: Table Fine-tuned GPT for Diverse Table Tasks\n",
      "Authors: PengLi, YeyeHe, DrorYashar, WeiweiCui, SongGe, HaidongZhang, DanielleRifinski Fainman, DongmeiZhang, SurajitChaudhuri\n",
      "Abstract: Language models, such as GPT-3 and ChatGPT, demonstrate remarkable abilities to follow diverse human instructions and perform a wide range of tasks, using instruction fine-tuning. However, when we test language models with a range of basic table-understanding tasks, we observe that today's language models are still sub-optimal in many table-related tasks, likely because they are pre-trained predominantly on one-dimensional natural-language texts, whereas relational tables are two-dimensional objects. In this work, we propose a new \"\\emphtable fine-tuning '' paradigm, where we continue to train/fine-tune language models like GPT-3.5 and ChatGPT, using diverse table-tasks synthesized from real tables as training data, which is analogous to \"instruction fine-tuning'', but with the goal of enhancing language models' ability to understand tables and perform table tasks. We show that our resulting \\sys models demonstrate: (1) better table-understanding capabilities, by consistently outperforming the vanilla GPT-3.5 and ChatGPT, on a wide range of table tasks (data transformation, data cleaning, data profiling, data imputation, table-QA, etc.), including tasks that are completely holdout and unseen during training, and (2) strong generalizability, in its ability to respond to diverse human instructions to perform new and unseen table-tasks, in a manner similar to GPT-3.5 and ChatGPT. Our code and data have been released at https://github.com/microsoft/Table-GPT for future research.\n",
      "Submission Date: 30 May 2024\n",
      "DOI Link: https://doi.org/10.1145/3654979\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3639305\n",
      "PDF Link: https://dl.acm.org/doi/pdf/10.1145/3639305\n",
      "Title:Wred: Workload Reduction for Scalable Index Tuning\n",
      "Authors: MatteoBrucato, TariqueSiddiqui, WentaoWu, VivekNarasayya, SurajitChaudhuri\n",
      "Abstract: Modern database systems offer index-tuning advisors that automatically identify a set of indexes to improve workload performance. Advisors leverage the optimizer's what-if API to optimize a query for a hypothetical index configuration. Because what-if calls constitute a major bottleneck of index tuning, existing techniques, such as workload compression, help reduce the number of what-if calls to speed up tuning. Unfortunately, even with small workloads and few what-if calls, tuning can still take hours due to the complexity of the queries (e.g., the number of joins, filters, group-by and order-by clauses), which increases their optimization time. This paper introduces workload reduction, a new complementary technique aimed at expediting index tuning by decreasing individual what-if call time without significantly affecting the quality of index tuning. We present an efficient workload reduction algorithm, called Wred, which rewrites each query in the original workload to eliminate column and table expressions unlikely to benefit from indexes, thereby accelerating what-if calls. We study its complexity and ability to maintain high index quality. We perform an extensive evaluation over industry benchmarks and real-world customer workloads, which shows that Wred results in a 3x median speedup in tuning efficiency over an industrial-strength state-of-the-art index advisor, with only a 3.7% median loss in improvement---where improvement is the total workload cost as estimated by the query optimizer---and results in up to 24.7x speedup with 1.8% improvement loss. Furthermore, combining Wred and Isum (a state-of-the-art workload compression technique for index tuning) results in higher speedups than either of the two techniques alone, with 10.5x median speedup and 5% median improvement loss.\n",
      "Submission Date: 26 March 2024\n",
      "DOI Link: https://doi.org/10.1145/3639305\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3626756\n",
      "PDF Link: None\n",
      "Title:Solo: Data Discovery Using Natural Language Questions Via A Self-Supervised Approach\n",
      "Authors: QimingWang, RaulCastro Fernandez\n",
      "Abstract: Most deployed data discovery systems, such as Google Datasets, and open data portals only support keyword search. Keyword search is geared towards general audiences but limits the types of queries the systems can answer. We propose a new system that lets users write natural language questions directly. A major barrier to using this learned data discovery system is it needs expensive-to-collect training data, thus limiting its utility. In this paper, we introduce a self-supervised approach to assemble training datasets and train learned discovery systems without human intervention. It requires addressing several challenges, including the design of self-supervised strategies for data discovery, table representation strategies to feed to the models, and relevance models that work well with the synthetically generated questions. We combine all the above contributions into a system, Solo, that solves the problem end to end. The evaluation results demonstrate the new techniques outperform state-of-the-art approaches on well-known benchmarks. All in all, the technique is a stepping stone towards building learned discovery systems.\n",
      "Submission Date: 12 December 2023\n",
      "DOI Link: https://doi.org/10.1145/3626756\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3469830.3470894\n",
      "PDF Link: None\n",
      "Title:NALMO: A Natural Language Interface for Moving Objects Databases\n",
      "Authors: XieyangWang, JianqiuXu, HuaLu\n",
      "Abstract: Moving objects databases (MODs) have been extensively studied due to their wide variety of applications including traffic management, tourist service and mobile commerce. However, queries in natural languages are still not supported in MODs. Since most users are not familiar with structured query languages, it is essentially important to bridge the gap between natural languages and the underlying MODs system commands. Motivated by this, we design a natural language interface for moving objects, named NALMO. In general, we use semantic parsing in combination with a location knowledge base and domain-specific rules to interpret natural language queries. We design a corpus of moving objects queries for model training, which is later used to determine the query type. Extracted entities from parsing are mapped through deterministic rules to perform query composition. NALMO is able to well translate moving objects queries into structured (executable) languages. We support four kinds of queries including time interval queries, range queries, nearest neighbor queries and trajectory similarity queries. We develop the system in a prototype system SECONDO and evaluate our approach using 240 natural language queries extracted from popular conference and journal papers in the domain of moving objects. Experimental results show that (i) NALMO achieves accuracy and precision 98.1 and 88.1, respectively, and (ii) the average time cost of translating a query is 1.47s.\n",
      "Submission Date: 23 August 2021\n",
      "DOI Link: https://doi.org/10.1145/3469830.3470894\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3452383.3452396\n",
      "PDF Link: None\n",
      "Title:Open Information Extraction Using Dependency Parser for Business Rule Mining in SBVR Format\n",
      "Authors: ChandanPrakash, Pavan KumarChittimalli, RavindraNaik\n",
      "Abstract: Business Rules exists at the core of any Business Organization. For efficient execution of the business system, all the business rules must be in machine-interpretable format. There is an absence of such a system that can convert the business rule sentences into corresponding structured format automatically. We present BRMiner, a system which automatically converts business rules represented as Natural Language sentences to the corresponding SBVR format which is a structured representation that can be further converted to the machine-interpretable format. BRMiner is based on the idea of Open Information Extraction (OIE). We have shown that existing OIE systems are not suitable for SBVR rule formation that leads to the development of a new OIE system BRMiner, with more accurate prediction and additional capabilities. BRMiner uses the state of the art dependency parser to convert an unstructured business rule to the corresponding structured format. We have used internal as well as publically available datasets for our system evaluation and the results are encouraging which we have shown in the paper.\n",
      "Submission Date: 26 April 2021\n",
      "DOI Link: https://doi.org/10.1145/3452383.3452396\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3313831.3376485\n",
      "PDF Link: None\n",
      "Title:Debugging Database Queries: A Survey of Tools, Techniques, and Users\n",
      "Authors: SnehaGathani, PeterLim, LeilaniBattle\n",
      "Abstract: Database management systems (or DBMSs) have been around for decades, and yet are still difficult to use, particularly when trying to identify and fix errors in user programs (or queries). We seek to understand what methods have been proposed to help people debug database queries, and whether these techniques have ultimately been adopted by DBMSs (and users). We conducted an interdisciplinary review of 112 papers and tools from the database, visualisation and HCI communities. To better understand whether academic and industry approaches are meeting the needs of users, we interviewed 20 database users (and some designers), and found surprising results. In particular, there seems to be a wide gulf between users' debugging strategies and the functionality implemented in existing DBMSs, as well as proposed in the literature. In response, we propose new design guidelines to help system designers to build features that more closely match users debugging strategies.\n",
      "Submission Date: 23 April 2020\n",
      "DOI Link: https://doi.org/10.1145/3313831.3376485\n",
      "Processing link: https://dl.acm.org/doi/10.1145/2661829.2661883\n",
      "PDF Link: None\n",
      "Title:Templated Search over Relational Databases\n",
      "Authors: AnastasiosZouzias, MichailVlachos, VagelisHristidis\n",
      "Abstract: Businesses and large organizations accumulate increasingly large amounts of customer interaction data. Analysis of such data holds great importance for tasks such as strategic planning and orchestration of sales/marketing campaigns. However, discovery and analysis over heterogeneous enterprise data can be challenging. Primary reasons for this are dispersed data repositories, requirements for schema knowledge, and difficulties in using complex user interfaces. As a solution to the above, we propose a TEmplated Search paradigm (TES) for exploring relational data that combines the advantages of keyword search interfaces with the expressive power of question-answering systems. The user starts typing a few keywords and TES proposes data exploration questions in real time. A key aspect of our approach is that the questions displayed are diverse to each other and optimally cover the space of possible questions for a given question-ranking framework. Efficient exact and provably approximate algorithms are presented. We show that the Templated Search paradigm renders the potentially complex underlying data sources intelligible and easily navigable. We support our claims with experimental results on real-world enterprise data.\n",
      "Submission Date: 03 November 2014\n",
      "DOI Link: https://doi.org/10.1145/2661829.2661883\n",
      "Processing link: https://dl.acm.org/doi/proceedings/10.1145/3568812\n",
      "PDF Link: None\n",
      "Title:None\n",
      "Author: None\n",
      "Abstract: None\n",
      "Submission Date: None\n",
      "DOI Link: None\n",
      "Processing link: https://dl.acm.org/doi/10.3115/1118845.1118847\n",
      "PDF Link: https://dl.acm.org/doi/pdf/10.3115/1118845.1118847\n",
      "Title:Multilingual question answering with high portability on relational databases\n",
      "Authors: HanminJung, Gary GeunbaeLee\n",
      "Abstract: This paper describes a highly-portable multilingual question answering system on multiple relational databases. We apply semantic category and pattern-based grammars, into natural language interfaces to relational databases. Lexico-semantic pattern (LSP) and multi-level grammars achieve portability of languages, domains, and DBMSs. The LSP-based linguistic processing does not require deep analysis that sacrifices robustness and flexibility, but can handle delicate natural language questions. To maximize portability, we drive various dependent parts into two tight corners, i.e., language-dependent part into front linguistic analysis, and domain-dependent and database-dependent parts into backend SQL query generation. Experiments with 779 queries generate only constraint-missing errors, which can be easily corrected by adding new terms, of 2.25% for English and 5.67% for Korean.\n",
      "Submission Date: 31 August 2002\n",
      "DOI Link: https://doi.org/10.3115/1118845.1118847\n",
      "Processing link: https://dl.acm.org/doi/proceedings/10.1145/3701717\n",
      "PDF Link: None\n",
      "Title:None\n",
      "Author: None\n",
      "Abstract: None\n",
      "Submission Date: None\n",
      "DOI Link: None\n",
      "Processing link: https://dl.acm.org/doi/book/10.1145/3581906\n",
      "PDF Link: None\n",
      "Title:None\n",
      "Author: None\n",
      "Abstract: None\n",
      "Submission Date: None\n",
      "DOI Link: None\n",
      "Processing link: https://dl.acm.org/doi/proceedings/10.1145/3718491\n",
      "PDF Link: None\n",
      "Title:None\n",
      "Author: None\n",
      "Abstract: None\n",
      "Submission Date: None\n",
      "DOI Link: None\n",
      "Processing link: https://dl.acm.org/doi/proceedings/10.1145/3613904\n",
      "PDF Link: None\n",
      "Title:None\n",
      "Author: None\n",
      "Abstract: None\n",
      "Submission Date: None\n",
      "DOI Link: None\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3712068\n",
      "PDF Link: https://dl.acm.org/doi/pdf/10.1145/3712068\n",
      "Title:Augmenting Human Potential: The Role of LLMs in Shaping the Future of HCI\n",
      "Authors: ChameeraDe Silva, ThilinaHalloluwa\n",
      "Abstract: None\n",
      "Submission Date: 25 February 2025\n",
      "DOI Link: https://doi.org/10.1145/3712068\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3516431.3516436\n",
      "PDF Link: None\n",
      "Title:INODE: Building an End-to-End Data Exploration System in Practice\n",
      "Authors: SihemAmer-Yahia, GeorgiaKoutrika, MartinBraschler, DiegoCalvanese, DavideLanti, HendrikLücke-Tieke, AlessandroMosca, TarcisioMendes de Farias, DimitrisPapadopoulos, YogendraPatil, GuillemRull, EllerySmith, DimitriosSkoutas, SrividyaSubramanian, KurtStockinger\n",
      "Abstract: A full-fledged data exploration system must combine different access modalities with a powerful concept of guiding the user in the exploration process, by being reactive and anticipative both for data discovery and for data linking. Such systems are a real opportunity for our community to cater to users with different domain and data science expertise. We introduce INODE - an end-to-end data exploration system - that leverages, on the one hand, Machine Learning and, on the other hand, semantics for the purpose of Data Management (DM). Our vision is to develop a classic unified, comprehensive platform that provides extensive access to open datasets, and we demonstrate it in three significant use cases in the fields of Cancer Biomarker Research, Research and Innovation Policy Making, and Astrophysics. INODE offers sustainable services in (a) data modeling and linking, (b) integrated query processing using natural language, (c) guidance, and (d) data exploration through visualization, thus facilitating the user in discovering new insights. We demonstrate that our system is uniquely accessible to a wide range of users from larger scientific communities to the public. Finally, we briefly illustrate how this work paves the way for new research opportunities in DM.\n",
      "Submission Date: 31 January 2022\n",
      "DOI Link: https://doi.org/10.1145/3516431.3516436\n",
      "Processing link: https://dl.acm.org/doi/10.14778/3476311.3476352\n",
      "PDF Link: None\n",
      "Title:DatAgent: the imminent age of intelligent data assistants\n",
      "Authors: AntonisMandamadiotis, StavroulaEleftherakis, ApostolosGlenis, DimitriosSkoutas, YannisStavrakas, GeorgiaKoutrika\n",
      "Abstract: In this demonstration, we present DatAgent, an intelligent data assistant system that allows users to ask queries in natural language, and can respond in natural language as well. Moreover, the system actively guides the user using different types of recommendations and hints, and learns from user actions. We will demonstrate different exploration scenarios that show how the system and the user engage in a human-like interaction inspired by the interaction paradigm of chatbots and virtual assistants.\n",
      "Submission Date: 01 July 2021\n",
      "DOI Link: https://doi.org/10.14778/3476311.3476352\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3527546.3527563\n",
      "PDF Link: None\n",
      "Title:Report on the 2nd international conference on design of experimental search & information retrieval systems (DESIRES 2021)\n",
      "Authors: OmarAlonso, StefanoMarchesin, MarcNajork, GianmariaSilvello\n",
      "Abstract: This is a report on the second edition of the International Conference on Design of Experimental Search & Information REtrieval Systems (DESIRES 2021) held at the Department of Information Engineering of the University od Padua (Padua, Italy) from September 15 to September 18, 2021. Date: 15--18 September, 2021. Website: http://desires.dei.unipd.it/.\n",
      "Submission Date: 17 March 2022\n",
      "DOI Link: https://doi.org/10.1145/3527546.3527563\n",
      "Processing link: https://dl.acm.org/doi/10.14778/3611479.3611534\n",
      "PDF Link: None\n",
      "Title:Auto-Tables: Synthesizing Multi-Step Transformations to Relationalize Tables without Using Examples\n",
      "Authors: PengLi, YeyeHe, CongYan, YueWang, SurajitChaudhuri\n",
      "Abstract: Relational tables, where each row corresponds to an entity and each column corresponds to an attribute, have been the standard for tables in relational databases. However, such a standard cannot be taken for granted when dealing with tables \"in the wild\". Our survey of real spreadsheet-tables and web-tables shows that over 30% of such tables do not conform to the relational standard, for which complex table-restructuring transformations are needed before these tables can be queried easily using SQL-based tools. Unfortunately, the required transformations are non-trivial to program, which has become a substantial pain point for technical and non-technical users alike, as evidenced by large numbers of forum questions in places like StackOverflow and Excel/Tableau forums. We develop an Auto-Tables system that can automatically synthesize pipelines with multi-step transformations (in Python or other languages), to transform non-relational tables into standard relational forms for downstream analytics, obviating the need for users to manually program transformations. We compile an extensive benchmark for this new task, by collecting 244 real test cases from user spreadsheets and online forums. Our evaluation suggests that Auto-Tables can successfully synthesize transformations for over 70% of test cases at interactive speeds, without requiring any input from users, making this an effective tool for both technical and non-technical users to prepare data for analytics.\n",
      "Submission Date: 01 July 2023\n",
      "DOI Link: https://doi.org/10.14778/3611479.3611534\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3514221.3526166\n",
      "PDF Link: https://dl.acm.org/doi/pdf/10.1145/3514221.3526166\n",
      "Title:PI2: End-to-end Interactive Visualization Interface Generation from Queries\n",
      "Authors: YiruChen, EugeneWu\n",
      "Abstract: Interactive visualization interfaces are critical in data analysis. Yet creating new interfaces is challenging, as the developer must understand the queries needed for the desired analysis task, and then design the appropriate interface. Existing task models are too abstract to be used to automatically generate interfaces, and visualization recommenders do not take the queries nor interactions into account. PI2 is the first system to generate fully functional interactive visualization interfaces from a representative sequence of task queries. PI2 analyzes queries syntactically and proposes a novel Difftree representation that encodes the systematic variations between query abstract syntax trees. PI2 then poses interface generation as a schema mapping problem from each Difftree to a visualization that renders its results, and the variations encoded in each Difftree to interactions in the interface. Interface generation further takes the layout and screen size into account. Our user studies show that PI2 interfaces are comparable to or better than those designed by developers, and that PI2 can generate exploration interfaces that are easier to use than the state-of-the-art SQL notebook products. What's more, PI2 generates high-quality interfaces within a few seconds.\n",
      "Submission Date: 11 June 2022\n",
      "DOI Link: https://doi.org/10.1145/3514221.3526166\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3643894\n",
      "PDF Link: None\n",
      "Title:Talk2Data: A Natural Language Interface for Exploratory Visual Analysis via Question Decomposition\n",
      "Authors: YiGuo, DanqingShi, MingjuanGuo, YanqiuWu, NanCao, QingChen\n",
      "Abstract: Through a natural language interface (NLI) for exploratory visual analysis, users can directly “ask” analytical questions about the given tabular data. This process greatly improves user experience and lowers the technical barriers of data analysis. Existing techniques focus on generating a visualization from a concrete question. However, complex questions, requiring multiple data queries and visualizations to answer, are frequently asked in data exploration and analysis, which cannot be easily solved with the existing techniques. To address this issue, in this article, we introduce Talk2Data, a natural language interface for exploratory visual analysis that supports answering complex questions. It leverages an advanced deep-learning model to resolve complex questions into a series of simple questions that could gradually elaborate on the users’ requirements. To present answers, we design a set of annotated and captioned visualizations to represent the answers in a form that supports interpretation and narration. We conducted an ablation study and a controlled user study to evaluate the Talk2Data’s effectiveness and usefulness.\n",
      "Submission Date: 22 April 2024\n",
      "DOI Link: https://doi.org/10.1145/3643894\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3654777.3676359\n",
      "PDF Link: https://dl.acm.org/doi/pdf/10.1145/3654777.3676359\n",
      "Title:\"The Data Says Otherwise\" — Towards Automated Fact-checking and Communication of Data Claims\n",
      "Authors: YuFu, ShunanGuo, JaneHoffswell, VictorS. Bursztyn, RyanRossi, JohnStasko\n",
      "Abstract: Fact-checking data claims requires data evidence retrieval and analysis, which can become tedious and intractable when done manually. This work presents Aletheia, an automated fact-checking prototype designed to facilitate data claims verification and enhance data evidence communication. For verification, we utilize a pre-trained LLM to parse the semantics for evidence retrieval. To effectively communicate the data evidence, we design representations in two forms: data tables and visualizations, tailored to various data fact types. Additionally, we design interactions that showcase a real-world application of these techniques. We evaluate the performance of two core NLP tasks with a curated dataset comprising 400 data claims and compare the two representation forms regarding viewers’ assessment time, confidence, and preference via a user study with 20 participants. The evaluation offers insights into the feasibility and bottlenecks of using LLMs for data fact-checking tasks, potential advantages and disadvantages of using visualizations over data tables, and design recommendations for presenting data evidence.\n",
      "Submission Date: 11 October 2024\n",
      "DOI Link: https://doi.org/10.1145/3654777.3676359\n",
      "Processing link: https://dl.acm.org/doi/10.14778/3229863.3236241\n",
      "PDF Link: None\n",
      "Title:NLproveNAns: natural language provenance for non-answers\n",
      "Authors: DanielDeutch, NaveFrost, AmirGilad, TomerHaimovich\n",
      "Abstract: Natural language (NL) interfaces to databases allow users without technical background to query the database and get the results. Users of such systems may be surprised by the absence of certain expected results. To this end, we propose to demonstrate NLProveNAns, a system that allows non-expert users to view explanations for non-answers of interest. The explanations are shown in an intuitive manner, by highlighting parts of the original NL query that are intuitively \"responsible\" for the absence of the expected result. Our solution builds upon and combines recent advancements in Natural Language Interfaces to Databases and models for why-not provenance. In particular, the systems can provide explanations in one of two flavors corresponding to two different why-not provenance models: a short explanation based on the frontier picky model, and a detailed explanation based on the why-not polynomial model.\n",
      "Submission Date: 01 August 2018\n",
      "DOI Link: https://doi.org/10.14778/3229863.3236241\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3411764.3445400\n",
      "PDF Link: None\n",
      "Title:Collecting and Characterizing Natural Language Utterances for Specifying Data Visualizations\n",
      "Authors: ArjunSrinivasan, NikhilaNyapathy, BongshinLee, Steven M.Drucker, JohnStasko\n",
      "Abstract: Natural language interfaces (NLIs) for data visualization are becoming increasingly popular both in academic research and in commercial software. Yet, there is a lack of empirical understanding of how people specify visualizations through natural language. We conducted an online study (N = 102), showing participants a series of visualizations and asking them to provide utterances they would pose to generate the displayed charts. From the responses, we curated a dataset of 893 utterances and characterized the utterances according to (1) their phrasing (e.g., commands, queries, questions) and (2) the information they contained (e.g., chart types, data aggregations). To help guide future research and development, we contribute this utterance dataset and discuss its applications toward the creation and benchmarking of NLIs for visualization.\n",
      "Submission Date: 07 May 2021\n",
      "DOI Link: https://doi.org/10.1145/3411764.3445400\n",
      "Processing link: https://dl.acm.org/doi/10.14778/3603581.3603596\n",
      "PDF Link: None\n",
      "Title:Auto-BI: Automatically Build BI-Models Leveraging Local Join Prediction and Global Schema Graph\n",
      "Authors: YimingLin, YeyeHe, SurajitChaudhuri\n",
      "Abstract: Business Intelligence (BI) is crucial in modern enterprises and billion-dollar business. Traditionally, technical experts like database administrators would manually prepare BI-models (e.g., in star or snowflake schemas) that join tables in data warehouses, before less-technical business users can run analytics using end-user dashboarding tools. However, the popularity of self-service BI (e.g., Tableau and Power-BI) in recent years creates a strong demand for less technical end-users to build BI-models themselves. We develop an Auto-BI system that can accurately predict BI models given a set of input tables, using a principled graph-based optimization problem we propose called k-Min-Cost-Arborescence (k-MCA), which holistically considers both local join prediction and global schema-graph structures, leveraging a graph-theoretical structure called arborescence. While we prove k-MCA is intractable and inapproximate in general, we develop novel algorithms that can solve k-MCA optimally, which is shown to be efficient in practice with sub-second latency and can scale to the largest BI-models we encounter (with close to 100 tables). Auto-BI is rigorously evaluated on a unique dataset with over 100K real BI models we harvested, as well as on 4 popular TPC benchmarks. It is shown to be both efficient and accurate, achieving over 0.9 F1-score on both real and synthetic benchmarks.\n",
      "Submission Date: 01 June 2023\n",
      "DOI Link: https://doi.org/10.14778/3603581.3603596\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3277006.3277017\n",
      "PDF Link: None\n",
      "Title:Natural Language Explanations for Query Results\n",
      "Authors: DanielDeutch, NaveFrost, AmirGilad\n",
      "Abstract: Multiple lines of research have developed Natural Language (NL) interfaces for formulating database queries. We build upon this work, but focus on presenting a highly detailed form of the answers in NL. The answers that we present are importantly based on the provenance of tuples in the query result, detailing not only the results but also their explanations. We develop a novel method for transforming provenance information to NL, by leveraging the original NL query structure. Furthermore, since provenance information is typically large and complex, we present two solutions for its effective presentation as NL text: one that is based on provenance factorization, with novel desiderata relevant to the NL case, and one that is based on summarization.\n",
      "Submission Date: 10 September 2018\n",
      "DOI Link: https://doi.org/10.1145/3277006.3277017\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3318464.3386139\n",
      "PDF Link: None\n",
      "Title:An Ontology-Based Conversation System for Knowledge Bases\n",
      "Authors: AbdulQuamar, ChuanLei, DorianMiller, FatmaOzcan, JeffreyKreulen, Robert J.Moore, VasilisEfthymiou\n",
      "Abstract: Domain-specific knowledge bases (KB), carefully curated from various data sources, provide an invaluable reference for professionals. Conversation systems make these KBs easily accessible to professionals and are gaining popularity due to recent advances in natural language understanding and AI. Despite the increasing use of various conversation systems in open-domain applications, the requirements of a domain-specific conversation system are quite different and challenging. In this paper, we propose an ontology-based conversation system for domain-specific KBs. In particular, we exploit the domain knowledge inherent in the domain ontology to identify user intents, and the corresponding entities to bootstrap the conversation space. We incorporate the feedback from domain experts to further refine these patterns, and use them to generate training samples for the conversation model, lifting the heavy burden from the conversation designers. We have incorporated our innovations into a conversation agent focused on healthcare as a feature of the IBM Micromedex product.\n",
      "Submission Date: 31 May 2020\n",
      "DOI Link: https://doi.org/10.1145/3318464.3386139\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3485535\n",
      "PDF Link: https://dl.acm.org/doi/pdf/10.1145/3485535\n",
      "Title:Multi-modal program inference: a marriage of pre-trained language models and component-based synthesis\n",
      "Authors: KiaRahmani, MohammadRaza, SumitGulwani, VuLe, DanielMorris, ArjunRadhakrishna, GustavoSoares, AshishTiwari\n",
      "Abstract: Multi-modal program synthesis refers to the task of synthesizing programs (code) from their specification given in different forms, such as a combination of natural language and examples. Examples provide a precise but incomplete specification, and natural language provides an ambiguous but more \"complete\" task description. Machine-learned pre-trained models (PTMs) are adept at handling ambiguous natural language, but struggle with generating syntactically and semantically precise code. Program synthesis techniques can generate correct code, often even from incomplete but precise specifications, such as examples, but they are unable to work with the ambiguity of natural languages. We present an approach that combines PTMs with component-based synthesis (CBS): PTMs are used to generate candidates programs from the natural language description of the task, which are then used to guide the CBS procedure to find the program that matches the precise examples-based specification. We use our combination approach to instantiate multi-modal synthesis systems for two programming domains: the domain of regular expressions and the domain of CSS selectors. Our evaluation demonstrates the effectiveness of our domain-agnostic approach in comparison to a state-of-the-art specialized system, and the generality of our approach in providing multi-modal program synthesis from natural language and examples in different programming domains.\n",
      "Submission Date: 15 October 2021\n",
      "DOI Link: https://doi.org/10.1145/3485535\n",
      "Processing link: https://dl.acm.org/doi/10.14778/3055540.3055550\n",
      "PDF Link: None\n",
      "Title:Provenance for natural language queries\n",
      "Authors: DanielDeutch, NaveFrost, AmirGilad\n",
      "Abstract: Multiple lines of research have developed Natural Language (NL) interfaces for formulating database queries. We build upon this work, but focus on presenting a highly detailed form of the answers in NL. The answers that we present are importantly based on the provenance of tuples in the query result, detailing not only the results but also their explanations. We develop a novel method for transforming provenance information to NL, by leveraging the original NL query structure. Furthermore, since provenance information is typically large and complex, we present two solutions for its effective presentation as NL text: one that is based on provenance factorization, with novel desiderata relevant to the NL case, and one that is based on summarization. We have implemented our solution in an end-to-end system supporting questions, answers and provenance, all expressed in NL. Our experiments, including a user study, indicate the quality of our solution and its scalability.\n",
      "Submission Date: 01 January 2017\n",
      "DOI Link: https://doi.org/10.14778/3055540.3055550\n",
      "Processing link: https://dl.acm.org/doi/10.14778/2824032.2824042\n",
      "PDF Link: None\n",
      "Title:A natural language interface for querying general and individual knowledge\n",
      "Authors: ChenLi, VolkerMarkl, YaelAmsterdamer, AnnaKukliansky, TovaMilo\n",
      "Abstract: Many real-life scenarios require the joint analysis of general knowledge, which includes facts about the world, with individual knowledge, which relates to the opinions or habits of individuals. Recently developed crowd mining platforms, which were designed for such tasks, are a major step towards the solution. However, these platforms require users to specify their information needs in a formal, declarative language, which may be too complicated for naïve users. To make the joint analysis of general and individual knowledge accessible to the public, it is desirable to provide an interface that translates the user questions, posed in natural language (NL), into the formal query languages that crowd mining platforms support. While the translation of NL questions to queries over conventional databases has been studied in previous work, a setting with mixed individual and general knowledge raises unique challenges. In particular, to support the distinct query constructs associated with these two types of knowledge, the NL question must be partitioned and translated using different means; yet eventually all the translated parts should be seamlessly combined to a well-formed query. To account for these challenges, we design and implement a modular translation framework that employs new solutions along with state-of-the art NL parsing tools. The results of our experimental study, involving real user questions on various topics, demonstrate that our framework provides a high-quality translation for many questions that are not handled by previous translation tools.\n",
      "Submission Date: 01 August 2015\n",
      "DOI Link: https://doi.org/10.14778/2824032.2824042\n",
      "Processing link: https://dl.acm.org/doi/10.3115/992730.992808\n",
      "PDF Link: https://dl.acm.org/doi/pdf/10.3115/992730.992808\n",
      "Title:Querying temporal databases using controlled natural language\n",
      "Authors: RaniNelken, NissimFrancez\n",
      "Abstract: Recent years have shown a surge in interest in temporal database systems, which allow users to store time-dependent information. We present a novel controlled natural language interface to temporal databases, based on translating natural language questions into SQL/Temporal, a temporal database query language. The syntactic analysis is done using the Type-Logical Grammar framework, highlighting its utility not only as a theoretical framework but also as a practical tool. The semantic analysis is done using a novel theory of the semantics of temporal questions, focusing on the role of temporal preposition phrases rather than the more traditional focus on tense and aspect. Our translation method is considerably simpler than previous attempts in this direction. We present a prototype software implementation.\n",
      "Submission Date: 31 July 2000\n",
      "DOI Link: https://doi.org/10.3115/992730.992808\n",
      "Processing link: https://dl.acm.org/doi/proceedings/10.1145/3411764\n",
      "PDF Link: None\n",
      "Title:None\n",
      "Author: None\n",
      "Abstract: None\n",
      "Submission Date: None\n",
      "DOI Link: None\n",
      "Processing link: https://dl.acm.org/doi/10.1145/3665939.3665957\n",
      "PDF Link: None\n",
      "Title:Cocoon: Semantic Table Profiling Using Large Language Models\n",
      "Authors: ZezhouHuang, EugeneWu\n",
      "Abstract: Data profilers play a crucial role in the preprocessing phase of data analysis by identifying quality issues such as missing, extreme, or erroneous values. Traditionally, profilers have relied solely on statistical methods, which lead to high false positives and false negatives. For example, they may incorrectly flag missing values where such absences are expected and normal based on the data's semantic context. To address these, we introduce Cocoon, a data profiling system that integrates LLMs to imbue statistical profiling with semantics. Cocoon enhances traditional profiling methods by adding a three-step process: Semantic Context, Semantic Profile, and Semantic Review. Our user studies show that Cocoon is highly effective at accurately discerning whether anomalies are genuine errors requiring correction or acceptable variations based on the semantics for real-world datasets.\n",
      "Submission Date: 18 June 2024\n",
      "DOI Link: https://doi.org/10.1145/3665939.3665957\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from DrissionPage import ChromiumPage\n",
    "\n",
    "paper = pd.read_csv('../raw_crawl_papers/acm/all_acm_papers.csv')\n",
    "\n",
    "titles = []\n",
    "authors = []\n",
    "pdf_links = []\n",
    "abstracts = [] \n",
    "dois = []\n",
    "submitted_dates = []\n",
    "\n",
    "page = ChromiumPage()\n",
    "for link in paper['link']:\n",
    "\n",
    "    print(f\"Processing link: {link}\")\n",
    "\n",
    "    title, author, pdf_link, abstract, doi, submitted_date = extract_detail(page, link)\n",
    "    titles.append(title)\n",
    "    authors.append(author)\n",
    "    pdf_links.append(pdf_link)\n",
    "    abstracts.append(abstract)\n",
    "    dois.append(doi)\n",
    "    submitted_dates.append(submitted_date)\n",
    "\n",
    "# Create a DataFrame with the extracted details\n",
    "paper['pdf_link'] = pdf_links\n",
    "paper['title'] = titles\n",
    "paper['authors'] = authors\n",
    "paper['abstract'] = abstracts\n",
    "paper['submitted'] = submitted_dates\n",
    "paper['doi'] = dois\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "paper.to_csv('../all_acm_papers.csv', index=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd98c38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "page.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9102094e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe02281",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crawl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
