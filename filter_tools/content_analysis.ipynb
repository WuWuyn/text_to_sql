{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b326f4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from google import genai\n",
    "import PyPDF2\n",
    "import os\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c973fb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Danh sách API keys\n",
    "api_keys = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8fb4319e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Biến toàn cục để quản lý rotate API keys\n",
    "current_key_index = 0\n",
    "request_count = 0\n",
    "max_requests_per_key = 10  # Rotate sau 10 requests\n",
    "requests_in_minute = 0\n",
    "minute_start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d683c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm lấy API key hiện tại và rotate nếu cần\n",
    "def get_current_api_key():\n",
    "    global current_key_index, request_count, requests_in_minute, minute_start_time\n",
    "    # Kiểm tra giới hạn 15 requests/phút\n",
    "    current_time = time.time()\n",
    "    if current_time - minute_start_time >= 60:\n",
    "        requests_in_minute = 0\n",
    "        minute_start_time = current_time\n",
    "    \n",
    "    if requests_in_minute >= 15:\n",
    "        print(\"Đạt giới hạn 15 requests/phút. Đợi 65 giây...\")\n",
    "        time.sleep(65)\n",
    "        requests_in_minute = 0\n",
    "        minute_start_time = time.time()\n",
    "    \n",
    "    # Rotate key sau 10 requests\n",
    "    if request_count >= max_requests_per_key:\n",
    "        current_key_index = (current_key_index + 1) % len(api_keys)\n",
    "        request_count = 0\n",
    "        print(f\"Đã chuyển sang API key: {api_keys[current_key_index]}\")\n",
    "    \n",
    "    request_count += 1\n",
    "    requests_in_minute += 1\n",
    "    return api_keys[current_key_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97a79544",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_structure = \"\"\"\n",
    "    {\n",
    "        \"paper_identification\": {\n",
    "            \"title\": \"Extract the title of the paper exactly as it appears.\",\n",
    "            \"authors\": \"List all authors in the order they are presented, including their affiliations if provided.\",\n",
    "            \"publication_venue_year\": \"Specify the publication venue (e.g., conference, journal) and the year of publication.\"\n",
    "        },\n",
    "        \"abstract_analysis\": {\n",
    "            \"problem_statement\": {\n",
    "                \"analysis\": \"Identify and describe the core problem in Text-to-SQL that the paper aims to solve, as explicitly stated in the abstract. Focus on the specific challenge or gap the authors highlight, such as limitations in natural language understanding, schema complexity, or query accuracy.\",\n",
    "                \"evidence\": \"Provide a direct quote or a precise paraphrase from the abstract that clearly defines the problem.\"\n",
    "            },\n",
    "            \"proposed_methodology_summary\": {\n",
    "                \"analysis\": \"Summarize the core methodology or system proposed by the authors to address the identified problem. Include the key components or techniques mentioned in the abstract, such as neural network architectures, prompt engineering, or retrieval mechanisms.\",\n",
    "                \"evidence\": \"Quote or specifically paraphrase the part of the abstract that outlines the proposed approach.\"\n",
    "            },\n",
    "            \"key_achievements_summary\": {\n",
    "                \"analysis\": \"Summarize the main achievements, key results, or the claimed 'goodness' of their approach as highlighted in the abstract. This may include performance improvements (e.g., accuracy gains), novel capabilities (e.g., handling complex queries), or other significant outcomes (e.g., scalability).\",\n",
    "                \"evidence\": \"Quote or specifically paraphrase the abstract's statements about the results or contributions.\"\n",
    "            }\n",
    "        },\n",
    "        \"introduction_analysis\": {\n",
    "            \"background\": {\n",
    "                \"analysis\": \"Describe the general background context provided in the introduction, including any historical developments (e.g., evolution of Text-to-SQL systems), current challenges (e.g., schema ambiguity, multi-table queries), or the broader problem area (e.g., natural language interfaces to databases) that sets the stage for the specific research problem. Highlight how this context relates to the field of Text-to-SQL.\",\n",
    "                \"evidence\": \"Quote or specifically paraphrase from the introduction to support the background description.\"\n",
    "            },\n",
    "            \"literature_review\": {\n",
    "                \"analysis\": \"Conduct an in-depth analysis of the literature review, which may be integrated into the introduction or presented separately. Focus on the following aspects:\\n- Identify and categorize the existing Text-to-SQL approaches discussed (e.g., rule-based systems, statistical models, neural networks, hybrid methods).\\n- For each major approach or key study mentioned, summarize:\\n    - The core methodology or technique used (e.g., parsing techniques, encoder-decoder models).\\n    - The main findings or contributions (e.g., accuracy on specific benchmarks).\\n    - Any reported limitations or challenges (e.g., inability to generalize across datasets).\\n- Describe how the current paper builds upon, extends, or differs from these existing approaches (e.g., by introducing a novel component or addressing a specific limitation).\\n- Highlight any gaps or unresolved issues in the literature that the paper aims to address (e.g., lack of robustness in real-world scenarios).\\n- If applicable, note any comparative analyses or discussions of the strengths and weaknesses of different approaches provided by the authors.\\n- Observe any trends or shifts in the field as reflected in the literature discussed (e.g., the move from rule-based to neural approaches).\\n- If the literature review is extensive, prioritize summarizing the most relevant or influential works that directly relate to the paper's contributions.\",\n",
    "                \"evidence\": \"Provide quotes or specific paraphrases from the relevant section(s) to support each point of analysis.\"\n",
    "            },\n",
    "            \"extended_detail_on_context\": {\n",
    "                \"analysis\": \"Identify and describe any specific aspects of the background or prior work that the paper extends or details further. This could include deeper explanations of certain techniques (e.g., how schema linking is performed), additional context on challenges (e.g., handling nested queries), or clarifications on the problem space (e.g., specific database types).\",\n",
    "                \"evidence\": \"Quote or specifically paraphrase from the introduction to illustrate these extensions.\"\n",
    "            },\n",
    "            \"problem_definition_detailed\": {\n",
    "                \"analysis\": \"Explain how the paper formally or in-depth defines the Text-to-SQL problem it addresses within the introduction. Include any specific constraints (e.g., single-table vs. multi-table queries), assumptions (e.g., schema availability), or scope limitations (e.g., focus on specific query types) mentioned.\",\n",
    "                \"evidence\": \"Quote or specifically paraphrase the detailed problem definition from the introduction.\"\n",
    "            },\n",
    "            \"existing_approaches_overview\": {\n",
    "                \"analysis\": \"Summarize the general categories (e.g., syntax-based, semantics-based) or specific examples (e.g., Seq2SQL, IRNet) of existing Text-to-SQL approaches mentioned in the introduction. Focus on how these approaches are characterized or grouped by the authors.\",\n",
    "                \"evidence\": \"Quote or specifically paraphrase from the introduction to support the overview.\"\n",
    "            },\n",
    "            \"limitations_of_existing_approaches\": {\n",
    "                \"analysis\": \"Detail the limitations or shortcomings of existing approaches as pointed out by the authors. Include specific examples (e.g., failure on complex joins) or categories of issues (e.g., poor generalization, high error rates) that motivate the current research.\",\n",
    "                \"evidence\": \"Quote or specifically paraphrase the discussion of limitations from the introduction.\"\n",
    "            },\n",
    "            \"claimed_contributions\": {\n",
    "                \"analysis\": \"Identify and describe the specific, novel contributions the paper claims to make to the field of Text-to-SQL. Focus on what sets this work apart from prior research, such as new techniques, improved performance, or addressing previously unsolved problems.\",\n",
    "                \"evidence\": \"Quote or specifically paraphrase the statements of contributions from the introduction.\"\n",
    "            },\n",
    "            \"introduction_conclusion_roadmap\": {\n",
    "                \"analysis\": \"Determine if the introduction concludes with a roadmap or outline of the paper's structure. If present, summarize the key sections or flow of the paper as described (e.g., methodology, experiments, discussion).\",\n",
    "                \"evidence\": \"Quote or specifically paraphrase the roadmap or outline from the introduction.\"\n",
    "            }\n",
    "        },\n",
    "        \"methodology_analysis\": {\n",
    "            \"ai_techniques_used\": {\n",
    "                \"analysis\": \"Identify and describe any specific AI techniques mentioned in the methodology, such as deep learning architectures (e.g., transformers, RNNs), reinforcement learning, or specific types of neural networks (e.g., BERT-based models). Explain how these techniques are applied in the context of Text-to-SQL (e.g., query generation, schema encoding).\",\n",
    "                \"evidence\": \"Quote or specifically paraphrase from the methodology section to support the description.\"\n",
    "            },\n",
    "            \"input_output_specifications\": {\n",
    "                \"analysis\": \"Describe the precise input to the system (e.g., natural language question format, database schema representation such as JSON or SQL DDL) and the expected output (e.g., SQL query syntax, including specific clauses like SELECT, WHERE). Include any preprocessing (e.g., tokenization) or postprocessing steps (e.g., query validation) mentioned.\",\n",
    "                \"evidence\": \"Quote or specifically paraphrase from the methodology section to detail the input and output.\"\n",
    "            },\n",
    "            \"algorithm_llm_prompt_details\": {\n",
    "                \"analysis\": \"Provide a detailed explanation of the proposed algorithm or model architecture. If a Large Language Model (LLM) is used, specify which LLM (e.g., GPT-3, LLaMA), any fine-tuning processes (e.g., dataset used, training objectives), and critically, the details of prompt engineering (e.g., few-shot examples, chain-of-thought reasoning, schema linking instructions, specific prompt templates like 'Given this schema: {schema}, generate an SQL query for: {question}').\",\n",
    "                \"evidence\": \"Quote or specifically paraphrase from the methodology section to support the explanation.\"\n",
    "            },\n",
    "            \"rag_usage_details\": {\n",
    "                \"analysis\": \"If Retrieval Augmented Generation (RAG) or similar techniques are used for schema or knowledge integration, explain how they are implemented and utilized within the system. Include details on the retrieval mechanism (e.g., vector search over schema elements), how retrieved information is integrated (e.g., into prompts), and how it enhances the Text-to-SQL process (e.g., improving accuracy on unseen schemas).\",\n",
    "                \"evidence\": \"Quote or specifically paraphrase from the methodology section to describe the implementation.\"\n",
    "            },\n",
    "            \"workflow_details\": {\n",
    "                \"analysis\": \"Describe the step-by-step workflow or pipeline of how a natural language question is processed and converted to an SQL query by the system. Include stages like question parsing, schema mapping, query generation, and validation. If multiple workflows or variations are presented (e.g., with/without RAG), detail each one.\",\n",
    "                \"evidence\": \"Quote or specifically paraphrase from the methodology section to outline the workflow.\"\n",
    "            },\n",
    "            \"control_mechanisms_or_experiments\": {\n",
    "                \"analysis\": \"Identify and describe any control mechanisms (e.g., baseline comparisons), ablation studies (e.g., removing prompt engineering), or variations of the method tested (e.g., different LLMs) to isolate the contributions of different components. Explain the purpose (e.g., to measure impact of schema linking) and findings of these experiments.\",\n",
    "                \"evidence\": \"Quote or specifically paraphrase from the methodology or experimental setup section.\"\n",
    "            },\n",
    "            \"complexity_of_method\": {\n",
    "                \"analysis\": \"Discuss any mentions of the complexity of the proposed method, whether computational (e.g., time complexity O(n), memory usage), architectural (e.g., number of parameters, layers), or conceptual (e.g., difficulty in implementation or interpretability). Include trade-offs if mentioned.\",\n",
    "                \"evidence\": \"Quote or specifically paraphrase from the methodology section to support the discussion.\"\n",
    "            },\n",
    "            \"presentation_of_methodology\": {\n",
    "                \"analysis\": \"Describe how the methodology is presented in the paper, such as through tables (e.g., parameter settings), figures (e.g., architecture diagrams), lists (e.g., workflow steps), or pseudo-code (e.g., algorithm outline). Briefly explain any key visual or structural aids that help clarify the method.\",\n",
    "                \"evidence\": \"Reference specific figures, tables, or sections, or quote descriptions from the text.\"\n",
    "            }\n",
    "        },\n",
    "        \"results_analysis\": {\n",
    "            \"evaluation_criteria_and_metrics\": {\n",
    "                \"analysis\": \"Identify and describe the specific evaluation criteria and metrics used to assess the performance of the Text-to-SQL system (e.g., Execution Accuracy, Exact Set Match Accuracy, F1-score for query components). Specify the standard Text-to-SQL benchmarks (e.g., Spider, WikiSQL, SParC, CoSQL) on which the results are reported, including dataset characteristics (e.g., complexity, size).\",\n",
    "                \"evidence\": \"Quote or specifically paraphrase from the results or experimental setup section.\"\n",
    "            },\n",
    "            \"quantitative_results\": {\n",
    "                \"analysis\": \"Present the key quantitative results reported in the paper, including specific scores (e.g., 85% accuracy), improvements over baselines (e.g., +5% over previous SOTA), and any statistical significance (e.g., p-values) mentioned. Include comparisons to other methods if provided.\",\n",
    "                \"evidence\": \"Directly quote or accurately summarize the numerical results and associated benchmarks/metrics.\"\n",
    "            }\n",
    "        },\n",
    "        \"discussion_analysis\": {\n",
    "            \"interpretation_of_results_how_good\": {\n",
    "                \"analysis\": \"Explain how the authors interpret their results, including how 'good' they claim their method is compared to state-of-the-art (SOTA) methods or baselines. Discuss any qualitative assessments (e.g., robustness) or implications (e.g., real-world applicability) of the results.\",\n",
    "                \"evidence\": \"Quote or specifically paraphrase from the discussion section to support the interpretation.\"\n",
    "            },\n",
    "            \"limitations_of_the_study\": {\n",
    "                \"analysis\": \"Identify and describe the explicitly stated or discernible limitations, weaknesses, or failure cases of the proposed method or the study itself, as discussed by the authors. Include specific examples (e.g., struggles with nested queries) or scenarios (e.g., low performance on certain benchmarks).\",\n",
    "                \"evidence\": \"Quote or specifically paraphrase from the discussion section.\"\n",
    "            },\n",
    "            \"explanation_of_performance_why\": {\n",
    "                \"analysis\": \"Determine if the paper offers explanations, hypotheses, or reasons for why their method achieves certain results, both positive (e.g., effective schema encoding) and negative (e.g., prompt sensitivity). For instance, why it performs well on certain types of queries (e.g., simple selects) or datasets (e.g., Spider), or why it fails in others (e.g., multi-table joins).\",\n",
    "                \"evidence\": \"Quote or specifically paraphrase from the discussion section to support the explanations.\"\n",
    "            },\n",
    "            \"deeper_analysis_insights\": {\n",
    "                \"analysis\": \"Identify any deeper analysis of the results, such as error analysis (e.g., types of SQL errors like incorrect joins, common failure modes like misinterpreting ambiguity), case studies (e.g., specific query examples), or qualitative insights into the system's behavior (e.g., over-reliance on training patterns). Describe the key findings from this analysis.\",\n",
    "                \"evidence\": \"Quote or specifically paraphrase from the discussion or error analysis section.\"\n",
    "            },\n",
    "            \"llm_specific_discussion\": {\n",
    "                \"analysis\": \"If the method is LLM-based, identify and describe any specific discussions around LLM behavior, such as generalization capabilities (e.g., across datasets), understanding of complex schemas (e.g., multi-table relationships), sensitivity to prompts (e.g., rephrasing effects), hallucination issues (e.g., generating invalid SQL), or ethical considerations (e.g., bias in query interpretation).\",\n",
    "                \"evidence\": \"Quote or specifically paraphrase from the discussion section focusing on LLM aspects.\"\n",
    "            }\n",
    "        },\n",
    "        \"conclusion_analysis\": {\n",
    "            \"summary_of_achievements\": {\n",
    "                \"analysis\": \"Summarize the main achievements, findings, and takeaways of the research as stated in the paper's conclusion section. Focus on the key points the authors want to leave with the reader, such as novel contributions, performance gains, or practical impacts.\",\n",
    "                \"evidence\": \"Quote or specifically paraphrase from the conclusion section.\"\n",
    "            },\n",
    "            \"llm_practical_considerations\": {\n",
    "                \"analysis\": \"If an LLM is central to the method, determine if the conclusion touches upon practical aspects such as accuracy-cost-latency tradeoffs (e.g., inference time vs. performance), stability (e.g., consistency across runs), scalability (e.g., handling large schemas), or security implications (e.g., injection risks) for real-world deployment of their Text-to-SQL system.\",\n",
    "                \"evidence\": \"Quote or specifically paraphrase from the conclusion section regarding LLM practicalities.\"\n",
    "            }\n",
    "        },\n",
    "        \"future_directions_analysis\": {\n",
    "            \"proposed_future_work_potential_solutions\": {\n",
    "                \"analysis\": \"Identify and describe the potential avenues for future research, improvements to their method, or solutions to remaining challenges in Text-to-SQL as suggested by the authors. Include any specific directions (e.g., incorporating external knowledge) or open questions (e.g., handling dynamic schemas) mentioned.\",\n",
    "                \"evidence\": \"Quote or specifically paraphrase from the future work or conclusion section.\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86843d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm tạo prompt content\n",
    "def create_prompt_content(paper_content):\n",
    "\n",
    "    prompt_string = (\n",
    "    \"You are an expert research paper analyst specializing in Natural Language Processing, particularly Text-to-SQL systems. \"\n",
    "    \"Your primary task is to perform a **thorough, in-depth, and comprehensive analysis** of the provided Text-to-SQL research paper. \"\n",
    "    \"You must generate a detailed report in JSON format. \\n\\n\"\n",
    "    \"**Crucially, for EACH AND EVERY analytical point and for EVERY field within the JSON structure that requires textual interpretation, you MUST provide direct quotes or highly specific paraphrased evidence extracted directly from the paper.** \"\n",
    "    \"This evidence is non-negotiable. Clearly cite the section or page number for each piece of evidence, if available. \"\n",
    "    \"Ensure that your analysis covers all relevant aspects presented in the paper, leaving no significant detail unaddressed. \"\n",
    "    \"Generic statements or analyses without direct textual backing from the paper are unacceptable.\\n\\n\"\n",
    "    \"**When extracting text from the paper for inclusion in the JSON, ensure that:**\\n\"\n",
    "    \"- All special characters are properly escaped according to JSON standards (e.g., double quotes should be escaped with a backslash).\\n\"\n",
    "    \"- Any formatting issues in the paper's text are handled to prevent JSON syntax errors (e.g., remove or replace problematic characters).\\n\"\n",
    "    \"- Text is treated as plain strings, without interpreting any content as JSON syntax.\\n\"\n",
    "    \"- Use UTF-8 encoding for any non-ASCII characters to ensure compatibility.\\n\"\n",
    "    \"- Remove or replace any control characters or non-printable characters that could invalidate the JSON.\\n\"\n",
    "    \"- While handling the text for JSON compatibility, ensure that the meaning and accuracy of the extracted evidence are preserved. Do not alter the text in a way that changes its original intent or content.\\n\\n\"\n",
    "    \"**Additionally, ensure that all analysis is strictly based on the content extracted from the paper. Do not use external knowledge or make inferences that extend beyond what is explicitly stated in the text. Your analysis must remain focused solely on the information provided within the paper.**\\n\\n\"\n",
    "    \"The JSON output must **strictly adhere** to the following structure, mirroring a detailed breakdown of a research paper:\\n\\n\" +\n",
    "    json_structure +  # Biến này chứa chuỗi định dạng JSON template của bạn\n",
    "    \"\\n\\nProvide your detailed and evidence-backed analysis for the following paper content:\\n\\n\" +\n",
    "    paper_content +   # Biến này chứa nội dung bài báo\n",
    "    \"\\n\\n**Before finalizing your analysis, review each point to ensure it is directly supported by the paper's content.**\\n\"\n",
    "    \"**Additionally, verify that the generated JSON is structurally valid and that all text fields are properly formatted and escaped.**\\n\\n\"\n",
    "    \"Your Response:\\n\"\n",
    "    )\n",
    "\n",
    "    return prompt_string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b85d860a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm gọi Gemini API\n",
    "def analyze_content_with_gemini(paper_content, api_key):\n",
    "    client = genai.Client(api_key=api_key)  # Khởi tạo client theo tài liệu thực tế\n",
    "    \n",
    "    prompt_content = create_prompt_content(paper_content)\n",
    "    \n",
    "    try:\n",
    "        response = client.models.generate_content(\n",
    "            model='gemini-2.5-flash-preview-05-20',\n",
    "            contents=prompt_content\n",
    "        )\n",
    "        result = response.text.strip()   \n",
    "        print(\"Gemini API Output:\", result)\n",
    "\n",
    "        # Extract JSON from markdown code block\n",
    "        match = re.search(r'```json\\s*(.*?)\\s*```', result, re.DOTALL)\n",
    "        if match:\n",
    "            json_str = match.group(1)\n",
    "            try:\n",
    "                json_data = json.loads(json_str)\n",
    "                return json_data  # Return parsed dictionary\n",
    "            except json.JSONDecodeError:\n",
    "                print(\"Failed to parse JSON from response\")\n",
    "                return None\n",
    "        else:\n",
    "            print(\"No JSON found in the response\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error calling Gemini API: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68395c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract text from PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Extracts text from a PDF file.\"\"\"\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        text = \"\"\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text() + \"\\n\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7fe766c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_json_output(file_path, json_result):\n",
    "    base_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    output_file_name = f\"{base_name}.json\"\n",
    "    output_full_path = os.path.join(os.path.dirname(file_path), output_file_name)\n",
    "    \n",
    "    # Check if json_result is valid (not None and is a dict)\n",
    "    if json_result is not None and isinstance(json_result, dict):\n",
    "        with open(output_full_path, 'w', encoding='utf-8') as json_file:\n",
    "            json.dump(json_result, json_file, ensure_ascii=False, indent=4)\n",
    "        print(f\"Đã lưu kết quả vào {output_full_path}\")\n",
    "    else:\n",
    "        print(f\"Không thể lưu kết quả cho {file_path}: json_result không hợp lệ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfc7ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = 'arxiv'\n",
    "\n",
    "if not os.path.isdir(directory_path):\n",
    "    raise ValueError(f\"{directory_path} không phải là một thư mục hợp lệ.\")\n",
    "    \n",
    "# Duyệt qua tất cả các file trong thư mục\n",
    "for file in os.listdir(directory_path):\n",
    "    if file.lower().endswith('.pdf'):  # Kiểm tra file có phải PDF không (không phân biệt hoa thường)\n",
    "        full_path = os.path.join(directory_path, file)  # Tạo đường dẫn đầy đủ cho file PDF\n",
    "        json_path = os.path.splitext(full_path)[0] + '.json'  # Tạo đường dẫn cho file JSON tương ứng\n",
    "        if os.path.exists(json_path):\n",
    "            print(f\"File JSON đã tồn tại cho {full_path}, skip...\")\n",
    "            continue\n",
    "        print(f\"Đang xử lý {full_path}...\")  # Thông báo file đang được xử lý\n",
    "        try:\n",
    "            api_key = get_current_api_key()     # Lấy API key hiện tại\n",
    "            text = extract_text_from_pdf(full_path)  # Trích xuất văn bản từ PDF\n",
    "            json_result = analyze_content_with_gemini(paper_content=text, api_key=api_key)\n",
    "            if json_result is not None:\n",
    "                save_json_output(file_path=full_path, json_result=json_result)\n",
    "            else:\n",
    "                print(f\"Không thể xử lý JSON cho {full_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi khi xử lý {full_path}: {e}\")  # Thông báo lỗi nếu có"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcb1c21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crawl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
