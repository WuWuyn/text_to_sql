{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "379ae730",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\giang\\anaconda3\\Lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "import re\n",
    "from nltk import sent_tokenize\n",
    "from nltk import ngrams\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01718e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"Preprocess the text: convert to lowercase, replace punctuation with space, and reduce multiple spaces to one.\"\"\"\n",
    "    text = text.lower()  # Chuyển văn bản thành chữ thường\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)  # Thay thế dấu câu bằng khoảng trắng\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Rút gọn nhiều khoảng trắng thành một\n",
    "    text = text.strip()  # Loại bỏ khoảng trắng đầu và cuối\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00cce467",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ngrams(text, n):\n",
    "    \"\"\"Generate n-grams from the text.\"\"\"\n",
    "    words = text.split()\n",
    "    return [' '.join(gram) for gram in ngrams(words, n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d16790c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_group(sentences, keywords, threshold=90):\n",
    "    \"\"\"Check if the group of keywords is related to the abstract.\"\"\"\n",
    "    all_ngrams = []\n",
    "    for sentence in sentences:\n",
    "        for n in range(1, 5):  # From 1-gram to 4-gram\n",
    "            all_ngrams.extend(generate_ngrams(sentence, n))\n",
    "    \n",
    "    for keyword in keywords:\n",
    "        for ngram in all_ngrams:\n",
    "            if fuzz.WRatio(keyword, ngram) > threshold:\n",
    "                return True\n",
    "        for sentence in sentences:\n",
    "            if fuzz.WRatio(keyword, sentence) > threshold:\n",
    "                return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750b357a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_abstract(abstract):\n",
    "    \"\"\"Classify the abstract and return a list of True/False for each keyword group.\"\"\"\n",
    "    abstract = preprocess_text(abstract)\n",
    "    sentences = sent_tokenize(abstract)\n",
    "    \n",
    "    text_to_sql_keywords = [\"functional testing\", \"LLM\", \"LLM to Funtional test\", \"Test Generation\", \"Automation generative\", \"UI Testing\", \"Benchmark for functional testing\"]\n",
    "    security_keywords = [\"security\", \"access control\", \"injection\", \"prompt injection\", \n",
    "                         \"defense\", \"attack\", \"vulnerability\"]\n",
    "    llm_keywords = [\"llm\", \"large language model\"]\n",
    "    \n",
    "    t2sql_result = check_group(sentences, text_to_sql_keywords)\n",
    "    security_result = check_group(sentences, security_keywords)\n",
    "    llm_result = check_group(sentences, llm_keywords)\n",
    "    \n",
    "    return [t2sql_result, security_result, llm_result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d036366",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_csv(input_csv, output_csv=None):\n",
    "    \"\"\"\n",
    "    Đọc file CSV, phân loại từng abstract với xử lý song song, và thêm 3 cột boolean mới: t2sql, security, llm.\n",
    "    \n",
    "    :param input_csv: Đường dẫn đến file CSV đầu vào.\n",
    "    :param output_csv: Đường dẫn để lưu file CSV đầu ra. Nếu None, không lưu.\n",
    "    :return: DataFrame đã được cập nhật với các cột boolean mới.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(input_csv)\n",
    "    \n",
    "    if 'abstract' not in df.columns:\n",
    "        raise ValueError(\"File CSV phải chứa cột 'abstract'.\")\n",
    "    \n",
    "    df['abstract'] = df['abstract'].astype(str)\n",
    "    classifications = Parallel(n_jobs=-1)(delayed(classify_abstract)(abstract) for abstract in df['abstract'])\n",
    "    \n",
    "    df['t2sql'] = [result[0] for result in classifications]\n",
    "    df['security'] = [result[1] for result in classifications]\n",
    "    df['llm'] = [result[2] for result in classifications]\n",
    "    \n",
    "    df['submitted'] = pd.to_datetime(df['submitted'])\n",
    "    df = df.sort_values(by='submitted', ascending=False)\n",
    "\n",
    "    if output_csv:\n",
    "        df.to_csv(output_csv, index=False)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "664c141e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total papers: 126\n"
     ]
    }
   ],
   "source": [
    "type = \"ieee\"\n",
    "input_csv = f\"../raw_crawl_papers/date_processed/{type}_papers.csv\"  # Thay bằng đường dẫn file CSV của bạn\n",
    "output_csv = f\"../keywords_summary/{type}/{type}_with_keywords.csv\"  # Thay bằng đường dẫn file CSV đầu ra\n",
    "df = process_csv(input_csv, output_csv)\n",
    "print(f\"Total papers: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f4bdf2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of papers that relating to t2sql, llm and security keywords: 2\n"
     ]
    }
   ],
   "source": [
    "# 1. Trích xuất các record có True trong cả 3 cột\n",
    "all_true_df = df[(df['t2sql'] == True) & (df['llm'] == True) & (df['security'] == True)]\n",
    "print(f\"Total number of papers that relating to t2sql, llm and security keywords: {len(all_true_df)}\")\n",
    "\n",
    "all_true_df = all_true_df.copy()\n",
    "\n",
    "all_true_df['submitted'] = pd.to_datetime(all_true_df['submitted'])\n",
    "all_true_df = all_true_df.sort_values(by='submitted', ascending=False)\n",
    "\n",
    "all_true_df.to_csv(f\"../keywords_summary/{type}/all_true.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fa8fd10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of papers that relating to t2sql and llm keywords: 43\n"
     ]
    }
   ],
   "source": [
    "# 2. Trích xuất các record có True trong t2sql và llm\n",
    "t2sql_llm_true_df = df[(df['t2sql'] == True) & (df['llm'] == True)]\n",
    "print(f\"Total number of papers that relating to t2sql and llm keywords: {len(t2sql_llm_true_df)}\")\n",
    "\n",
    "t2sql_llm_true_df = t2sql_llm_true_df.copy()\n",
    "\n",
    "t2sql_llm_true_df['submitted'] = pd.to_datetime(t2sql_llm_true_df['submitted'])\n",
    "t2sql_llm_true_df = t2sql_llm_true_df.sort_values(by='submitted', ascending=False)\n",
    "\n",
    "t2sql_llm_true_df.to_csv(f\"../keywords_summary/{type}/t2sql_llm_true.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57efc1c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of papers that relating to t2sql and security keywords: 4\n"
     ]
    }
   ],
   "source": [
    "# 3. Trích xuất các record có True trong t2sql và security\n",
    "t2sql_security_true_df = df[(df['t2sql'] == True) & (df['security'] == True)]\n",
    "print(f\"Total number of papers that relating to t2sql and security keywords: {len(t2sql_security_true_df)}\")\n",
    "\n",
    "t2sql_security_true_df = t2sql_security_true_df.copy()\n",
    "\n",
    "t2sql_security_true_df['submitted'] = pd.to_datetime(t2sql_security_true_df['submitted'])\n",
    "t2sql_security_true_df = t2sql_security_true_df.sort_values(by='submitted', ascending=False)\n",
    "\n",
    "t2sql_security_true_df.to_csv(f\"../keywords_summary/{type}/t2sql_security_true.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e289599b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique papers in merged DataFrame: 45\n"
     ]
    }
   ],
   "source": [
    "# Hợp nhất ba DataFrame\n",
    "merged_df = pd.concat([all_true_df, t2sql_llm_true_df, t2sql_security_true_df], ignore_index=True)\n",
    "\n",
    "# Loại bỏ các bản ghi trùng lặp\n",
    "merged_df = merged_df.drop_duplicates()\n",
    "\n",
    "# Lưu vào tệp CSV mới\n",
    "output_path = f\"../keywords_summary/{type}/merged_keyword_results.csv\"\n",
    "merged_df.to_csv(output_path, index=False)\n",
    "\n",
    "# In số lượng bản ghi trong DataFrame hợp nhất\n",
    "print(f\"Total number of unique papers in merged DataFrame: {len(merged_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0bfd6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
