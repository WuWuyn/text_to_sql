{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Crispy Chicken Research Pipeline\n",
        "\n",
        "This notebook demonstrates the complete workflow for the Crispy Chicken academic paper crawler:\n",
        "1. Crawl papers from multiple academic sources\n",
        "2. Combine papers and remove duplicates\n",
        "3. Download papers with date filtering\n",
        "4. Perform quality assessment\n",
        "5. Analyze content\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Import necessary libraries and modules and define all variables\n",
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "# Import crawler tools\n",
        "from crawl_tools.acm_crawler import ACMCrawler\n",
        "from crawl_tools.arxiv_crawler import ArxivCrawler\n",
        "from crawl_tools.ieee_crawler import IEEECrawler\n",
        "from crawl_tools.mdpi_crawler import MDPICrawler\n",
        "from crawl_tools.science_direct_crawler import ScienceDirectCrawler\n",
        "from crawl_tools.springer_crawler import SpringerCrawler\n",
        "\n",
        "# Import filter tools\n",
        "from filter_tools.combine_papers import PaperCombiner\n",
        "from filter_tools.download_papers import PaperDownloader\n",
        "from filter_tools.quality_assessment import QualityAssessment\n",
        "from filter_tools.content_analysis_csv import CSVContentAnalyzer\n",
        "from filter_tools.research_pipeline import ResearchPipeline, create_pipeline\n",
        "\n",
        "# Define keyword sets for search\n",
        "keyword_sets = {\n",
        "    'functional_testing': [\n",
        "        '\"Functional Testing\"', '\"Software Testing\"', '\"Test Case Generation\"',\n",
        "        '\"Test Data Generation\"', '\"Test Automation Frameworks\"',\n",
        "        '\"WEB UI Testing\"', '\"API Testing\"',\n",
        "        '\"Test Oracle Problem\"', '\"Test Coverage\"', '\"Bug Detection\"'\n",
        "    ],\n",
        "    'llm': ['\"llm\"', '\"large language model\"'],\n",
        "    'object': ['\"web\"', '\"mobile\"', '\"code\"', '\"software\"']\n",
        "}\n",
        "\n",
        "# Configuration for crawlers\n",
        "CRAWL_CONFIG = {\n",
        "    'headless': True,          # Run browser in headless mode\n",
        "    'max_threads': 4,          # Maximum number of threads\n",
        "    'use_multithreading': True # Use multithreading\n",
        "}\n",
        "\n",
        "# Define output directories\n",
        "OUTPUT_DIR = \"output\"\n",
        "FILTERED_DIR = \"filtered_papers\"\n",
        "DOWNLOAD_DIR = os.path.join(FILTERED_DIR, \"downloaded_papers\")\n",
        "\n",
        "# Create directories if they don't exist\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "os.makedirs(FILTERED_DIR, exist_ok=True)\n",
        "os.makedirs(DOWNLOAD_DIR, exist_ok=True)\n",
        "\n",
        "# Define API keys for quality assessment\n",
        "API_KEYS = [\"AIzaSyANNoXbbOQ4C_q01LYE8_WvUIPU79-80Tc\",\"AIzaSyCsnZT98ULdpJEKGsry5Fv-wnedcRvzV2Y\"]\n",
        "\n",
        "# Define paths for papers and assessments\n",
        "PAPERS_DIR = os.path.join(DOWNLOAD_DIR, \"all_papers\")\n",
        "ASSESSMENT_DIR = os.path.join(FILTERED_DIR, \"quality_assessments\")\n",
        "os.makedirs(ASSESSMENT_DIR, exist_ok=True)\n",
        "\n",
        "# Define source files for paper combination\n",
        "source_files = {\n",
        "    'ArXiv': f\"{OUTPUT_DIR}/arxiv/all_arxiv_papers.csv\",\n",
        "    'IEEE': f\"{OUTPUT_DIR}/ieee/all_ieee_papers.csv\",\n",
        "    'ACM': f\"{OUTPUT_DIR}/acm/all_acm_papers.csv\",\n",
        "    'Science Direct': f\"{OUTPUT_DIR}/science_direct/all_science_direct_papers.csv\",\n",
        "    'Springer': f\"{OUTPUT_DIR}/springer/all_springer_papers.csv\",\n",
        "}\n",
        "\n",
        "# Path to the combined papers file\n",
        "combined_file = os.path.join(FILTERED_DIR, \"all_papers_consolidated_unique.csv\")\n",
        "input_csv = combined_file\n",
        "\n",
        "# Analysis directory\n",
        "output_analysis_dir = os.path.join(FILTERED_DIR, \"analysis\")\n",
        "os.makedirs(output_analysis_dir, exist_ok=True)\n",
        "\n",
        "print(\"‚úÖ Successfully imported all required modules and initialized variables\")\n",
        "print(f\"üîç Using {len(keyword_sets['functional_testing'])} functional testing keywords\")\n",
        "print(f\"üîç Using {len(keyword_sets['llm'])} LLM keywords\")\n",
        "print(f\"üîç Using {len(keyword_sets['object'])} object keywords\")\n",
        "print(\"üìÅ All directories created\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. Initialize the pipeline with the configured variables\n",
        "\n",
        "# Create the research pipeline with all predefined variables\n",
        "pipeline = create_pipeline()\n",
        "\n",
        "# Update the pipeline configuration with our predefined settings\n",
        "pipeline.config.keyword_sets = keyword_sets\n",
        "pipeline.config.crawl_config = CRAWL_CONFIG\n",
        "pipeline.config.filtered_output_dir = FILTERED_DIR\n",
        "pipeline.config.base_output_dir = OUTPUT_DIR\n",
        "pipeline.config.download_dir = DOWNLOAD_DIR\n",
        "\n",
        "# Set API keys in the pipeline\n",
        "if API_KEYS and API_KEYS[0] != \"YOUR_API_KEY_HERE\":\n",
        "    pipeline.config.set_api_keys(API_KEYS)\n",
        "\n",
        "print(\"üöÄ Pipeline initialized with predefined configuration\")\n",
        "print(f\"üìÅ Output directory: {pipeline.config.filtered_output_dir}\")\n",
        "print(f\"üéØ Keyword groups: {list(pipeline.config.keyword_sets.keys())}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. STEP 1: Crawl papers using the initialized pipeline\n",
        "print(\"üöÄ Running all crawlers using research pipeline...\")\n",
        "\n",
        "# Run all crawlers with the pipeline we already configured\n",
        "# Select a subset of crawlers for testing\n",
        "selected_crawlers = ['arxiv', 'ieee']  # You can add 'acm', 'springer', 'science_direct', 'mdpi'\n",
        "crawl_results = pipeline.run_all_crawlers(selected_crawlers=selected_crawlers)\n",
        "\n",
        "print(f\"üéâ All crawling completed!\")\n",
        "print(f\"‚úÖ Successful crawlers: {crawl_results['successful_crawls']}/{crawl_results['total_crawlers']}\")\n",
        "print(f\"‚ùå Failed crawlers: {crawl_results['failed_crawls']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4. STEP 2: Combine papers from all sources\n",
        "print(\"üîÑ Combining papers from all sources...\")\n",
        "\n",
        "# Initialize the paper combiner with our predefined directory\n",
        "# PaperCombiner uses base_dir parameter, not output_dir\n",
        "combiner = PaperCombiner(base_dir=\".\")\n",
        "\n",
        "# Use the source_files already defined in our initial setup\n",
        "# Filter to only use existing files\n",
        "existing_files = {k: v for k, v in source_files.items() if os.path.exists(v)}\n",
        "\n",
        "if existing_files:\n",
        "    print(f\"üìä Found {len(existing_files)} source files: {', '.join(existing_files.keys())}\")\n",
        "    \n",
        "    # Combine papers using the combine_papers method\n",
        "    output_file = combiner.combine_papers(\n",
        "        file_paths=list(existing_files.values()),\n",
        "        output_filename=\"all_papers_consolidated_unique.csv\"\n",
        "    )\n",
        "    \n",
        "    if output_file and os.path.exists(output_file):\n",
        "        # Read and display the results\n",
        "        combined_df = pd.read_csv(output_file)\n",
        "        print(f\"‚úÖ Combined {len(combined_df)} unique papers\")\n",
        "        print(f\"üíæ Saved combined papers to {output_file}\")\n",
        "        \n",
        "        # Display a sample of the combined papers\n",
        "        print(\"üìã Sample of combined papers:\")\n",
        "        display(combined_df.head(3))\n",
        "    else:\n",
        "        print(\"‚ùå No papers found or error in combining papers\")\n",
        "else:\n",
        "    print(f\"‚ùå No source files found. Please run crawling first.\")\n",
        "    print(f\"üîç Expected files: {list(source_files.values())}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5. STEP 3: Download papers with date filtering\n",
        "print(\"üì• Downloading papers with date filtering...\")\n",
        "\n",
        "# Initialize the paper downloader with our predefined output directory\n",
        "downloader = PaperDownloader(output_dir=DOWNLOAD_DIR)\n",
        "\n",
        "# Use input_csv that was already defined in our initial setup\n",
        "# Check if the combined file exists\n",
        "if os.path.exists(input_csv):\n",
        "    # Define date range\n",
        "    start_date = \"2023-01-01\"\n",
        "    end_date = \"2025-07-01\"\n",
        "    \n",
        "    # Define output subdirectory\n",
        "    output_subdir = \"all_papers\"\n",
        "    output_dir_all = os.path.join(DOWNLOAD_DIR, output_subdir)\n",
        "    os.makedirs(output_dir_all, exist_ok=True)\n",
        "    \n",
        "    print(f\"üóìÔ∏è Filtering papers from {start_date} to {end_date}\")\n",
        "    filtered_df = downloader.filter_papers_by_date(\n",
        "        input_csv=input_csv,\n",
        "        start_date=start_date,\n",
        "        end_date=end_date\n",
        "    )\n",
        "    \n",
        "    if filtered_df is not None and not filtered_df.empty:\n",
        "        print(f\"‚úÖ Found {len(filtered_df)} papers from 2023 to 2025\")\n",
        "        \n",
        "        # Download a limited number of papers (for testing)\n",
        "        max_papers = 5  # Limit for testing\n",
        "        \n",
        "        # Download the papers\n",
        "        download_results = downloader.download_papers(\n",
        "            papers_df=filtered_df,\n",
        "            pdf_link_column='pdf_link',\n",
        "            max_papers=max_papers\n",
        "        )\n",
        "        \n",
        "        # Count successful downloads\n",
        "        successful = sum(1 for result in download_results if result[0] == 'success')\n",
        "        failed = sum(1 for result in download_results if result[0] == 'error')\n",
        "        \n",
        "        print(f\"üìä Download Results:\")\n",
        "        print(f\"   ‚úÖ Successfully downloaded: {successful}\")\n",
        "        print(f\"   ‚ùå Failed downloads: {failed}\")\n",
        "        print(f\"   üìÅ Saved to directory: {output_dir_all}\")\n",
        "    else:\n",
        "        print(\"‚ùå No papers found for the specified date range\")\n",
        "else:\n",
        "    print(f\"‚ùå Combined file not found: {input_csv}\")\n",
        "    print(\"üí° Please complete the paper combination step first\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 6. STEP 4: Perform quality assessment\n",
        "print(\"üß† Performing quality assessment...\")\n",
        "\n",
        "# Use PAPERS_DIR and ASSESSMENT_DIR already defined in our initial setup\n",
        "# We're already using API_KEYS defined at the beginning\n",
        "\n",
        "# Check if API keys are provided\n",
        "if not API_KEYS or API_KEYS[0] == \"YOUR_API_KEY_HERE\":\n",
        "    print(\"‚ö†Ô∏è Please add your Gemini API key to run quality assessment\")\n",
        "else:\n",
        "    # Check if papers directory exists and contains PDFs\n",
        "    if os.path.exists(PAPERS_DIR) and any(f.endswith('.pdf') for f in os.listdir(PAPERS_DIR)):\n",
        "        # Initialize quality assessment with our predefined API keys\n",
        "        assessor = QualityAssessment(api_keys=API_KEYS)\n",
        "        \n",
        "        # Assess a limited number of papers (for testing)\n",
        "        max_papers = 2  # Limit for testing\n",
        "        \n",
        "        print(f\"üîç Assessing up to {max_papers} papers from {PAPERS_DIR}\")\n",
        "        \n",
        "        # Run assessment\n",
        "        summary = assessor.batch_assess_papers(\n",
        "            pdf_dir=PAPERS_DIR,\n",
        "            output_dir=ASSESSMENT_DIR,\n",
        "            max_papers=max_papers\n",
        "        )\n",
        "        \n",
        "        if summary:\n",
        "            print(f\"üìä Assessment Results:\")\n",
        "            print(f\"   üìÑ Total papers: {summary.get('total_papers', 0)}\")\n",
        "            print(f\"   ‚úÖ Successful assessments: {summary.get('successful_assessments', 0)}\")\n",
        "            print(f\"   ‚ùå Failed assessments: {summary.get('failed_assessments', 0)}\")\n",
        "            \n",
        "            # If there are successful assessments, create quality report\n",
        "            if summary.get('successful_assessments', 0) > 0:\n",
        "                report = assessor.create_quality_report(ASSESSMENT_DIR)\n",
        "                \n",
        "                if report:\n",
        "                    print(f\"üìà Quality report created:\")\n",
        "                    print(f\"   üìÑ Total papers analyzed: {report.get('total_papers', 0)}\")\n",
        "                    print(f\"   üìã Report CSV: {report.get('report_csv', 'N/A')}\")\n",
        "                    print(f\"   üìä Metrics JSON: {report.get('metrics_json', 'N/A')}\")\n",
        "        else:\n",
        "            print(\"‚ùå Quality assessment failed\")\n",
        "    else:\n",
        "        print(f\"‚ùå Papers directory not found or empty: {PAPERS_DIR}\")\n",
        "        print(\"üí° Please complete the paper download step first\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 7. STEP 5: Analyze content\n",
        "print(\"üìä Analyzing content...\")\n",
        "\n",
        "# Use input_csv and output_analysis_dir already defined in our initial setup\n",
        "\n",
        "# Check if the combined file exists\n",
        "if os.path.exists(input_csv):\n",
        "    # Initialize the content analyzer with our predefined API key\n",
        "    analyzer = CSVContentAnalyzer(api_key=API_KEYS[0] if API_KEYS and API_KEYS[0] != \"YOUR_API_KEY_HERE\" else None)\n",
        "    \n",
        "    # Analyze a limited number of papers (for testing)\n",
        "    max_papers = 5  # Limit for testing\n",
        "    \n",
        "    print(f\"üîç Analyzing up to {max_papers} papers from {input_csv}\")\n",
        "    \n",
        "    # If API key is not provided, run without content enhancement\n",
        "    if not API_KEYS or API_KEYS[0] == \"YOUR_API_KEY_HERE\":\n",
        "        print(\"‚ö†Ô∏è Running without content enhancement (no API key)\")\n",
        "        \n",
        "        # Analyze without content enhancement\n",
        "        result = analyzer.analyze_papers_csv(\n",
        "            input_csv=input_csv,\n",
        "            output_dir=output_analysis_dir,\n",
        "            max_papers=max_papers,\n",
        "            enhance_content=False\n",
        "        )\n",
        "    else:\n",
        "        # Analyze with content enhancement\n",
        "        result = analyzer.analyze_papers_csv(\n",
        "            input_csv=input_csv,\n",
        "            output_dir=output_analysis_dir,\n",
        "            max_papers=max_papers,\n",
        "            enhance_content=True\n",
        "        )\n",
        "    \n",
        "    if result:\n",
        "        print(f\"üìä Analysis Results:\")\n",
        "        print(f\"   üìÑ Total papers: {result.get('total_papers', 0)}\")\n",
        "        print(f\"   üìã Analysis CSV: {result.get('analysis_csv', 'N/A')}\")\n",
        "        \n",
        "        # If topics were extracted, display them\n",
        "        if result.get('topics'):\n",
        "            print(f\"   üîë Top topics:\")\n",
        "            for i, topic in enumerate(result.get('topics', [])[:5], 1):\n",
        "                print(f\"      {i}. {topic}\")\n",
        "    else:\n",
        "        print(\"‚ùå Content analysis failed\")\n",
        "else:\n",
        "    print(f\"‚ùå Combined file not found: {input_csv}\")\n",
        "    print(\"üí° Please complete the paper combination step first\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 8. Alternative: Running the complete pipeline using ResearchPipeline\n",
        "print(\"üîÑ Alternative: Running the complete pipeline...\")\n",
        "\n",
        "\"\"\"\n",
        "# Only uncomment this section if you want to run the full pipeline at once\n",
        "\n",
        "# We already have the pipeline created and configured at the beginning\n",
        "# No need to create it again, just reuse our 'pipeline' variable\n",
        "\n",
        "# Run the full pipeline\n",
        "# Set skip_crawling=True if you've already crawled papers\n",
        "# Set max_papers_to_analyze to limit the number of papers to analyze\n",
        "results = pipeline.run_full_pipeline(\n",
        "    selected_crawlers=['arxiv', 'ieee'],  # Add more if needed\n",
        "    skip_crawling=False,                  # Set to True to skip crawling\n",
        "    skip_download=False,                  # Set to True to skip downloading\n",
        "    max_papers_to_analyze=5               # Limit for testing\n",
        ")\n",
        "\n",
        "# Print summary\n",
        "if results:\n",
        "    print(f\"\\nüìä Pipeline Results Summary:\")\n",
        "    print(f\"   ‚úÖ Crawling: {results.get('crawling_status', 'Not run')}\")\n",
        "    print(f\"   ‚úÖ Combination: {results.get('combination_status', 'Not run')}\")\n",
        "    print(f\"   ‚úÖ Download: {results.get('download_status', 'Not run')}\")\n",
        "    print(f\"   ‚úÖ Analysis: {results.get('analysis_status', 'Not run')}\")\n",
        "    \n",
        "    # Paper statistics\n",
        "    paper_stats = results.get('paper_stats', {})\n",
        "    print(f\"\\nüìö Paper Statistics:\")\n",
        "    print(f\"   üìÑ Total papers combined: {paper_stats.get('total_combined', 0)}\")\n",
        "    print(f\"   üìÑ Unique papers after deduplication: {paper_stats.get('unique_papers', 0)}\")\n",
        "    print(f\"   üìÑ Papers from 2023 to now: {paper_stats.get('papers_from_2023', 0)}\")\n",
        "    print(f\"   üìÑ Successfully downloaded: {paper_stats.get('downloaded_papers', 0)}\")\n",
        "    print(f\"   üìÑ Papers analyzed: {paper_stats.get('analyzed_papers', 0)}\")\n",
        "else:\n",
        "    print(\"‚ùå Pipeline execution failed\")\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 9. Summary of workflow steps\n",
        "print(\"üéâ Complete workflow summary:\")\n",
        "print(\"=\" * 50)\n",
        "print(\"1Ô∏è‚É£ STEP 1: Crawl papers\")\n",
        "print(\"   - Used multiple academic sources (ArXiv, IEEE, etc.)\")\n",
        "print(\"   - Filtered by keywords related to LLM and software testing\")\n",
        "print(\"   - Saved results to CSV files in the output directory\")\n",
        "print()\n",
        "print(\"2Ô∏è‚É£ STEP 2: Combine papers\")\n",
        "print(\"   - Combined papers from all sources\")\n",
        "print(\"   - Removed duplicates based on title and content similarity\")\n",
        "print(\"   - Generated a consolidated CSV file\")\n",
        "print()\n",
        "print(\"3Ô∏è‚É£ STEP 3: Download papers\")\n",
        "print(\"   - Filtered papers by date (2023 - now)\")\n",
        "print(\"   - Downloaded PDF files\")\n",
        "print(\"   - Saved to the filtered_papers/downloaded_papers directory\")\n",
        "print()\n",
        "print(\"4Ô∏è‚É£ STEP 4: Quality assessment\")\n",
        "print(\"   - Assessed paper quality using structured criteria\")\n",
        "print(\"   - Used Google Gemini API for analysis\")\n",
        "print(\"   - Generated detailed quality reports\")\n",
        "print()\n",
        "print(\"5Ô∏è‚É£ STEP 5: Content analysis\")\n",
        "print(\"   - Analyzed paper content to extract topics and insights\")\n",
        "print(\"   - Generated analysis reports and visualizations\")\n",
        "print(\"   - Saved results to the filtered_papers/analysis directory\")\n",
        "print(\"=\" * 50)\n",
        "print(\"üìù Note: This notebook provides a step-by-step approach.\")\n",
        "print(\"üí° Tip: For a streamlined workflow, use the ResearchPipeline class in step 8\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
